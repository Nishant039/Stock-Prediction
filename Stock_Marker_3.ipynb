{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "m4gS_n9Ymj77",
    "outputId": "adc37203-68ad-475b-d480-8152edb531f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "dddhEoLTml_T",
    "outputId": "a8caf0ec-05eb-4c16-bb47-8d2b47a549f6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "C8liehSUzrZ9",
    "outputId": "4f4f9b87-a9aa-42fd-8a79-ad8a43db5f28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375085, 49)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/content/drive/My Drive/stock_model_data_v3.0.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "u332ZSM-zuhL",
    "outputId": "83dd5d54-dc47-4ff0-94fe-d6364aa41cb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>Date</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028324</td>\n",
       "      <td>-0.619374</td>\n",
       "      <td>-5.776217</td>\n",
       "      <td>-0.128374</td>\n",
       "      <td>-1.196622</td>\n",
       "      <td>-4.130699</td>\n",
       "      <td>-0.141451</td>\n",
       "      <td>-2.754825</td>\n",
       "      <td>16.118412</td>\n",
       "      <td>-0.141652</td>\n",
       "      <td>-2.832865</td>\n",
       "      <td>13.881013</td>\n",
       "      <td>-0.018553</td>\n",
       "      <td>44.654238</td>\n",
       "      <td>26.666771</td>\n",
       "      <td>21.389005</td>\n",
       "      <td>-10.691524</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-39802.853071</td>\n",
       "      <td>31.386050</td>\n",
       "      <td>-79.104469</td>\n",
       "      <td>28.299750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027104</td>\n",
       "      <td>-0.062579</td>\n",
       "      <td>-0.016417</td>\n",
       "      <td>0.162006</td>\n",
       "      <td>-0.296453</td>\n",
       "      <td>-0.168612</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>-0.017248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.594737</td>\n",
       "      <td>-0.959373</td>\n",
       "      <td>-6.527129</td>\n",
       "      <td>-0.463886</td>\n",
       "      <td>-1.540035</td>\n",
       "      <td>-4.473790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.305790</td>\n",
       "      <td>14.146333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.418809</td>\n",
       "      <td>12.393156</td>\n",
       "      <td>-0.011341</td>\n",
       "      <td>42.897735</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.444479</td>\n",
       "      <td>-14.204529</td>\n",
       "      <td>96.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>-44958.858662</td>\n",
       "      <td>40.888905</td>\n",
       "      <td>-79.166680</td>\n",
       "      <td>26.291190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063537</td>\n",
       "      <td>-0.115363</td>\n",
       "      <td>0.089180</td>\n",
       "      <td>0.357055</td>\n",
       "      <td>-0.329759</td>\n",
       "      <td>-0.249793</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>-0.079502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141833</td>\n",
       "      <td>-0.593041</td>\n",
       "      <td>-6.477486</td>\n",
       "      <td>-0.120266</td>\n",
       "      <td>-1.103674</td>\n",
       "      <td>-4.021913</td>\n",
       "      <td>-0.845066</td>\n",
       "      <td>-1.262260</td>\n",
       "      <td>14.100497</td>\n",
       "      <td>-0.852268</td>\n",
       "      <td>-1.278397</td>\n",
       "      <td>12.357963</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>44.082184</td>\n",
       "      <td>13.334165</td>\n",
       "      <td>13.333645</td>\n",
       "      <td>-11.835631</td>\n",
       "      <td>92.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>-49014.263402</td>\n",
       "      <td>41.359657</td>\n",
       "      <td>-74.999921</td>\n",
       "      <td>25.399437</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.084301</td>\n",
       "      <td>-0.110805</td>\n",
       "      <td>0.062925</td>\n",
       "      <td>0.333051</td>\n",
       "      <td>-0.227927</td>\n",
       "      <td>-0.189294</td>\n",
       "      <td>0.040711</td>\n",
       "      <td>-0.038782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.284095</td>\n",
       "      <td>-0.847463</td>\n",
       "      <td>-6.982913</td>\n",
       "      <td>-0.269718</td>\n",
       "      <td>-1.213539</td>\n",
       "      <td>-4.112059</td>\n",
       "      <td>-0.707223</td>\n",
       "      <td>-0.425535</td>\n",
       "      <td>16.033060</td>\n",
       "      <td>-0.712260</td>\n",
       "      <td>-0.427354</td>\n",
       "      <td>13.817665</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>43.118985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.444722</td>\n",
       "      <td>-13.762030</td>\n",
       "      <td>88.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>-51912.119485</td>\n",
       "      <td>39.205711</td>\n",
       "      <td>-78.260898</td>\n",
       "      <td>24.873025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.036456</td>\n",
       "      <td>-0.083404</td>\n",
       "      <td>0.068255</td>\n",
       "      <td>0.321459</td>\n",
       "      <td>-0.219496</td>\n",
       "      <td>-0.173907</td>\n",
       "      <td>0.054477</td>\n",
       "      <td>-0.040057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.541101</td>\n",
       "      <td>-2.293976</td>\n",
       "      <td>-8.773608</td>\n",
       "      <td>-1.325062</td>\n",
       "      <td>-2.548441</td>\n",
       "      <td>-5.511520</td>\n",
       "      <td>-2.266292</td>\n",
       "      <td>-3.765688</td>\n",
       "      <td>13.673796</td>\n",
       "      <td>-2.318844</td>\n",
       "      <td>-3.913041</td>\n",
       "      <td>12.028978</td>\n",
       "      <td>-0.013779</td>\n",
       "      <td>37.784663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.444722</td>\n",
       "      <td>-24.430673</td>\n",
       "      <td>100.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-58934.898772</td>\n",
       "      <td>39.488791</td>\n",
       "      <td>-95.238164</td>\n",
       "      <td>21.811585</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.018645</td>\n",
       "      <td>-0.037138</td>\n",
       "      <td>-0.025653</td>\n",
       "      <td>0.333212</td>\n",
       "      <td>-0.380410</td>\n",
       "      <td>-0.298181</td>\n",
       "      <td>0.070855</td>\n",
       "      <td>-0.092486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols        Date  bin_gain  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS  2015-03-17         0  ...    -0.168612     0.020377    -0.017248\n",
       "1  20MICRONS.NS  2015-03-18         1  ...    -0.249793     0.038237    -0.079502\n",
       "2  20MICRONS.NS  2015-03-19         0  ...    -0.189294     0.040711    -0.038782\n",
       "3  20MICRONS.NS  2015-03-20         0  ...    -0.173907     0.054477    -0.040057\n",
       "4  20MICRONS.NS  2015-03-23         1  ...    -0.298181     0.070855    -0.092486\n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "buvPetKpz66D"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:50000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117
    },
    "colab_type": "code",
    "id": "nJ9avml30L7U",
    "outputId": "03d52139-297b-4db6-cccf-b55be6898246"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>Date</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.028324</td>\n",
       "      <td>-0.619374</td>\n",
       "      <td>-5.776217</td>\n",
       "      <td>-0.128374</td>\n",
       "      <td>-1.196622</td>\n",
       "      <td>-4.130699</td>\n",
       "      <td>-0.141451</td>\n",
       "      <td>-2.754825</td>\n",
       "      <td>16.118412</td>\n",
       "      <td>-0.141652</td>\n",
       "      <td>-2.832865</td>\n",
       "      <td>13.881013</td>\n",
       "      <td>-0.018553</td>\n",
       "      <td>44.654238</td>\n",
       "      <td>26.666771</td>\n",
       "      <td>21.389005</td>\n",
       "      <td>-10.691524</td>\n",
       "      <td>100.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-39802.853071</td>\n",
       "      <td>31.38605</td>\n",
       "      <td>-79.104469</td>\n",
       "      <td>28.29975</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.027104</td>\n",
       "      <td>-0.062579</td>\n",
       "      <td>-0.016417</td>\n",
       "      <td>0.162006</td>\n",
       "      <td>-0.296453</td>\n",
       "      <td>-0.168612</td>\n",
       "      <td>0.020377</td>\n",
       "      <td>-0.017248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols        Date  bin_gain  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS  2015-03-17         0  ...    -0.168612     0.020377    -0.017248\n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df.iloc[0:1,:]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "sTlp7f8n0G2W",
    "outputId": "69140266-6faa-42c7-d80b-a4365a9a90d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df.iloc[0:1,:]\n",
    "def prepare_train(df):\n",
    "    global df_train\n",
    "    # if(len(df)<210):\n",
    "    #     return\n",
    "    df_subset=df[df[\"Date\"]<'2020-01-01']\n",
    "    df_train=df_train.append(df_subset)\n",
    "        \n",
    "df.iloc[1:,:].groupby('Symbols').apply(prepare_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "u9ZByKCs03jO",
    "outputId": "97bd6aa9-c96d-46a0-905b-62b7378fb784"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48478, 49)"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGVY3VeJ04z_"
   },
   "outputs": [],
   "source": [
    "symbols=df_train['Symbols']\n",
    "dates=df_train['Date']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df_train_scaled_values=scaler.fit_transform(df_train.iloc[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "bBmaMxzJ2C3Y",
    "outputId": "8d7a154a-886d-4c9e-bbaf-cacc55006928"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>Date</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389976</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.315688</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.346913</td>\n",
       "      <td>0.377649</td>\n",
       "      <td>0.288815</td>\n",
       "      <td>0.311172</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.670016</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>0.213890</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.501681</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.267385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.544408</td>\n",
       "      <td>0.334923</td>\n",
       "      <td>0.430139</td>\n",
       "      <td>0.394494</td>\n",
       "      <td>0.350173</td>\n",
       "      <td>0.509418</td>\n",
       "      <td>0.491746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385249</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>0.312051</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.375629</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.784833</td>\n",
       "      <td>0.861528</td>\n",
       "      <td>0.524370</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.501654</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.245844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592822</td>\n",
       "      <td>0.524141</td>\n",
       "      <td>0.375024</td>\n",
       "      <td>0.519810</td>\n",
       "      <td>0.372945</td>\n",
       "      <td>0.324383</td>\n",
       "      <td>0.522981</td>\n",
       "      <td>0.460014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389029</td>\n",
       "      <td>0.324269</td>\n",
       "      <td>0.312292</td>\n",
       "      <td>0.438550</td>\n",
       "      <td>0.347581</td>\n",
       "      <td>0.378290</td>\n",
       "      <td>0.285018</td>\n",
       "      <td>0.318089</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>0.524452</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.133342</td>\n",
       "      <td>0.133336</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>0.250001</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.525891</td>\n",
       "      <td>0.365054</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.438832</td>\n",
       "      <td>0.343603</td>\n",
       "      <td>0.524860</td>\n",
       "      <td>0.480770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387842</td>\n",
       "      <td>0.322645</td>\n",
       "      <td>0.309843</td>\n",
       "      <td>0.437002</td>\n",
       "      <td>0.346791</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.285762</td>\n",
       "      <td>0.321966</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.666711</td>\n",
       "      <td>0.795090</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.524496</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.501618</td>\n",
       "      <td>0.392057</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.230635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.602968</td>\n",
       "      <td>0.536412</td>\n",
       "      <td>0.367078</td>\n",
       "      <td>0.503445</td>\n",
       "      <td>0.444287</td>\n",
       "      <td>0.348491</td>\n",
       "      <td>0.535314</td>\n",
       "      <td>0.480119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377350</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.426072</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>0.369519</td>\n",
       "      <td>0.277349</td>\n",
       "      <td>0.306488</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.657406</td>\n",
       "      <td>0.783138</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>0.320076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.320076</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.197803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609640</td>\n",
       "      <td>0.554176</td>\n",
       "      <td>0.331416</td>\n",
       "      <td>0.508848</td>\n",
       "      <td>0.340172</td>\n",
       "      <td>0.309011</td>\n",
       "      <td>0.547752</td>\n",
       "      <td>0.453395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols        Date  bin_gain  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS  2015-03-17       0.0  ...     0.350173     0.509418     0.491746\n",
       "1  20MICRONS.NS  2015-03-18       1.0  ...     0.324383     0.522981     0.460014\n",
       "2  20MICRONS.NS  2015-03-19       0.0  ...     0.343603     0.524860     0.480770\n",
       "3  20MICRONS.NS  2015-03-20       0.0  ...     0.348491     0.535314     0.480119\n",
       "4  20MICRONS.NS  2015-03-23       1.0  ...     0.309011     0.547752     0.453395\n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled=pd.DataFrame(df_train_scaled_values,columns=df_train.columns[2:])\n",
    "df_train_scaled['Symbols']=symbols.values\n",
    "df_train_scaled['Date']=dates.values\n",
    "df_train_scaled=df_train_scaled[df_train.columns]\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "mB5c0TsS2N2i",
    "outputId": "b8cc428b-6d00-4440-a2de-bbc6921e385a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48478, 49)"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "osOClwKk4Eao",
    "outputId": "035bc962-2445-4e22-9e72-fc45009d9d53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47634, 15, 45)"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "y_train_names=[]\n",
    "def prepare_train_arr(df):\n",
    "    for i in range(15,len(df)):\n",
    "        X_train.append(df.iloc[i-15:i,4:].values)\n",
    "        y_train.append(df.iloc[i,4])\n",
    "        y_train_names.append(df.iloc[i,0])\n",
    "    \n",
    "df_train_scaled.groupby([\"Symbols\"]).apply(prepare_train_arr)\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "id": "aRZefJxS4gAq",
    "outputId": "43753ab6-6388-48cc-c56a-5bd7661e3184"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>Date</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389976</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.315688</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.346913</td>\n",
       "      <td>0.377649</td>\n",
       "      <td>0.288815</td>\n",
       "      <td>0.311172</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.670016</td>\n",
       "      <td>0.786842</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>0.213890</td>\n",
       "      <td>0.396049</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.501681</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.267385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606471</td>\n",
       "      <td>0.544408</td>\n",
       "      <td>0.334923</td>\n",
       "      <td>0.430139</td>\n",
       "      <td>0.394494</td>\n",
       "      <td>0.350173</td>\n",
       "      <td>0.509418</td>\n",
       "      <td>0.491746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385249</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>0.312051</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.375629</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>0.308619</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.784833</td>\n",
       "      <td>0.861528</td>\n",
       "      <td>0.524370</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.376623</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.501654</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.245844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.592822</td>\n",
       "      <td>0.524141</td>\n",
       "      <td>0.375024</td>\n",
       "      <td>0.519810</td>\n",
       "      <td>0.372945</td>\n",
       "      <td>0.324383</td>\n",
       "      <td>0.522981</td>\n",
       "      <td>0.460014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389029</td>\n",
       "      <td>0.324269</td>\n",
       "      <td>0.312292</td>\n",
       "      <td>0.438550</td>\n",
       "      <td>0.347581</td>\n",
       "      <td>0.378290</td>\n",
       "      <td>0.285018</td>\n",
       "      <td>0.318089</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.792172</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>0.524452</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.133342</td>\n",
       "      <td>0.133336</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>0.250001</td>\n",
       "      <td>0.236281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>0.525891</td>\n",
       "      <td>0.365054</td>\n",
       "      <td>0.508774</td>\n",
       "      <td>0.438832</td>\n",
       "      <td>0.343603</td>\n",
       "      <td>0.524860</td>\n",
       "      <td>0.480770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387842</td>\n",
       "      <td>0.322645</td>\n",
       "      <td>0.309843</td>\n",
       "      <td>0.437002</td>\n",
       "      <td>0.346791</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.285762</td>\n",
       "      <td>0.321966</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.666711</td>\n",
       "      <td>0.795090</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.524496</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.501618</td>\n",
       "      <td>0.392057</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.230635</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.602968</td>\n",
       "      <td>0.536412</td>\n",
       "      <td>0.367078</td>\n",
       "      <td>0.503445</td>\n",
       "      <td>0.444287</td>\n",
       "      <td>0.348491</td>\n",
       "      <td>0.535314</td>\n",
       "      <td>0.480119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>2015-03-23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377350</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.426072</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>0.369519</td>\n",
       "      <td>0.277349</td>\n",
       "      <td>0.306488</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.657406</td>\n",
       "      <td>0.783138</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>0.320076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.320076</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.197803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.609640</td>\n",
       "      <td>0.554176</td>\n",
       "      <td>0.331416</td>\n",
       "      <td>0.508848</td>\n",
       "      <td>0.340172</td>\n",
       "      <td>0.309011</td>\n",
       "      <td>0.547752</td>\n",
       "      <td>0.453395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols        Date  bin_gain  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS  2015-03-17       0.0  ...     0.350173     0.509418     0.491746\n",
       "1  20MICRONS.NS  2015-03-18       1.0  ...     0.324383     0.522981     0.460014\n",
       "2  20MICRONS.NS  2015-03-19       0.0  ...     0.343603     0.524860     0.480770\n",
       "3  20MICRONS.NS  2015-03-20       0.0  ...     0.348491     0.535314     0.480119\n",
       "4  20MICRONS.NS  2015-03-23       1.0  ...     0.309011     0.547752     0.453395\n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_symbols=df['Symbols']\n",
    "df_dates=df['Date']\n",
    "df_scaled_values=scaler.transform(df.iloc[:,2:])\n",
    "df_scaled=pd.DataFrame(df_scaled_values,columns=df.columns[2:])\n",
    "df_scaled['Symbols']=df_symbols.values\n",
    "df_scaled['Date']=df_dates.values\n",
    "df_scaled=df_scaled[df.columns]\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hEDq2I1z7RHb"
   },
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "y_test=[]\n",
    "y_test_names=[]\n",
    "def prepare_test(df):\n",
    "  if(not any(df.Date>'2020-01-01')):\n",
    "    return\n",
    "  start_index=np.where(df.Date>='2020-01-01')[0][0]\n",
    "\n",
    "  for i in range(start_index,len(df)):\n",
    "    if(i<15):\n",
    "      continue\n",
    "    X_test.append(df.iloc[i-15:i,4:].values)\n",
    "    y_test.append(df.iloc[i,4])\n",
    "    y_test_names.append(df.iloc[i,0])\n",
    " \n",
    "df_scaled.groupby([\"Symbols\"]).apply(prepare_test)\n",
    "X_test=np.array(X_test)\n",
    "X_test.shape\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "jqfMYPkq5Sc7",
    "outputId": "e7caecdf-1167-4828-9615-5f2abaa74f25"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    41462\n",
       "1.0     8538\n",
       "Name: bin_gain_2%, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled['bin_gain_2%'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1eVoFEASCS-S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dOVFHivPAaFt",
    "outputId": "303412ec-200d-4347-c880-491b5c0da434"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxlrDAO06Lam"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7gUnEbJ36NZd",
    "outputId": "c7d82fa5-3306-4e4e-c077-23a1791633c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "47634/47634 [==============================] - 27s 559us/step - loss: 0.1533 - binary_accuracy: 0.1758\n",
      "Epoch 2/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1522 - binary_accuracy: 0.1693\n",
      "Epoch 3/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1516 - binary_accuracy: 0.1700\n",
      "Epoch 4/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1515 - binary_accuracy: 0.1742\n",
      "Epoch 5/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1513 - binary_accuracy: 0.1770\n",
      "Epoch 6/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1509 - binary_accuracy: 0.1854\n",
      "Epoch 7/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1509 - binary_accuracy: 0.1912\n",
      "Epoch 8/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1507 - binary_accuracy: 0.1908\n",
      "Epoch 9/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1501 - binary_accuracy: 0.2095\n",
      "Epoch 10/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1501 - binary_accuracy: 0.2050\n",
      "Epoch 11/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1499 - binary_accuracy: 0.2080\n",
      "Epoch 12/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.1496 - binary_accuracy: 0.2079\n",
      "Epoch 13/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1495 - binary_accuracy: 0.2161\n",
      "Epoch 14/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1496 - binary_accuracy: 0.2098\n",
      "Epoch 15/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.1492 - binary_accuracy: 0.2195\n",
      "Epoch 16/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1490 - binary_accuracy: 0.2180\n",
      "Epoch 17/300\n",
      "47634/47634 [==============================] - 28s 591us/step - loss: 0.1492 - binary_accuracy: 0.2211\n",
      "Epoch 18/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.1491 - binary_accuracy: 0.2207\n",
      "Epoch 19/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.1489 - binary_accuracy: 0.2208\n",
      "Epoch 20/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.1490 - binary_accuracy: 0.2317\n",
      "Epoch 21/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.1489 - binary_accuracy: 0.2195\n",
      "Epoch 22/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1488 - binary_accuracy: 0.2342\n",
      "Epoch 23/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1489 - binary_accuracy: 0.2258\n",
      "Epoch 24/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1485 - binary_accuracy: 0.2336\n",
      "Epoch 25/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.1485 - binary_accuracy: 0.2388\n",
      "Epoch 26/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1484 - binary_accuracy: 0.2441\n",
      "Epoch 27/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1484 - binary_accuracy: 0.2347\n",
      "Epoch 28/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1480 - binary_accuracy: 0.2423\n",
      "Epoch 29/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1481 - binary_accuracy: 0.2419\n",
      "Epoch 30/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1477 - binary_accuracy: 0.2481\n",
      "Epoch 31/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1481 - binary_accuracy: 0.2452\n",
      "Epoch 32/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.1478 - binary_accuracy: 0.2514\n",
      "Epoch 33/300\n",
      "47634/47634 [==============================] - 26s 543us/step - loss: 0.1476 - binary_accuracy: 0.2547\n",
      "Epoch 34/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1473 - binary_accuracy: 0.2581\n",
      "Epoch 35/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.1475 - binary_accuracy: 0.2552\n",
      "Epoch 36/300\n",
      "47634/47634 [==============================] - 26s 543us/step - loss: 0.1473 - binary_accuracy: 0.2555\n",
      "Epoch 37/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.1471 - binary_accuracy: 0.2661\n",
      "Epoch 38/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1467 - binary_accuracy: 0.2610\n",
      "Epoch 39/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.1464 - binary_accuracy: 0.2693\n",
      "Epoch 40/300\n",
      "47634/47634 [==============================] - 30s 630us/step - loss: 0.1465 - binary_accuracy: 0.2714\n",
      "Epoch 41/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1464 - binary_accuracy: 0.2698\n",
      "Epoch 42/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1458 - binary_accuracy: 0.2839\n",
      "Epoch 43/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1459 - binary_accuracy: 0.2819\n",
      "Epoch 44/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1454 - binary_accuracy: 0.2818\n",
      "Epoch 45/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1451 - binary_accuracy: 0.2906\n",
      "Epoch 46/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1450 - binary_accuracy: 0.2962\n",
      "Epoch 47/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1448 - binary_accuracy: 0.2949\n",
      "Epoch 48/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.1441 - binary_accuracy: 0.3016\n",
      "Epoch 49/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1441 - binary_accuracy: 0.3099\n",
      "Epoch 50/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1441 - binary_accuracy: 0.2973\n",
      "Epoch 51/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1434 - binary_accuracy: 0.3138\n",
      "Epoch 52/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1438 - binary_accuracy: 0.3120\n",
      "Epoch 53/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1429 - binary_accuracy: 0.3162\n",
      "Epoch 54/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1425 - binary_accuracy: 0.3281\n",
      "Epoch 55/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1422 - binary_accuracy: 0.3290\n",
      "Epoch 56/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1414 - binary_accuracy: 0.3413\n",
      "Epoch 57/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1418 - binary_accuracy: 0.3357\n",
      "Epoch 58/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1410 - binary_accuracy: 0.3496\n",
      "Epoch 59/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1403 - binary_accuracy: 0.3545\n",
      "Epoch 60/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1402 - binary_accuracy: 0.3512\n",
      "Epoch 61/300\n",
      "47634/47634 [==============================] - 26s 548us/step - loss: 0.1400 - binary_accuracy: 0.3549\n",
      "Epoch 62/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1395 - binary_accuracy: 0.3611\n",
      "Epoch 63/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1390 - binary_accuracy: 0.3635\n",
      "Epoch 64/300\n",
      "47634/47634 [==============================] - 28s 589us/step - loss: 0.1397 - binary_accuracy: 0.3650\n",
      "Epoch 65/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1381 - binary_accuracy: 0.3746\n",
      "Epoch 66/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1380 - binary_accuracy: 0.3744\n",
      "Epoch 67/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1375 - binary_accuracy: 0.3763\n",
      "Epoch 68/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1365 - binary_accuracy: 0.3920\n",
      "Epoch 69/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1367 - binary_accuracy: 0.3893\n",
      "Epoch 70/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1359 - binary_accuracy: 0.3933\n",
      "Epoch 71/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1352 - binary_accuracy: 0.3993\n",
      "Epoch 72/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1351 - binary_accuracy: 0.3999\n",
      "Epoch 73/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1343 - binary_accuracy: 0.4118\n",
      "Epoch 74/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1342 - binary_accuracy: 0.4070\n",
      "Epoch 75/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1338 - binary_accuracy: 0.4107\n",
      "Epoch 76/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1332 - binary_accuracy: 0.4172\n",
      "Epoch 77/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1328 - binary_accuracy: 0.4198\n",
      "Epoch 78/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1322 - binary_accuracy: 0.4213\n",
      "Epoch 79/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1324 - binary_accuracy: 0.4283\n",
      "Epoch 80/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1321 - binary_accuracy: 0.4255\n",
      "Epoch 81/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1305 - binary_accuracy: 0.4429\n",
      "Epoch 82/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1298 - binary_accuracy: 0.4463\n",
      "Epoch 83/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1295 - binary_accuracy: 0.4449\n",
      "Epoch 84/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.1286 - binary_accuracy: 0.4477\n",
      "Epoch 85/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.1278 - binary_accuracy: 0.4545\n",
      "Epoch 86/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1285 - binary_accuracy: 0.4552\n",
      "Epoch 87/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1273 - binary_accuracy: 0.4588\n",
      "Epoch 88/300\n",
      "47634/47634 [==============================] - 28s 591us/step - loss: 0.1291 - binary_accuracy: 0.4521\n",
      "Epoch 89/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1264 - binary_accuracy: 0.4682\n",
      "Epoch 90/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.1263 - binary_accuracy: 0.4667\n",
      "Epoch 91/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1256 - binary_accuracy: 0.4737\n",
      "Epoch 92/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1247 - binary_accuracy: 0.4827\n",
      "Epoch 93/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1235 - binary_accuracy: 0.4915\n",
      "Epoch 94/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1251 - binary_accuracy: 0.4839\n",
      "Epoch 95/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.1236 - binary_accuracy: 0.4881\n",
      "Epoch 96/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1244 - binary_accuracy: 0.4848\n",
      "Epoch 97/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1224 - binary_accuracy: 0.4958\n",
      "Epoch 98/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.1227 - binary_accuracy: 0.4924\n",
      "Epoch 99/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1215 - binary_accuracy: 0.5018\n",
      "Epoch 100/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1213 - binary_accuracy: 0.5093\n",
      "Epoch 101/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1208 - binary_accuracy: 0.5078\n",
      "Epoch 102/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1197 - binary_accuracy: 0.5140\n",
      "Epoch 103/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1192 - binary_accuracy: 0.5176\n",
      "Epoch 104/300\n",
      "47634/47634 [==============================] - 27s 564us/step - loss: 0.1186 - binary_accuracy: 0.5240\n",
      "Epoch 105/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1194 - binary_accuracy: 0.5222\n",
      "Epoch 106/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1181 - binary_accuracy: 0.5252\n",
      "Epoch 107/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1176 - binary_accuracy: 0.5317\n",
      "Epoch 108/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1168 - binary_accuracy: 0.5319\n",
      "Epoch 109/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1155 - binary_accuracy: 0.5388\n",
      "Epoch 110/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1163 - binary_accuracy: 0.5398\n",
      "Epoch 111/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1158 - binary_accuracy: 0.5407\n",
      "Epoch 112/300\n",
      "47634/47634 [==============================] - 28s 588us/step - loss: 0.1148 - binary_accuracy: 0.5475\n",
      "Epoch 113/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1156 - binary_accuracy: 0.5394\n",
      "Epoch 114/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1133 - binary_accuracy: 0.5516\n",
      "Epoch 115/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1159 - binary_accuracy: 0.5391\n",
      "Epoch 116/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1132 - binary_accuracy: 0.5616\n",
      "Epoch 117/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1133 - binary_accuracy: 0.5541\n",
      "Epoch 118/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1119 - binary_accuracy: 0.5663\n",
      "Epoch 119/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1128 - binary_accuracy: 0.5605\n",
      "Epoch 120/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1109 - binary_accuracy: 0.5732\n",
      "Epoch 121/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1110 - binary_accuracy: 0.5756\n",
      "Epoch 122/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1108 - binary_accuracy: 0.5719\n",
      "Epoch 123/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1106 - binary_accuracy: 0.5739\n",
      "Epoch 124/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1101 - binary_accuracy: 0.5825\n",
      "Epoch 125/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1103 - binary_accuracy: 0.5777\n",
      "Epoch 126/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1080 - binary_accuracy: 0.5903\n",
      "Epoch 127/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.1096 - binary_accuracy: 0.5808\n",
      "Epoch 128/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1086 - binary_accuracy: 0.5887\n",
      "Epoch 129/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1085 - binary_accuracy: 0.5913\n",
      "Epoch 130/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.1079 - binary_accuracy: 0.5894\n",
      "Epoch 131/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1083 - binary_accuracy: 0.5910\n",
      "Epoch 132/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.1079 - binary_accuracy: 0.5948\n",
      "Epoch 133/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1074 - binary_accuracy: 0.5916\n",
      "Epoch 134/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1058 - binary_accuracy: 0.5972\n",
      "Epoch 135/300\n",
      "47634/47634 [==============================] - 26s 553us/step - loss: 0.1053 - binary_accuracy: 0.6003\n",
      "Epoch 136/300\n",
      "47634/47634 [==============================] - 27s 567us/step - loss: 0.1060 - binary_accuracy: 0.6020\n",
      "Epoch 137/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1065 - binary_accuracy: 0.6051\n",
      "Epoch 138/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.1036 - binary_accuracy: 0.6157\n",
      "Epoch 139/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1042 - binary_accuracy: 0.6102\n",
      "Epoch 140/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1039 - binary_accuracy: 0.6146\n",
      "Epoch 141/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.1045 - binary_accuracy: 0.6066\n",
      "Epoch 142/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1044 - binary_accuracy: 0.6126\n",
      "Epoch 143/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.1026 - binary_accuracy: 0.6180\n",
      "Epoch 144/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1031 - binary_accuracy: 0.6186\n",
      "Epoch 145/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.1033 - binary_accuracy: 0.6167\n",
      "Epoch 146/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1006 - binary_accuracy: 0.6318\n",
      "Epoch 147/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.1026 - binary_accuracy: 0.6211\n",
      "Epoch 148/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1014 - binary_accuracy: 0.6237\n",
      "Epoch 149/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.1006 - binary_accuracy: 0.6323\n",
      "Epoch 150/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0994 - binary_accuracy: 0.6360\n",
      "Epoch 151/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0990 - binary_accuracy: 0.6401\n",
      "Epoch 152/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0991 - binary_accuracy: 0.6422\n",
      "Epoch 153/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0995 - binary_accuracy: 0.6395\n",
      "Epoch 154/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.1001 - binary_accuracy: 0.6364\n",
      "Epoch 155/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0990 - binary_accuracy: 0.6426\n",
      "Epoch 156/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0982 - binary_accuracy: 0.6424\n",
      "Epoch 157/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0986 - binary_accuracy: 0.6423\n",
      "Epoch 158/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0980 - binary_accuracy: 0.6505\n",
      "Epoch 159/300\n",
      "47634/47634 [==============================] - 28s 590us/step - loss: 0.0962 - binary_accuracy: 0.6512\n",
      "Epoch 160/300\n",
      "47634/47634 [==============================] - 25s 529us/step - loss: 0.0990 - binary_accuracy: 0.6424\n",
      "Epoch 161/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0980 - binary_accuracy: 0.6465\n",
      "Epoch 162/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0970 - binary_accuracy: 0.6544\n",
      "Epoch 163/300\n",
      "47634/47634 [==============================] - 25s 529us/step - loss: 0.0976 - binary_accuracy: 0.6497\n",
      "Epoch 164/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.0949 - binary_accuracy: 0.6633\n",
      "Epoch 165/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.0962 - binary_accuracy: 0.6538\n",
      "Epoch 166/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0960 - binary_accuracy: 0.6594\n",
      "Epoch 167/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.0959 - binary_accuracy: 0.6588\n",
      "Epoch 168/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0952 - binary_accuracy: 0.6609\n",
      "Epoch 169/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0952 - binary_accuracy: 0.6617\n",
      "Epoch 170/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0948 - binary_accuracy: 0.6628\n",
      "Epoch 171/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0954 - binary_accuracy: 0.6624\n",
      "Epoch 172/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0955 - binary_accuracy: 0.6622\n",
      "Epoch 173/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0938 - binary_accuracy: 0.6683\n",
      "Epoch 174/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0917 - binary_accuracy: 0.6762\n",
      "Epoch 175/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0926 - binary_accuracy: 0.6742\n",
      "Epoch 176/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0948 - binary_accuracy: 0.6677\n",
      "Epoch 177/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0935 - binary_accuracy: 0.6694\n",
      "Epoch 178/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0912 - binary_accuracy: 0.6806\n",
      "Epoch 179/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0908 - binary_accuracy: 0.6814\n",
      "Epoch 180/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0919 - binary_accuracy: 0.6801\n",
      "Epoch 181/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0905 - binary_accuracy: 0.6802\n",
      "Epoch 182/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.0942 - binary_accuracy: 0.6716\n",
      "Epoch 183/300\n",
      "47634/47634 [==============================] - 28s 587us/step - loss: 0.0904 - binary_accuracy: 0.6837\n",
      "Epoch 184/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.0909 - binary_accuracy: 0.6826\n",
      "Epoch 185/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0901 - binary_accuracy: 0.6881\n",
      "Epoch 186/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0918 - binary_accuracy: 0.6812\n",
      "Epoch 187/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.0902 - binary_accuracy: 0.6865\n",
      "Epoch 188/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0889 - binary_accuracy: 0.6912\n",
      "Epoch 189/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0886 - binary_accuracy: 0.6949\n",
      "Epoch 190/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0890 - binary_accuracy: 0.6932\n",
      "Epoch 191/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0887 - binary_accuracy: 0.6923\n",
      "Epoch 192/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0877 - binary_accuracy: 0.6991\n",
      "Epoch 193/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0883 - binary_accuracy: 0.6951\n",
      "Epoch 194/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.0889 - binary_accuracy: 0.6943\n",
      "Epoch 195/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0896 - binary_accuracy: 0.6915\n",
      "Epoch 196/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0880 - binary_accuracy: 0.7002\n",
      "Epoch 197/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0868 - binary_accuracy: 0.7016\n",
      "Epoch 198/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.0881 - binary_accuracy: 0.6948\n",
      "Epoch 199/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0902 - binary_accuracy: 0.6882\n",
      "Epoch 200/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0880 - binary_accuracy: 0.6972\n",
      "Epoch 201/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0871 - binary_accuracy: 0.7028\n",
      "Epoch 202/300\n",
      "47634/47634 [==============================] - 26s 543us/step - loss: 0.0879 - binary_accuracy: 0.6979\n",
      "Epoch 203/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0885 - binary_accuracy: 0.6931\n",
      "Epoch 204/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0855 - binary_accuracy: 0.7061\n",
      "Epoch 205/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0852 - binary_accuracy: 0.7106\n",
      "Epoch 206/300\n",
      "47634/47634 [==============================] - 26s 546us/step - loss: 0.0869 - binary_accuracy: 0.7042\n",
      "Epoch 207/300\n",
      "47634/47634 [==============================] - 30s 621us/step - loss: 0.0854 - binary_accuracy: 0.7080\n",
      "Epoch 208/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0857 - binary_accuracy: 0.7110\n",
      "Epoch 209/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0853 - binary_accuracy: 0.7078\n",
      "Epoch 210/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0856 - binary_accuracy: 0.7110\n",
      "Epoch 211/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.0841 - binary_accuracy: 0.7141\n",
      "Epoch 212/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0854 - binary_accuracy: 0.7097\n",
      "Epoch 213/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0826 - binary_accuracy: 0.7205\n",
      "Epoch 214/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0859 - binary_accuracy: 0.7093\n",
      "Epoch 215/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0837 - binary_accuracy: 0.7157\n",
      "Epoch 216/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0842 - binary_accuracy: 0.7174\n",
      "Epoch 217/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0829 - binary_accuracy: 0.7181\n",
      "Epoch 218/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0823 - binary_accuracy: 0.7254\n",
      "Epoch 219/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0830 - binary_accuracy: 0.7213\n",
      "Epoch 220/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0835 - binary_accuracy: 0.7185\n",
      "Epoch 221/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0829 - binary_accuracy: 0.7231\n",
      "Epoch 222/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0833 - binary_accuracy: 0.7198\n",
      "Epoch 223/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0831 - binary_accuracy: 0.7220\n",
      "Epoch 224/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0816 - binary_accuracy: 0.7283\n",
      "Epoch 225/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0817 - binary_accuracy: 0.7289\n",
      "Epoch 226/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0802 - binary_accuracy: 0.7325\n",
      "Epoch 227/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0824 - binary_accuracy: 0.7256\n",
      "Epoch 228/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0797 - binary_accuracy: 0.7336\n",
      "Epoch 229/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0812 - binary_accuracy: 0.7266\n",
      "Epoch 230/300\n",
      "47634/47634 [==============================] - 26s 545us/step - loss: 0.0797 - binary_accuracy: 0.7360\n",
      "Epoch 231/300\n",
      "47634/47634 [==============================] - 29s 604us/step - loss: 0.0814 - binary_accuracy: 0.7321\n",
      "Epoch 232/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0797 - binary_accuracy: 0.7365\n",
      "Epoch 233/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0819 - binary_accuracy: 0.7284\n",
      "Epoch 234/300\n",
      "47634/47634 [==============================] - 25s 531us/step - loss: 0.0790 - binary_accuracy: 0.7362\n",
      "Epoch 235/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0819 - binary_accuracy: 0.7297\n",
      "Epoch 236/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0815 - binary_accuracy: 0.7301\n",
      "Epoch 237/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0783 - binary_accuracy: 0.7423\n",
      "Epoch 238/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0791 - binary_accuracy: 0.7421\n",
      "Epoch 239/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.0777 - binary_accuracy: 0.7432\n",
      "Epoch 240/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0797 - binary_accuracy: 0.7377\n",
      "Epoch 241/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0780 - binary_accuracy: 0.7464\n",
      "Epoch 242/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0785 - binary_accuracy: 0.7435\n",
      "Epoch 243/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0787 - binary_accuracy: 0.7435\n",
      "Epoch 244/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0821 - binary_accuracy: 0.7244\n",
      "Epoch 245/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0776 - binary_accuracy: 0.7461\n",
      "Epoch 246/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0795 - binary_accuracy: 0.7403\n",
      "Epoch 247/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0778 - binary_accuracy: 0.7442\n",
      "Epoch 248/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0763 - binary_accuracy: 0.7515\n",
      "Epoch 249/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0782 - binary_accuracy: 0.7438\n",
      "Epoch 250/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0785 - binary_accuracy: 0.7445\n",
      "Epoch 251/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0778 - binary_accuracy: 0.7471\n",
      "Epoch 252/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0760 - binary_accuracy: 0.7544\n",
      "Epoch 253/300\n",
      "47634/47634 [==============================] - 26s 535us/step - loss: 0.0793 - binary_accuracy: 0.7460\n",
      "Epoch 254/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.0757 - binary_accuracy: 0.7550\n",
      "Epoch 255/300\n",
      "47634/47634 [==============================] - 29s 604us/step - loss: 0.0772 - binary_accuracy: 0.7516\n",
      "Epoch 256/300\n",
      "47634/47634 [==============================] - 25s 532us/step - loss: 0.0749 - binary_accuracy: 0.7573\n",
      "Epoch 257/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0753 - binary_accuracy: 0.7550\n",
      "Epoch 258/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0770 - binary_accuracy: 0.7549\n",
      "Epoch 259/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0747 - binary_accuracy: 0.7581\n",
      "Epoch 260/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0753 - binary_accuracy: 0.7579\n",
      "Epoch 261/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.0759 - binary_accuracy: 0.7586\n",
      "Epoch 262/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.0769 - binary_accuracy: 0.7504\n",
      "Epoch 263/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.0752 - binary_accuracy: 0.7595\n",
      "Epoch 264/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.0737 - binary_accuracy: 0.7611\n",
      "Epoch 265/300\n",
      "47634/47634 [==============================] - 26s 543us/step - loss: 0.0745 - binary_accuracy: 0.7595\n",
      "Epoch 266/300\n",
      "47634/47634 [==============================] - 26s 545us/step - loss: 0.0757 - binary_accuracy: 0.7591\n",
      "Epoch 267/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.0741 - binary_accuracy: 0.7630\n",
      "Epoch 268/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0732 - binary_accuracy: 0.7670\n",
      "Epoch 269/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0740 - binary_accuracy: 0.7658\n",
      "Epoch 270/300\n",
      "47634/47634 [==============================] - 25s 530us/step - loss: 0.0767 - binary_accuracy: 0.7542\n",
      "Epoch 271/300\n",
      "47634/47634 [==============================] - 25s 525us/step - loss: 0.0743 - binary_accuracy: 0.7664\n",
      "Epoch 272/300\n",
      "47634/47634 [==============================] - 25s 525us/step - loss: 0.0730 - binary_accuracy: 0.7645\n",
      "Epoch 273/300\n",
      "47634/47634 [==============================] - 25s 523us/step - loss: 0.0729 - binary_accuracy: 0.7675\n",
      "Epoch 274/300\n",
      "47634/47634 [==============================] - 25s 523us/step - loss: 0.0723 - binary_accuracy: 0.7680\n",
      "Epoch 275/300\n",
      "47634/47634 [==============================] - 25s 524us/step - loss: 0.0758 - binary_accuracy: 0.7568\n",
      "Epoch 276/300\n",
      "47634/47634 [==============================] - 30s 623us/step - loss: 0.0724 - binary_accuracy: 0.7706\n",
      "Epoch 277/300\n",
      "47634/47634 [==============================] - 25s 533us/step - loss: 0.0738 - binary_accuracy: 0.7639\n",
      "Epoch 278/300\n",
      "47634/47634 [==============================] - 28s 595us/step - loss: 0.0747 - binary_accuracy: 0.7621\n",
      "Epoch 279/300\n",
      "47634/47634 [==============================] - 26s 539us/step - loss: 0.0724 - binary_accuracy: 0.7696\n",
      "Epoch 280/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0724 - binary_accuracy: 0.7689\n",
      "Epoch 281/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0721 - binary_accuracy: 0.7738\n",
      "Epoch 282/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0716 - binary_accuracy: 0.7731\n",
      "Epoch 283/300\n",
      "47634/47634 [==============================] - 26s 541us/step - loss: 0.0731 - binary_accuracy: 0.7661\n",
      "Epoch 284/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0730 - binary_accuracy: 0.7715\n",
      "Epoch 285/300\n",
      "47634/47634 [==============================] - 25s 534us/step - loss: 0.0734 - binary_accuracy: 0.7642\n",
      "Epoch 286/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0711 - binary_accuracy: 0.7763\n",
      "Epoch 287/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0712 - binary_accuracy: 0.7756\n",
      "Epoch 288/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0721 - binary_accuracy: 0.7721\n",
      "Epoch 289/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0708 - binary_accuracy: 0.7781\n",
      "Epoch 290/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0721 - binary_accuracy: 0.7749\n",
      "Epoch 291/300\n",
      "47634/47634 [==============================] - 26s 540us/step - loss: 0.0708 - binary_accuracy: 0.7759\n",
      "Epoch 292/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0698 - binary_accuracy: 0.7814\n",
      "Epoch 293/300\n",
      "47634/47634 [==============================] - 26s 538us/step - loss: 0.0736 - binary_accuracy: 0.7682\n",
      "Epoch 294/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0699 - binary_accuracy: 0.7796\n",
      "Epoch 295/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0698 - binary_accuracy: 0.7804\n",
      "Epoch 296/300\n",
      "47634/47634 [==============================] - 25s 535us/step - loss: 0.0709 - binary_accuracy: 0.7769\n",
      "Epoch 297/300\n",
      "47634/47634 [==============================] - 26s 536us/step - loss: 0.0705 - binary_accuracy: 0.7777\n",
      "Epoch 298/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0699 - binary_accuracy: 0.7805\n",
      "Epoch 299/300\n",
      "47634/47634 [==============================] - 26s 542us/step - loss: 0.0699 - binary_accuracy: 0.7835\n",
      "Epoch 300/300\n",
      "47634/47634 [==============================] - 26s 537us/step - loss: 0.0687 - binary_accuracy: 0.7837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff40395ce80>"
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, nb_epoch=300,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "g-AbkfXJ7bK0",
    "outputId": "4ac79900-e790-4554-f4a2-f050ace83706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0003055 , 0.00025514, 0.0011147 , ..., 0.09624344, 0.00836724,\n",
       "       0.00727639], dtype=float32)"
      ]
     },
     "execution_count": 207,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_prediction_probab=model.predict_proba(X_train).reshape(1,-1)[0]\n",
    "train_prediction_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "TY1j6x5Z78zN",
    "outputId": "fb2b184f-50d2-462e-ba28-3253a62a94e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Recall')"
      ]
     },
     "execution_count": 208,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "precision,recall,threshold=precision_recall_curve(y_train,train_prediction_probab)\n",
    "plt.plot(recall,precision,marker='.')\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.xlabel(\"Recall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JUt4cdESA4Vs",
    "outputId": "53c9aa91-97d8-4d3b-d2a5-636449b2eebf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     2, ..., 20220, 20222, 20223]),)"
      ]
     },
     "execution_count": 211,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(precision<0.90)\n",
    "# threshold[16854]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "b5EyKHxeBf4l",
    "outputId": "4d367415-1f8f-4cf5-f0d1-a8a0f37b69d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>37952</td>\n",
       "      <td>1633</td>\n",
       "      <td>39585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>1954</td>\n",
       "      <td>6095</td>\n",
       "      <td>8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>39906</td>\n",
       "      <td>7728</td>\n",
       "      <td>47634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0     1    All\n",
       "True                         \n",
       "0.0        37952  1633  39585\n",
       "1.0         1954  6095   8049\n",
       "All        39906  7728  47634"
      ]
     },
     "execution_count": 199,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pred=[1 if i>=0.90 else 0 for i in train_prediction_probab]\n",
    "from sklearn.metrics import precision_score,accuracy_score,classification_report\n",
    "pd.crosstab(y_train, np.array(train_pred), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "MUmoPoqCEusy",
    "outputId": "a5de56a2-14af-47b9-96fc-8ccdad8bb3fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     39585\n",
      "         1.0       0.79      0.76      0.77      8049\n",
      "\n",
      "    accuracy                           0.92     47634\n",
      "   macro avg       0.87      0.86      0.86     47634\n",
      "weighted avg       0.92      0.92      0.92     47634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,np.array(train_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "lpJ1G3hr9MVx",
    "outputId": "4f851cc4-f07f-4991-a7d8-1871ddc250b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1054</td>\n",
       "      <td>153</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>253</td>\n",
       "      <td>47</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1307</td>\n",
       "      <td>200</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0    1   All\n",
       "True                      \n",
       "0.0        1054  153  1207\n",
       "1.0         253   47   300\n",
       "All        1307  200  1507"
      ]
     },
     "execution_count": 205,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction_probab=model.predict_proba(X_test).reshape(1,-1)[0]\n",
    "test_pred=[1 if i>=0.90 else 0 for i in test_prediction_probab]\n",
    "pd.crosstab(y_test, np.array(test_pred), rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "tCjSZtSN_6hc",
    "outputId": "b6bd5345-fe6d-428d-f00d-29283f3d0311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.87      0.84      1207\n",
      "         1.0       0.23      0.16      0.19       300\n",
      "\n",
      "    accuracy                           0.73      1507\n",
      "   macro avg       0.52      0.51      0.51      1507\n",
      "weighted avg       0.69      0.73      0.71      1507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,np.array(test_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "bX7YNXpr6g3X",
    "outputId": "9189d161-6016-4dbd-a84a-792d9409ac2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.4794651384909265\n",
      "Train Accuracy is  0.8165805936935803\n",
      "(47634,) (47634,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>30865</td>\n",
       "      <td>8720</td>\n",
       "      <td>39585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>17</td>\n",
       "      <td>8032</td>\n",
       "      <td>8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>30882</td>\n",
       "      <td>16752</td>\n",
       "      <td>47634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        30865   8720  39585\n",
       "1.0           17   8032   8049\n",
       "All        30882  16752  47634"
      ]
     },
     "execution_count": 131,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)\n",
    "\n",
    "print(y_train.shape,y_predicted.shape)\n",
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "lT19sQomhq1b",
    "outputId": "de5def92-4e78-4985-c0be-8ca416c80cfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.23299319727891157\n",
      "Test Accuracy is  0.5925680159256802\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>756</td>\n",
       "      <td>451</td>\n",
       "      <td>1207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>163</td>\n",
       "      <td>137</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>919</td>\n",
       "      <td>588</td>\n",
       "      <td>1507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1   All\n",
       "True                     \n",
       "0.0        756  451  1207\n",
       "1.0        163  137   300\n",
       "All        919  588  1507"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)\n",
    "\n",
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPTZF9SkiDSo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4IvDjiZmqC9I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ha4Dkia_riof"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Marker-3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
