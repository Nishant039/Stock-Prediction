{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "id": "Jju4A6se1yt_",
    "outputId": "688b96ee-2612-40af-e565-48a50e289c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GwwP_K0J3AOJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oC5jUbJg5V82"
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('/content/drive/My Drive/stock_model_data_v3.0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cL3rLePy6HlF",
    "outputId": "c41f4a9c-2000-4d52-de11-83445c414a1e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1375085, 49)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "colab_type": "code",
    "id": "HFp7xGHH6QjW",
    "outputId": "51884fd9-4542-4c73-e810-e4631fb30581"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-03-17', '2015-03-18', '2015-03-19', '2015-03-20',\n",
       "               '2015-03-23', '2015-03-24', '2015-03-25', '2015-03-26',\n",
       "               '2015-03-27', '2015-03-30',\n",
       "               ...\n",
       "               '2020-02-06', '2020-02-07', '2020-02-10', '2020-02-11',\n",
       "               '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-17',\n",
       "               '2020-02-18', '2020-02-19'],\n",
       "              dtype='datetime64[ns]', name='Date', length=1375085, freq=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(\"Date\",inplace=True)\n",
    "df.index=pd.to_datetime(df.index)\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fAikBONt6R-5"
   },
   "outputs": [],
   "source": [
    "df=df.iloc[:70000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "colab_type": "code",
    "id": "tZS6oVVe6WD0",
    "outputId": "7ff46d70-bc10-4527-9398-5cf9e3ed282d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=df.iloc[0:1,:]\n",
    "def prepare_train(df):\n",
    "    global df_train\n",
    "    if(len(df)<110):\n",
    "        return\n",
    "    temp=df.iloc[:(len(df)-50),:]\n",
    "    df_train=df_train.append(temp)\n",
    "        \n",
    "df.iloc[1:,:].groupby('Symbols').apply(prepare_train)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Eimm0cQL6YI8",
    "outputId": "f870a8a8-af8d-49a0-8c43-b6c1b2723bdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66143, 48)"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MFAGY2BY6a5W"
   },
   "outputs": [],
   "source": [
    "symbols=df_train['Symbols']\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df_train_scaled_values=scaler.fit_transform(df_train.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "Fp-uE_Ij6f54",
    "outputId": "0cff7403-7631-4b79-a3a8-e43134e88f8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389976</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.315688</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.346913</td>\n",
       "      <td>0.377649</td>\n",
       "      <td>0.288815</td>\n",
       "      <td>0.289324</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.670016</td>\n",
       "      <td>0.731595</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>0.213890</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.501681</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.263301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388508</td>\n",
       "      <td>0.333363</td>\n",
       "      <td>0.548892</td>\n",
       "      <td>0.712064</td>\n",
       "      <td>0.557186</td>\n",
       "      <td>0.308617</td>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.604795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385249</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>0.312051</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.375629</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>0.286690</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.729065</td>\n",
       "      <td>0.861528</td>\n",
       "      <td>0.524370</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.501654</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.241850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379764</td>\n",
       "      <td>0.320953</td>\n",
       "      <td>0.576092</td>\n",
       "      <td>0.761647</td>\n",
       "      <td>0.541427</td>\n",
       "      <td>0.281178</td>\n",
       "      <td>0.564579</td>\n",
       "      <td>0.580121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389029</td>\n",
       "      <td>0.324269</td>\n",
       "      <td>0.312292</td>\n",
       "      <td>0.438550</td>\n",
       "      <td>0.347581</td>\n",
       "      <td>0.378290</td>\n",
       "      <td>0.285018</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>0.524452</td>\n",
       "      <td>0.444681</td>\n",
       "      <td>0.133342</td>\n",
       "      <td>0.133336</td>\n",
       "      <td>0.444681</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>0.250001</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374781</td>\n",
       "      <td>0.322024</td>\n",
       "      <td>0.569329</td>\n",
       "      <td>0.755545</td>\n",
       "      <td>0.589611</td>\n",
       "      <td>0.301626</td>\n",
       "      <td>0.566294</td>\n",
       "      <td>0.596260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387842</td>\n",
       "      <td>0.322645</td>\n",
       "      <td>0.309843</td>\n",
       "      <td>0.437002</td>\n",
       "      <td>0.346791</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.285762</td>\n",
       "      <td>0.300460</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.666711</td>\n",
       "      <td>0.741981</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.524496</td>\n",
       "      <td>0.434162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.434162</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.501618</td>\n",
       "      <td>0.392057</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.226705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386264</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.570702</td>\n",
       "      <td>0.752598</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.306828</td>\n",
       "      <td>0.575836</td>\n",
       "      <td>0.595755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377350</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.426072</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>0.369519</td>\n",
       "      <td>0.277349</td>\n",
       "      <td>0.284491</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.657406</td>\n",
       "      <td>0.726931</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.194009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390538</td>\n",
       "      <td>0.339344</td>\n",
       "      <td>0.546513</td>\n",
       "      <td>0.755586</td>\n",
       "      <td>0.517460</td>\n",
       "      <td>0.264823</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>0.574975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols  bin_gain  bin_gain_1%  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS       0.0          0.0  ...     0.308617     0.552198     0.604795\n",
       "1  20MICRONS.NS       1.0          0.0  ...     0.281178     0.564579     0.580121\n",
       "2  20MICRONS.NS       0.0          0.0  ...     0.301626     0.566294     0.596260\n",
       "3  20MICRONS.NS       0.0          0.0  ...     0.306828     0.575836     0.595755\n",
       "4  20MICRONS.NS       1.0          0.0  ...     0.264823     0.587189     0.574975\n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled=pd.DataFrame(df_train_scaled_values,columns=df_train.columns[1:])\n",
    "df_train_scaled['Symbols']=symbols.values\n",
    "df_train_scaled=df_train_scaled[df_train.columns]\n",
    "df_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FFXFFAV76iR5",
    "outputId": "e8ddc75b-3ce5-46af-c282-88f0e9afa686"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66143, 48)"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-E-2HPe-6kZG",
    "outputId": "21cbbfc5-71b1-462d-c00f-07e1474ce9dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62393, 50, 45)"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "def prepare_train_arr(df):\n",
    "    for i in range(50,len(df)):\n",
    "        X_train.append(df.iloc[i-50:i,3:].values)\n",
    "        y_train.append(df.iloc[i,3])\n",
    "    \n",
    "df_train_scaled.groupby([\"Symbols\"]).apply(prepare_train_arr)\n",
    "X_train=np.array(X_train)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "HvqziaHu6oBR",
    "outputId": "a42c14cc-8a3e-47ca-dc7f-fd305d51a1ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbols</th>\n",
       "      <th>bin_gain</th>\n",
       "      <th>bin_gain_1%</th>\n",
       "      <th>bin_gain_2%</th>\n",
       "      <th>SMA_PCH5</th>\n",
       "      <th>SMA_PCH15</th>\n",
       "      <th>SMA_PCH50</th>\n",
       "      <th>EMA_PCH5</th>\n",
       "      <th>EMA_PCH15</th>\n",
       "      <th>EMA_PCH50</th>\n",
       "      <th>ROC5</th>\n",
       "      <th>ROC15</th>\n",
       "      <th>ROC50</th>\n",
       "      <th>MOM_PCH5</th>\n",
       "      <th>MOM_PCH15</th>\n",
       "      <th>MOM_PCH50</th>\n",
       "      <th>macdhist</th>\n",
       "      <th>RSI</th>\n",
       "      <th>StochK</th>\n",
       "      <th>StochD</th>\n",
       "      <th>CMO</th>\n",
       "      <th>AroonUp</th>\n",
       "      <th>AroonDown</th>\n",
       "      <th>ChaikinAD</th>\n",
       "      <th>MFI</th>\n",
       "      <th>WillR</th>\n",
       "      <th>ULTOS</th>\n",
       "      <th>MA_BIN5</th>\n",
       "      <th>MA_BIN15</th>\n",
       "      <th>MA_BIN50</th>\n",
       "      <th>EMA_BIN5</th>\n",
       "      <th>EMA_BIN15</th>\n",
       "      <th>EMA_BIN50</th>\n",
       "      <th>ROC_BIN5</th>\n",
       "      <th>ROC_BIN15</th>\n",
       "      <th>ROC_BIN50</th>\n",
       "      <th>MOM_BIN5</th>\n",
       "      <th>MOM_BIN15</th>\n",
       "      <th>MOM_BIN50</th>\n",
       "      <th>macd_BIN</th>\n",
       "      <th>Beta_DOW</th>\n",
       "      <th>Beta_NDQ</th>\n",
       "      <th>Beta_NKK</th>\n",
       "      <th>Beta_NFTY</th>\n",
       "      <th>Beta_EURINR</th>\n",
       "      <th>Beta_GBPINR</th>\n",
       "      <th>Beta_USDINR</th>\n",
       "      <th>Beta_JPYINR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389976</td>\n",
       "      <td>0.324101</td>\n",
       "      <td>0.315688</td>\n",
       "      <td>0.438466</td>\n",
       "      <td>0.346913</td>\n",
       "      <td>0.377649</td>\n",
       "      <td>0.288815</td>\n",
       "      <td>0.289324</td>\n",
       "      <td>0.109555</td>\n",
       "      <td>0.670016</td>\n",
       "      <td>0.731595</td>\n",
       "      <td>0.864214</td>\n",
       "      <td>0.524334</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>0.266668</td>\n",
       "      <td>0.213890</td>\n",
       "      <td>0.450929</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.501681</td>\n",
       "      <td>0.313860</td>\n",
       "      <td>0.208955</td>\n",
       "      <td>0.263301</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388508</td>\n",
       "      <td>0.333363</td>\n",
       "      <td>0.548892</td>\n",
       "      <td>0.712064</td>\n",
       "      <td>0.557186</td>\n",
       "      <td>0.308617</td>\n",
       "      <td>0.552198</td>\n",
       "      <td>0.604795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.385249</td>\n",
       "      <td>0.321931</td>\n",
       "      <td>0.312051</td>\n",
       "      <td>0.434991</td>\n",
       "      <td>0.344444</td>\n",
       "      <td>0.375629</td>\n",
       "      <td>0.289578</td>\n",
       "      <td>0.286690</td>\n",
       "      <td>0.107360</td>\n",
       "      <td>0.670837</td>\n",
       "      <td>0.729065</td>\n",
       "      <td>0.861528</td>\n",
       "      <td>0.524370</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144445</td>\n",
       "      <td>0.431746</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.501654</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.241850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.379764</td>\n",
       "      <td>0.320953</td>\n",
       "      <td>0.576092</td>\n",
       "      <td>0.761647</td>\n",
       "      <td>0.541427</td>\n",
       "      <td>0.281178</td>\n",
       "      <td>0.564579</td>\n",
       "      <td>0.580121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389029</td>\n",
       "      <td>0.324269</td>\n",
       "      <td>0.312292</td>\n",
       "      <td>0.438550</td>\n",
       "      <td>0.347581</td>\n",
       "      <td>0.378290</td>\n",
       "      <td>0.285018</td>\n",
       "      <td>0.296460</td>\n",
       "      <td>0.107309</td>\n",
       "      <td>0.665900</td>\n",
       "      <td>0.738307</td>\n",
       "      <td>0.861464</td>\n",
       "      <td>0.524452</td>\n",
       "      <td>0.444681</td>\n",
       "      <td>0.133342</td>\n",
       "      <td>0.133336</td>\n",
       "      <td>0.444681</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.501633</td>\n",
       "      <td>0.413597</td>\n",
       "      <td>0.250001</td>\n",
       "      <td>0.232326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.374781</td>\n",
       "      <td>0.322024</td>\n",
       "      <td>0.569329</td>\n",
       "      <td>0.755545</td>\n",
       "      <td>0.589611</td>\n",
       "      <td>0.301626</td>\n",
       "      <td>0.566294</td>\n",
       "      <td>0.596260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.387842</td>\n",
       "      <td>0.322645</td>\n",
       "      <td>0.309843</td>\n",
       "      <td>0.437002</td>\n",
       "      <td>0.346791</td>\n",
       "      <td>0.377759</td>\n",
       "      <td>0.285762</td>\n",
       "      <td>0.300460</td>\n",
       "      <td>0.109460</td>\n",
       "      <td>0.666711</td>\n",
       "      <td>0.741981</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.524496</td>\n",
       "      <td>0.434162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.434162</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.501618</td>\n",
       "      <td>0.392057</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.226705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.386264</td>\n",
       "      <td>0.328467</td>\n",
       "      <td>0.570702</td>\n",
       "      <td>0.752598</td>\n",
       "      <td>0.593600</td>\n",
       "      <td>0.306828</td>\n",
       "      <td>0.575836</td>\n",
       "      <td>0.595755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20MICRONS.NS</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.377350</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.426072</td>\n",
       "      <td>0.337193</td>\n",
       "      <td>0.369519</td>\n",
       "      <td>0.277349</td>\n",
       "      <td>0.284491</td>\n",
       "      <td>0.106834</td>\n",
       "      <td>0.657406</td>\n",
       "      <td>0.726931</td>\n",
       "      <td>0.860870</td>\n",
       "      <td>0.524358</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.501581</td>\n",
       "      <td>0.394888</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.194009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390538</td>\n",
       "      <td>0.339344</td>\n",
       "      <td>0.546513</td>\n",
       "      <td>0.755586</td>\n",
       "      <td>0.517460</td>\n",
       "      <td>0.264823</td>\n",
       "      <td>0.587189</td>\n",
       "      <td>0.574975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Symbols  bin_gain  bin_gain_1%  ...  Beta_GBPINR  Beta_USDINR  Beta_JPYINR\n",
       "0  20MICRONS.NS       0.0          0.0  ...     0.308617     0.552198     0.604795\n",
       "1  20MICRONS.NS       1.0          0.0  ...     0.281178     0.564579     0.580121\n",
       "2  20MICRONS.NS       0.0          0.0  ...     0.301626     0.566294     0.596260\n",
       "3  20MICRONS.NS       0.0          0.0  ...     0.306828     0.575836     0.595755\n",
       "4  20MICRONS.NS       1.0          0.0  ...     0.264823     0.587189     0.574975\n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_symbols=df['Symbols']\n",
    "df_scaled_values=scaler.transform(df.iloc[:,1:])\n",
    "df_scaled=pd.DataFrame(df_scaled_values,columns=df.columns[1:])\n",
    "df_scaled['Symbols']=df_symbols.values\n",
    "df_scaled=df_scaled[df.columns]\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4RIAVmiE6xLu",
    "outputId": "38acff5d-53aa-41e7-ffad-bcd16ba0469c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 48)"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aTdFY6GQ60Bl",
    "outputId": "67a1a134-a26a-4942-d3c5-7bb108173c7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3750, 50, 45)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=[]\n",
    "y_test=[]\n",
    "def prepare_test(df):\n",
    "    if(len(df)<110):\n",
    "        return\n",
    "    for i in range(len(df)-50,len(df)):\n",
    "        X_test.append(df.iloc[i-50:i,3:].values)\n",
    "        y_test.append(df.iloc[i,3])\n",
    "df_scaled.groupby([\"Symbols\"]).apply(prepare_test)\n",
    "X_test=np.array(X_test)\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VT00eNE664gM"
   },
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)\n",
    "y_test=np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XM-KudDo67x9",
    "outputId": "9f90d6e2-f41c-4cba-ec00-d729d616407c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "mOeKyA6O6_qj",
    "outputId": "b185b470-7b46-4e1a-db3c-63436aa4cd0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    58121\n",
       "1    11879\n",
       "Name: bin_gain_2%, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['bin_gain_2%'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ghF3MiS57BWQ"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "J8JMvj1e7GYd",
    "outputId": "f186555d-92d2-4585-8514-470a2eb42900"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62393/62393 [==============================] - 62s 989us/step - loss: 0.1528 - binary_accuracy: 0.1724\n",
      "Epoch 2/100\n",
      "62393/62393 [==============================] - 59s 943us/step - loss: 0.1520 - binary_accuracy: 0.1682\n",
      "Epoch 3/100\n",
      "62393/62393 [==============================] - 58s 928us/step - loss: 0.1511 - binary_accuracy: 0.1751\n",
      "Epoch 4/100\n",
      "62393/62393 [==============================] - 58s 928us/step - loss: 0.1505 - binary_accuracy: 0.1887\n",
      "Epoch 5/100\n",
      "62393/62393 [==============================] - 57s 919us/step - loss: 0.1500 - binary_accuracy: 0.2053\n",
      "Epoch 6/100\n",
      "62393/62393 [==============================] - 58s 925us/step - loss: 0.1494 - binary_accuracy: 0.2209\n",
      "Epoch 7/100\n",
      "62393/62393 [==============================] - 58s 928us/step - loss: 0.1493 - binary_accuracy: 0.2240\n",
      "Epoch 8/100\n",
      "62393/62393 [==============================] - 58s 930us/step - loss: 0.1491 - binary_accuracy: 0.2218\n",
      "Epoch 9/100\n",
      "62393/62393 [==============================] - 57s 912us/step - loss: 0.1490 - binary_accuracy: 0.2277\n",
      "Epoch 10/100\n",
      "62393/62393 [==============================] - 57s 918us/step - loss: 0.1486 - binary_accuracy: 0.2336\n",
      "Epoch 11/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1485 - binary_accuracy: 0.2454\n",
      "Epoch 12/100\n",
      "62393/62393 [==============================] - 58s 922us/step - loss: 0.1485 - binary_accuracy: 0.2305\n",
      "Epoch 13/100\n",
      "62393/62393 [==============================] - 58s 926us/step - loss: 0.1482 - binary_accuracy: 0.2460\n",
      "Epoch 14/100\n",
      "62393/62393 [==============================] - 58s 925us/step - loss: 0.1480 - binary_accuracy: 0.2439\n",
      "Epoch 15/100\n",
      "62393/62393 [==============================] - 58s 922us/step - loss: 0.1480 - binary_accuracy: 0.2509\n",
      "Epoch 16/100\n",
      "62393/62393 [==============================] - 58s 923us/step - loss: 0.1479 - binary_accuracy: 0.2502\n",
      "Epoch 17/100\n",
      "62393/62393 [==============================] - 57s 920us/step - loss: 0.1478 - binary_accuracy: 0.2490\n",
      "Epoch 18/100\n",
      "62393/62393 [==============================] - 58s 924us/step - loss: 0.1476 - binary_accuracy: 0.2549\n",
      "Epoch 19/100\n",
      "62393/62393 [==============================] - 58s 922us/step - loss: 0.1479 - binary_accuracy: 0.2466\n",
      "Epoch 20/100\n",
      "62393/62393 [==============================] - 57s 917us/step - loss: 0.1475 - binary_accuracy: 0.2537\n",
      "Epoch 21/100\n",
      "62393/62393 [==============================] - 57s 914us/step - loss: 0.1475 - binary_accuracy: 0.2550\n",
      "Epoch 22/100\n",
      "62393/62393 [==============================] - 57s 911us/step - loss: 0.1472 - binary_accuracy: 0.2632\n",
      "Epoch 23/100\n",
      "62393/62393 [==============================] - 57s 911us/step - loss: 0.1470 - binary_accuracy: 0.2634\n",
      "Epoch 24/100\n",
      "62393/62393 [==============================] - 58s 928us/step - loss: 0.1470 - binary_accuracy: 0.2642\n",
      "Epoch 25/100\n",
      "62393/62393 [==============================] - 57s 909us/step - loss: 0.1468 - binary_accuracy: 0.2803\n",
      "Epoch 26/100\n",
      "62393/62393 [==============================] - 57s 918us/step - loss: 0.1469 - binary_accuracy: 0.2716\n",
      "Epoch 27/100\n",
      "62393/62393 [==============================] - 57s 917us/step - loss: 0.1467 - binary_accuracy: 0.2710\n",
      "Epoch 28/100\n",
      "62393/62393 [==============================] - 57s 915us/step - loss: 0.1465 - binary_accuracy: 0.2749\n",
      "Epoch 29/100\n",
      "62393/62393 [==============================] - 57s 913us/step - loss: 0.1465 - binary_accuracy: 0.2761\n",
      "Epoch 30/100\n",
      "62393/62393 [==============================] - 58s 933us/step - loss: 0.1463 - binary_accuracy: 0.2795\n",
      "Epoch 31/100\n",
      "62393/62393 [==============================] - 59s 943us/step - loss: 0.1464 - binary_accuracy: 0.2849\n",
      "Epoch 32/100\n",
      "62393/62393 [==============================] - 59s 944us/step - loss: 0.1458 - binary_accuracy: 0.2927\n",
      "Epoch 33/100\n",
      "62393/62393 [==============================] - 57s 909us/step - loss: 0.1459 - binary_accuracy: 0.2925\n",
      "Epoch 34/100\n",
      "62393/62393 [==============================] - 60s 957us/step - loss: 0.1458 - binary_accuracy: 0.2935\n",
      "Epoch 35/100\n",
      "62393/62393 [==============================] - 57s 917us/step - loss: 0.1454 - binary_accuracy: 0.3009\n",
      "Epoch 36/100\n",
      "62393/62393 [==============================] - 57s 921us/step - loss: 0.1450 - binary_accuracy: 0.3034\n",
      "Epoch 37/100\n",
      "62393/62393 [==============================] - 57s 920us/step - loss: 0.1450 - binary_accuracy: 0.2991\n",
      "Epoch 38/100\n",
      "62393/62393 [==============================] - 57s 921us/step - loss: 0.1448 - binary_accuracy: 0.3082\n",
      "Epoch 39/100\n",
      "62393/62393 [==============================] - 57s 917us/step - loss: 0.1443 - binary_accuracy: 0.3084\n",
      "Epoch 40/100\n",
      "62393/62393 [==============================] - 58s 930us/step - loss: 0.1445 - binary_accuracy: 0.3120\n",
      "Epoch 41/100\n",
      "62393/62393 [==============================] - 59s 940us/step - loss: 0.1438 - binary_accuracy: 0.3269\n",
      "Epoch 42/100\n",
      "62393/62393 [==============================] - 59s 943us/step - loss: 0.1438 - binary_accuracy: 0.3218\n",
      "Epoch 43/100\n",
      "62393/62393 [==============================] - 58s 924us/step - loss: 0.1436 - binary_accuracy: 0.3193\n",
      "Epoch 44/100\n",
      "62393/62393 [==============================] - 57s 909us/step - loss: 0.1432 - binary_accuracy: 0.3223\n",
      "Epoch 45/100\n",
      "62393/62393 [==============================] - 57s 907us/step - loss: 0.1430 - binary_accuracy: 0.3286\n",
      "Epoch 46/100\n",
      "62393/62393 [==============================] - 58s 929us/step - loss: 0.1424 - binary_accuracy: 0.3279\n",
      "Epoch 47/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1425 - binary_accuracy: 0.3323\n",
      "Epoch 48/100\n",
      "62393/62393 [==============================] - 57s 913us/step - loss: 0.1418 - binary_accuracy: 0.3402\n",
      "Epoch 49/100\n",
      "62393/62393 [==============================] - 57s 915us/step - loss: 0.1416 - binary_accuracy: 0.3447\n",
      "Epoch 50/100\n",
      "62393/62393 [==============================] - 57s 920us/step - loss: 0.1411 - binary_accuracy: 0.3449\n",
      "Epoch 51/100\n",
      "62393/62393 [==============================] - 58s 930us/step - loss: 0.1410 - binary_accuracy: 0.3490\n",
      "Epoch 52/100\n",
      "62393/62393 [==============================] - 59s 941us/step - loss: 0.1400 - binary_accuracy: 0.3523\n",
      "Epoch 53/100\n",
      "62393/62393 [==============================] - 60s 963us/step - loss: 0.1400 - binary_accuracy: 0.3567\n",
      "Epoch 54/100\n",
      "62393/62393 [==============================] - 59s 948us/step - loss: 0.1401 - binary_accuracy: 0.3608\n",
      "Epoch 55/100\n",
      "62393/62393 [==============================] - 57s 912us/step - loss: 0.1393 - binary_accuracy: 0.3641\n",
      "Epoch 56/100\n",
      "62393/62393 [==============================] - 61s 970us/step - loss: 0.1394 - binary_accuracy: 0.3633\n",
      "Epoch 57/100\n",
      "62393/62393 [==============================] - 59s 938us/step - loss: 0.1381 - binary_accuracy: 0.3769\n",
      "Epoch 58/100\n",
      "62393/62393 [==============================] - 59s 952us/step - loss: 0.1385 - binary_accuracy: 0.3706\n",
      "Epoch 59/100\n",
      "62393/62393 [==============================] - 59s 940us/step - loss: 0.1375 - binary_accuracy: 0.3756\n",
      "Epoch 60/100\n",
      "62393/62393 [==============================] - 58s 933us/step - loss: 0.1372 - binary_accuracy: 0.3780\n",
      "Epoch 61/100\n",
      "62393/62393 [==============================] - 58s 932us/step - loss: 0.1370 - binary_accuracy: 0.3811\n",
      "Epoch 62/100\n",
      "62393/62393 [==============================] - 60s 967us/step - loss: 0.1362 - binary_accuracy: 0.3937\n",
      "Epoch 63/100\n",
      "62393/62393 [==============================] - 59s 939us/step - loss: 0.1350 - binary_accuracy: 0.3959\n",
      "Epoch 64/100\n",
      "62393/62393 [==============================] - 58s 936us/step - loss: 0.1352 - binary_accuracy: 0.3978\n",
      "Epoch 65/100\n",
      "62393/62393 [==============================] - 58s 925us/step - loss: 0.1350 - binary_accuracy: 0.3943\n",
      "Epoch 66/100\n",
      "62393/62393 [==============================] - 58s 931us/step - loss: 0.1347 - binary_accuracy: 0.3989\n",
      "Epoch 67/100\n",
      "62393/62393 [==============================] - 58s 928us/step - loss: 0.1335 - binary_accuracy: 0.4070\n",
      "Epoch 68/100\n",
      "62393/62393 [==============================] - 58s 935us/step - loss: 0.1340 - binary_accuracy: 0.3998\n",
      "Epoch 69/100\n",
      "62393/62393 [==============================] - 58s 927us/step - loss: 0.1332 - binary_accuracy: 0.4114\n",
      "Epoch 70/100\n",
      "62393/62393 [==============================] - 57s 909us/step - loss: 0.1336 - binary_accuracy: 0.4087\n",
      "Epoch 71/100\n",
      "62393/62393 [==============================] - 57s 906us/step - loss: 0.1336 - binary_accuracy: 0.4048\n",
      "Epoch 72/100\n",
      "62393/62393 [==============================] - 56s 903us/step - loss: 0.1320 - binary_accuracy: 0.4176\n",
      "Epoch 73/100\n",
      "62393/62393 [==============================] - 57s 919us/step - loss: 0.1312 - binary_accuracy: 0.4229\n",
      "Epoch 74/100\n",
      "62393/62393 [==============================] - 57s 914us/step - loss: 0.1312 - binary_accuracy: 0.4236\n",
      "Epoch 75/100\n",
      "62393/62393 [==============================] - 57s 912us/step - loss: 0.1302 - binary_accuracy: 0.4293\n",
      "Epoch 76/100\n",
      "62393/62393 [==============================] - 56s 905us/step - loss: 0.1303 - binary_accuracy: 0.4325\n",
      "Epoch 77/100\n",
      "62393/62393 [==============================] - 57s 919us/step - loss: 0.1300 - binary_accuracy: 0.4328\n",
      "Epoch 78/100\n",
      "62393/62393 [==============================] - 58s 922us/step - loss: 0.1297 - binary_accuracy: 0.4395\n",
      "Epoch 79/100\n",
      "62393/62393 [==============================] - 57s 919us/step - loss: 0.1288 - binary_accuracy: 0.4428\n",
      "Epoch 80/100\n",
      "62393/62393 [==============================] - 56s 905us/step - loss: 0.1281 - binary_accuracy: 0.4467\n",
      "Epoch 81/100\n",
      "62393/62393 [==============================] - 57s 908us/step - loss: 0.1287 - binary_accuracy: 0.4454\n",
      "Epoch 82/100\n",
      "62393/62393 [==============================] - 57s 913us/step - loss: 0.1269 - binary_accuracy: 0.4565\n",
      "Epoch 83/100\n",
      "62393/62393 [==============================] - 57s 919us/step - loss: 0.1279 - binary_accuracy: 0.4489\n",
      "Epoch 84/100\n",
      "62393/62393 [==============================] - 57s 914us/step - loss: 0.1265 - binary_accuracy: 0.4572\n",
      "Epoch 85/100\n",
      "62393/62393 [==============================] - 57s 913us/step - loss: 0.1263 - binary_accuracy: 0.4634\n",
      "Epoch 86/100\n",
      "62393/62393 [==============================] - 57s 920us/step - loss: 0.1263 - binary_accuracy: 0.4552\n",
      "Epoch 87/100\n",
      "62393/62393 [==============================] - 57s 918us/step - loss: 0.1263 - binary_accuracy: 0.4601\n",
      "Epoch 88/100\n",
      "62393/62393 [==============================] - 57s 914us/step - loss: 0.1249 - binary_accuracy: 0.4691\n",
      "Epoch 89/100\n",
      "62393/62393 [==============================] - 57s 910us/step - loss: 0.1251 - binary_accuracy: 0.4739\n",
      "Epoch 90/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1235 - binary_accuracy: 0.4769\n",
      "Epoch 91/100\n",
      "62393/62393 [==============================] - 57s 913us/step - loss: 0.1239 - binary_accuracy: 0.4788\n",
      "Epoch 92/100\n",
      "62393/62393 [==============================] - 57s 909us/step - loss: 0.1234 - binary_accuracy: 0.4842\n",
      "Epoch 93/100\n",
      "62393/62393 [==============================] - 58s 924us/step - loss: 0.1235 - binary_accuracy: 0.4785\n",
      "Epoch 94/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1231 - binary_accuracy: 0.4886\n",
      "Epoch 95/100\n",
      "62393/62393 [==============================] - 57s 915us/step - loss: 0.1226 - binary_accuracy: 0.4868\n",
      "Epoch 96/100\n",
      "62393/62393 [==============================] - 57s 914us/step - loss: 0.1216 - binary_accuracy: 0.4911\n",
      "Epoch 97/100\n",
      "62393/62393 [==============================] - 57s 918us/step - loss: 0.1215 - binary_accuracy: 0.4927\n",
      "Epoch 98/100\n",
      "62393/62393 [==============================] - 57s 915us/step - loss: 0.1214 - binary_accuracy: 0.4921\n",
      "Epoch 99/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1215 - binary_accuracy: 0.4917\n",
      "Epoch 100/100\n",
      "62393/62393 [==============================] - 57s 916us/step - loss: 0.1197 - binary_accuracy: 0.5060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f039ea5c828>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, nb_epoch=100,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c4OjhWJX7KXg",
    "outputId": "24ebcb11-90f4-4357-c058-0cfd55bddd3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.1877818778187782\n",
      "Test Accuracy is  0.4176\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "13TzX1gLWEDX",
    "outputId": "a4243307-db58-4e11-a6d2-392904ff9bc6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1108</td>\n",
       "      <td>1981</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>203</td>\n",
       "      <td>458</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1311</td>\n",
       "      <td>2439</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        1108  1981  3089\n",
       "1.0         203   458   661\n",
       "All        1311  2439  3750"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "T7w_QcJtTimK",
    "outputId": "240a3a9b-edfb-48ab-efc0-36f039c8da5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.36      0.50      3089\n",
      "         1.0       0.19      0.69      0.30       661\n",
      "\n",
      "    accuracy                           0.42      3750\n",
      "   macro avg       0.52      0.53      0.40      3750\n",
      "weighted avg       0.73      0.42      0.47      3750\n",
      "\n",
      "      0     1\n",
      "0  1108  1981\n",
      "1   203   458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_predicted))\n",
    "print(pd.DataFrame(confusion_matrix(y_test, y_predicted),columns=['0','1'],index=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "gHkbBmsdMHVv",
    "outputId": "1fcccc69-ca3e-44cc-f8ab-12c7e183c59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.25149788822316077\n",
      "Train Accuracy is  0.5076531021108137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "C0IVpQkZUmPs",
    "outputId": "d84061ae-dedf-4321-c2d1-1704bab281b5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>21432</td>\n",
       "      <td>30482</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>237</td>\n",
       "      <td>10242</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>21669</td>\n",
       "      <td>40724</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        21432  30482  51914\n",
       "1.0          237  10242  10479\n",
       "All        21669  40724  62393"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "bbW-WVAPRoP4",
    "outputId": "60ea4b2e-0f38-4924-d05a-78e512274071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.41      0.58     51914\n",
      "         1.0       0.25      0.98      0.40     10479\n",
      "\n",
      "    accuracy                           0.51     62393\n",
      "   macro avg       0.62      0.70      0.49     62393\n",
      "weighted avg       0.87      0.51      0.55     62393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5mnRKAOtSgdd"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "optimizer=optimizers.Adam(lr=0.005)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "q4AQSSbIXaZc",
    "outputId": "296da5ca-15c6-486f-df8d-8cdcf076d4c3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1348 - binary_accuracy: 0.4306\n",
      "Epoch 2/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1342 - binary_accuracy: 0.4358\n",
      "Epoch 3/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1347 - binary_accuracy: 0.4350\n",
      "Epoch 4/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1342 - binary_accuracy: 0.4375\n",
      "Epoch 5/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1333 - binary_accuracy: 0.4449\n",
      "Epoch 6/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1345 - binary_accuracy: 0.4396\n",
      "Epoch 7/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1343 - binary_accuracy: 0.4402\n",
      "Epoch 8/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1336 - binary_accuracy: 0.4420\n",
      "Epoch 9/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1334 - binary_accuracy: 0.4416\n",
      "Epoch 10/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1330 - binary_accuracy: 0.4506\n",
      "Epoch 11/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1331 - binary_accuracy: 0.4476\n",
      "Epoch 12/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1340 - binary_accuracy: 0.4359\n",
      "Epoch 13/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1328 - binary_accuracy: 0.4472\n",
      "Epoch 14/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1325 - binary_accuracy: 0.4507\n",
      "Epoch 15/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1324 - binary_accuracy: 0.4462\n",
      "Epoch 16/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1320 - binary_accuracy: 0.4509\n",
      "Epoch 17/100\n",
      "62393/62393 [==============================] - 98s 2ms/step - loss: 0.1316 - binary_accuracy: 0.4591\n",
      "Epoch 18/100\n",
      "62393/62393 [==============================] - 99s 2ms/step - loss: 0.1316 - binary_accuracy: 0.4569\n",
      "Epoch 19/100\n",
      "62393/62393 [==============================] - 99s 2ms/step - loss: 0.1316 - binary_accuracy: 0.4609\n",
      "Epoch 20/100\n",
      "62393/62393 [==============================] - 98s 2ms/step - loss: 0.1310 - binary_accuracy: 0.4658\n",
      "Epoch 21/100\n",
      "62393/62393 [==============================] - 97s 2ms/step - loss: 0.1313 - binary_accuracy: 0.4663\n",
      "Epoch 22/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1315 - binary_accuracy: 0.4585\n",
      "Epoch 23/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1305 - binary_accuracy: 0.4714\n",
      "Epoch 24/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1303 - binary_accuracy: 0.4753\n",
      "Epoch 25/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1296 - binary_accuracy: 0.4712\n",
      "Epoch 26/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1301 - binary_accuracy: 0.4722\n",
      "Epoch 27/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1296 - binary_accuracy: 0.4763\n",
      "Epoch 28/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1287 - binary_accuracy: 0.4787\n",
      "Epoch 29/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1301 - binary_accuracy: 0.4650\n",
      "Epoch 30/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1290 - binary_accuracy: 0.4782\n",
      "Epoch 31/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1288 - binary_accuracy: 0.4743\n",
      "Epoch 32/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1289 - binary_accuracy: 0.4804\n",
      "Epoch 33/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1281 - binary_accuracy: 0.4838\n",
      "Epoch 34/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1286 - binary_accuracy: 0.4807\n",
      "Epoch 35/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1277 - binary_accuracy: 0.4846\n",
      "Epoch 36/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1279 - binary_accuracy: 0.4838\n",
      "Epoch 37/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1277 - binary_accuracy: 0.4857\n",
      "Epoch 38/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1279 - binary_accuracy: 0.4857\n",
      "Epoch 39/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1271 - binary_accuracy: 0.4905\n",
      "Epoch 40/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1277 - binary_accuracy: 0.4858\n",
      "Epoch 41/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1271 - binary_accuracy: 0.4932\n",
      "Epoch 42/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1273 - binary_accuracy: 0.4853\n",
      "Epoch 43/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1266 - binary_accuracy: 0.4964\n",
      "Epoch 44/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1269 - binary_accuracy: 0.4902\n",
      "Epoch 45/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1265 - binary_accuracy: 0.4933\n",
      "Epoch 46/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1269 - binary_accuracy: 0.4924\n",
      "Epoch 47/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1261 - binary_accuracy: 0.4956\n",
      "Epoch 48/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1267 - binary_accuracy: 0.4912\n",
      "Epoch 49/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1267 - binary_accuracy: 0.4971\n",
      "Epoch 50/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1256 - binary_accuracy: 0.5024\n",
      "Epoch 51/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1249 - binary_accuracy: 0.5077\n",
      "Epoch 52/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1262 - binary_accuracy: 0.4954\n",
      "Epoch 53/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1253 - binary_accuracy: 0.5066\n",
      "Epoch 54/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1259 - binary_accuracy: 0.5014\n",
      "Epoch 55/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1254 - binary_accuracy: 0.5026\n",
      "Epoch 56/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1260 - binary_accuracy: 0.5046\n",
      "Epoch 57/100\n",
      "62393/62393 [==============================] - 98s 2ms/step - loss: 0.1253 - binary_accuracy: 0.5008\n",
      "Epoch 58/100\n",
      "62393/62393 [==============================] - 97s 2ms/step - loss: 0.1248 - binary_accuracy: 0.5082\n",
      "Epoch 59/100\n",
      "62393/62393 [==============================] - 98s 2ms/step - loss: 0.1254 - binary_accuracy: 0.5000\n",
      "Epoch 60/100\n",
      "62393/62393 [==============================] - 97s 2ms/step - loss: 0.1250 - binary_accuracy: 0.5061\n",
      "Epoch 61/100\n",
      "62393/62393 [==============================] - 97s 2ms/step - loss: 0.1236 - binary_accuracy: 0.5193\n",
      "Epoch 62/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1250 - binary_accuracy: 0.5081\n",
      "Epoch 63/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1241 - binary_accuracy: 0.5127\n",
      "Epoch 64/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1240 - binary_accuracy: 0.5089\n",
      "Epoch 65/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1233 - binary_accuracy: 0.5157\n",
      "Epoch 66/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1241 - binary_accuracy: 0.5104\n",
      "Epoch 67/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1245 - binary_accuracy: 0.5079\n",
      "Epoch 68/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1233 - binary_accuracy: 0.5210\n",
      "Epoch 69/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1232 - binary_accuracy: 0.5146\n",
      "Epoch 70/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1234 - binary_accuracy: 0.5198\n",
      "Epoch 71/100\n",
      "62393/62393 [==============================] - 96s 2ms/step - loss: 0.1228 - binary_accuracy: 0.5227\n",
      "Epoch 72/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1228 - binary_accuracy: 0.5168\n",
      "Epoch 73/100\n",
      "62393/62393 [==============================] - 95s 2ms/step - loss: 0.1226 - binary_accuracy: 0.5218\n",
      "Epoch 74/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1247 - binary_accuracy: 0.5130\n",
      "Epoch 75/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1219 - binary_accuracy: 0.5245\n",
      "Epoch 76/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1232 - binary_accuracy: 0.5188\n",
      "Epoch 77/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1231 - binary_accuracy: 0.5214\n",
      "Epoch 78/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1225 - binary_accuracy: 0.5245\n",
      "Epoch 79/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1226 - binary_accuracy: 0.5222\n",
      "Epoch 80/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1219 - binary_accuracy: 0.5285\n",
      "Epoch 81/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1213 - binary_accuracy: 0.5304\n",
      "Epoch 82/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1205 - binary_accuracy: 0.5329\n",
      "Epoch 83/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1216 - binary_accuracy: 0.5336\n",
      "Epoch 84/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1213 - binary_accuracy: 0.5307\n",
      "Epoch 85/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1200 - binary_accuracy: 0.5377\n",
      "Epoch 86/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1215 - binary_accuracy: 0.5352\n",
      "Epoch 87/100\n",
      "62393/62393 [==============================] - 94s 1ms/step - loss: 0.1213 - binary_accuracy: 0.5325\n",
      "Epoch 88/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1211 - binary_accuracy: 0.5347\n",
      "Epoch 89/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1211 - binary_accuracy: 0.5366\n",
      "Epoch 90/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1199 - binary_accuracy: 0.5376\n",
      "Epoch 91/100\n",
      "62393/62393 [==============================] - 92s 1ms/step - loss: 0.1209 - binary_accuracy: 0.5323\n",
      "Epoch 92/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1200 - binary_accuracy: 0.5468\n",
      "Epoch 93/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1197 - binary_accuracy: 0.5469\n",
      "Epoch 94/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1199 - binary_accuracy: 0.5465\n",
      "Epoch 95/100\n",
      "62393/62393 [==============================] - 94s 2ms/step - loss: 0.1192 - binary_accuracy: 0.5474\n",
      "Epoch 96/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1195 - binary_accuracy: 0.5459\n",
      "Epoch 97/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1203 - binary_accuracy: 0.5369\n",
      "Epoch 98/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1198 - binary_accuracy: 0.5448\n",
      "Epoch 99/100\n",
      "62393/62393 [==============================] - 93s 1ms/step - loss: 0.1191 - binary_accuracy: 0.5422\n",
      "Epoch 100/100\n",
      "62393/62393 [==============================] - 92s 1ms/step - loss: 0.1190 - binary_accuracy: 0.5497\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f039c69b0f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=300, nb_epoch=100,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hprLompDXgqy",
    "outputId": "e92ff789-8479-4f7b-b47f-6f3b17093de2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.18862275449101795\n",
      "Test Accuracy is  0.43546666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "4e05eQFY4lH9",
    "outputId": "b4842b48-1a0e-4adb-f31f-6bbf4374633e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1192</td>\n",
       "      <td>1897</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>220</td>\n",
       "      <td>441</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1412</td>\n",
       "      <td>2338</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        1192  1897  3089\n",
       "1.0         220   441   661\n",
       "All        1412  2338  3750"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SVB7ggw84wdq"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.20,\n",
    "               1:0.80}\n",
    "optimizer=optimizers.Adam(lr=0.005)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "nyLKNuQs5IaU",
    "outputId": "277ae6a4-92fd-41a1-95f2-f9b357cc631a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2070 - binary_accuracy: 0.8117\n",
      "Epoch 2/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2067 - binary_accuracy: 0.8274\n",
      "Epoch 3/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.2052 - binary_accuracy: 0.7756\n",
      "Epoch 4/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2036 - binary_accuracy: 0.7404\n",
      "Epoch 5/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2022 - binary_accuracy: 0.7310\n",
      "Epoch 6/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2016 - binary_accuracy: 0.7375\n",
      "Epoch 7/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2014 - binary_accuracy: 0.7404\n",
      "Epoch 8/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.2011 - binary_accuracy: 0.7343\n",
      "Epoch 9/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.2008 - binary_accuracy: 0.7335\n",
      "Epoch 10/100\n",
      "62393/62393 [==============================] - 62s 999us/step - loss: 0.2008 - binary_accuracy: 0.7317\n",
      "Epoch 11/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2004 - binary_accuracy: 0.7453\n",
      "Epoch 12/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2006 - binary_accuracy: 0.7357\n",
      "Epoch 13/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2004 - binary_accuracy: 0.7353\n",
      "Epoch 14/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2005 - binary_accuracy: 0.7405\n",
      "Epoch 15/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2005 - binary_accuracy: 0.7350\n",
      "Epoch 16/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1999 - binary_accuracy: 0.7303\n",
      "Epoch 17/100\n",
      "62393/62393 [==============================] - 62s 999us/step - loss: 0.2001 - binary_accuracy: 0.7353\n",
      "Epoch 18/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.2000 - binary_accuracy: 0.7387\n",
      "Epoch 19/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1998 - binary_accuracy: 0.7358\n",
      "Epoch 20/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1998 - binary_accuracy: 0.7312\n",
      "Epoch 21/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1997 - binary_accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1996 - binary_accuracy: 0.7373\n",
      "Epoch 23/100\n",
      "62393/62393 [==============================] - 62s 1000us/step - loss: 0.1996 - binary_accuracy: 0.7302\n",
      "Epoch 24/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.1995 - binary_accuracy: 0.7375\n",
      "Epoch 25/100\n",
      "62393/62393 [==============================] - 62s 996us/step - loss: 0.1991 - binary_accuracy: 0.7315\n",
      "Epoch 26/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1989 - binary_accuracy: 0.7335\n",
      "Epoch 27/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1989 - binary_accuracy: 0.7324\n",
      "Epoch 28/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1984 - binary_accuracy: 0.7346\n",
      "Epoch 29/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1984 - binary_accuracy: 0.7389\n",
      "Epoch 30/100\n",
      "62393/62393 [==============================] - 62s 1000us/step - loss: 0.1983 - binary_accuracy: 0.7425\n",
      "Epoch 31/100\n",
      "62393/62393 [==============================] - 62s 991us/step - loss: 0.1978 - binary_accuracy: 0.7423\n",
      "Epoch 32/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1976 - binary_accuracy: 0.7315\n",
      "Epoch 33/100\n",
      "62393/62393 [==============================] - 62s 1000us/step - loss: 0.1975 - binary_accuracy: 0.7389\n",
      "Epoch 34/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1975 - binary_accuracy: 0.7427\n",
      "Epoch 35/100\n",
      "62393/62393 [==============================] - 62s 995us/step - loss: 0.1971 - binary_accuracy: 0.7403\n",
      "Epoch 36/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1968 - binary_accuracy: 0.7412\n",
      "Epoch 37/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1967 - binary_accuracy: 0.7396\n",
      "Epoch 38/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1964 - binary_accuracy: 0.7364\n",
      "Epoch 39/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.1959 - binary_accuracy: 0.7347\n",
      "Epoch 40/100\n",
      "62393/62393 [==============================] - 62s 993us/step - loss: 0.1957 - binary_accuracy: 0.7421\n",
      "Epoch 41/100\n",
      "62393/62393 [==============================] - 62s 997us/step - loss: 0.1956 - binary_accuracy: 0.7340\n",
      "Epoch 42/100\n",
      "62393/62393 [==============================] - 61s 982us/step - loss: 0.1951 - binary_accuracy: 0.7412\n",
      "Epoch 43/100\n",
      "62393/62393 [==============================] - 62s 992us/step - loss: 0.1949 - binary_accuracy: 0.7389\n",
      "Epoch 44/100\n",
      "62393/62393 [==============================] - 62s 996us/step - loss: 0.1943 - binary_accuracy: 0.7409\n",
      "Epoch 45/100\n",
      "62393/62393 [==============================] - 62s 987us/step - loss: 0.1940 - binary_accuracy: 0.7352\n",
      "Epoch 46/100\n",
      "62393/62393 [==============================] - 62s 992us/step - loss: 0.1940 - binary_accuracy: 0.7399\n",
      "Epoch 47/100\n",
      "62393/62393 [==============================] - 61s 982us/step - loss: 0.1939 - binary_accuracy: 0.7352\n",
      "Epoch 48/100\n",
      "62393/62393 [==============================] - 62s 988us/step - loss: 0.1933 - binary_accuracy: 0.7374\n",
      "Epoch 49/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1934 - binary_accuracy: 0.7321\n",
      "Epoch 50/100\n",
      "62393/62393 [==============================] - 62s 995us/step - loss: 0.1925 - binary_accuracy: 0.7306\n",
      "Epoch 51/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1925 - binary_accuracy: 0.7317\n",
      "Epoch 52/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1924 - binary_accuracy: 0.7285\n",
      "Epoch 53/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7327\n",
      "Epoch 54/100\n",
      "62393/62393 [==============================] - 62s 999us/step - loss: 0.1914 - binary_accuracy: 0.7326\n",
      "Epoch 55/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1905 - binary_accuracy: 0.7324\n",
      "Epoch 57/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7315\n",
      "Epoch 58/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1904 - binary_accuracy: 0.7320\n",
      "Epoch 59/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7372\n",
      "Epoch 60/100\n",
      "62393/62393 [==============================] - 62s 997us/step - loss: 0.1892 - binary_accuracy: 0.7301\n",
      "Epoch 61/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.1892 - binary_accuracy: 0.7338\n",
      "Epoch 62/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.1889 - binary_accuracy: 0.7349\n",
      "Epoch 63/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1887 - binary_accuracy: 0.7256\n",
      "Epoch 64/100\n",
      "62393/62393 [==============================] - 62s 998us/step - loss: 0.1886 - binary_accuracy: 0.7359\n",
      "Epoch 65/100\n",
      "62393/62393 [==============================] - 62s 995us/step - loss: 0.1880 - binary_accuracy: 0.7320\n",
      "Epoch 66/100\n",
      "62393/62393 [==============================] - 62s 999us/step - loss: 0.1879 - binary_accuracy: 0.7304\n",
      "Epoch 67/100\n",
      "62393/62393 [==============================] - 62s 995us/step - loss: 0.1876 - binary_accuracy: 0.7280\n",
      "Epoch 68/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1868 - binary_accuracy: 0.7289\n",
      "Epoch 69/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1864 - binary_accuracy: 0.7277\n",
      "Epoch 70/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1870 - binary_accuracy: 0.7266\n",
      "Epoch 71/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1863 - binary_accuracy: 0.7248\n",
      "Epoch 72/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1865 - binary_accuracy: 0.7283\n",
      "Epoch 73/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1854 - binary_accuracy: 0.7338\n",
      "Epoch 74/100\n",
      "62393/62393 [==============================] - 62s 1ms/step - loss: 0.1858 - binary_accuracy: 0.7308\n",
      "Epoch 75/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1854 - binary_accuracy: 0.7322\n",
      "Epoch 76/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1842 - binary_accuracy: 0.7309\n",
      "Epoch 77/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1841 - binary_accuracy: 0.7316\n",
      "Epoch 78/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1841 - binary_accuracy: 0.7273\n",
      "Epoch 79/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1843 - binary_accuracy: 0.7280\n",
      "Epoch 80/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1838 - binary_accuracy: 0.7309\n",
      "Epoch 81/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1829 - binary_accuracy: 0.7264\n",
      "Epoch 82/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1827 - binary_accuracy: 0.7278\n",
      "Epoch 83/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1827 - binary_accuracy: 0.7257\n",
      "Epoch 84/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1828 - binary_accuracy: 0.7267\n",
      "Epoch 85/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1816 - binary_accuracy: 0.7267\n",
      "Epoch 86/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1815 - binary_accuracy: 0.7274\n",
      "Epoch 87/100\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1812 - binary_accuracy: 0.7275\n",
      "Epoch 88/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1817 - binary_accuracy: 0.7266\n",
      "Epoch 89/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1816 - binary_accuracy: 0.7309\n",
      "Epoch 90/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1818 - binary_accuracy: 0.7279\n",
      "Epoch 91/100\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1802 - binary_accuracy: 0.7302\n",
      "Epoch 92/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1805 - binary_accuracy: 0.7294\n",
      "Epoch 93/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1796 - binary_accuracy: 0.7313\n",
      "Epoch 94/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1792 - binary_accuracy: 0.7330\n",
      "Epoch 95/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1794 - binary_accuracy: 0.7302\n",
      "Epoch 96/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1792 - binary_accuracy: 0.7249\n",
      "Epoch 97/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1792 - binary_accuracy: 0.7223\n",
      "Epoch 98/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1781 - binary_accuracy: 0.7273\n",
      "Epoch 99/100\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1784 - binary_accuracy: 0.7332\n",
      "Epoch 100/100\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1779 - binary_accuracy: 0.7268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb58ab00d30>"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=300, nb_epoch=100,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "q4PtDQtU5L-M",
    "outputId": "9c67c1e2-e35d-490c-bf06-314e73758e31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.3713198253666182\n",
      "Train Accuracy is  0.758354302565993\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "5q6jsBD65OJE",
    "outputId": "e94d292f-1521-44f8-f034-6902e14d2b11"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>40682</td>\n",
       "      <td>11232</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3845</td>\n",
       "      <td>6634</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>44527</td>\n",
       "      <td>17866</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        40682  11232  51914\n",
       "1.0         3845   6634  10479\n",
       "All        44527  17866  62393"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "BXHBhTvI5R_X",
    "outputId": "2a70339f-c374-4cf7-8359-3aa79b441325"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.78      0.84     51914\n",
      "         1.0       0.37      0.63      0.47     10479\n",
      "\n",
      "    accuracy                           0.76     62393\n",
      "   macro avg       0.64      0.71      0.66     62393\n",
      "weighted avg       0.82      0.76      0.78     62393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "W8meWxJiAT9f",
    "outputId": "a312ccdd-9db1-4e7e-8f71-e9e47be9e4a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.21180555555555555\n",
      "Test Accuracy is  0.6466666666666666\n"
     ]
    }
   ],
   "source": [
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "VS9WQSDglvmf",
    "outputId": "db4d8080-bb53-42d9-d95d-9f16685cba7a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>2181</td>\n",
       "      <td>908</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>417</td>\n",
       "      <td>244</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2598</td>\n",
       "      <td>1152</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        2181   908  3089\n",
       "1.0         417   244   661\n",
       "All        2598  1152  3750"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v-PtZGnsl7oy"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.20,\n",
    "               1:0.80}\n",
    "optimizer=optimizers.Adam(lr=0.005)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xHTGI7sOmCpT",
    "outputId": "39ed895b-8d9c-48fc-b7a6-7c23da4eb396"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2073 - binary_accuracy: 0.8069\n",
      "Epoch 2/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2068 - binary_accuracy: 0.8301\n",
      "Epoch 3/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2069 - binary_accuracy: 0.8317\n",
      "Epoch 4/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2066 - binary_accuracy: 0.8255\n",
      "Epoch 5/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2038 - binary_accuracy: 0.7407\n",
      "Epoch 6/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2024 - binary_accuracy: 0.7391\n",
      "Epoch 7/200\n",
      "62393/62393 [==============================] - 67s 1ms/step - loss: 0.2019 - binary_accuracy: 0.7319\n",
      "Epoch 8/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2013 - binary_accuracy: 0.7308\n",
      "Epoch 9/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2009 - binary_accuracy: 0.7333\n",
      "Epoch 10/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2009 - binary_accuracy: 0.7309\n",
      "Epoch 11/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2010 - binary_accuracy: 0.7313\n",
      "Epoch 12/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2008 - binary_accuracy: 0.7311\n",
      "Epoch 13/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2007 - binary_accuracy: 0.7267\n",
      "Epoch 14/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2007 - binary_accuracy: 0.7312\n",
      "Epoch 15/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2006 - binary_accuracy: 0.7284\n",
      "Epoch 16/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2005 - binary_accuracy: 0.7246\n",
      "Epoch 17/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2005 - binary_accuracy: 0.7297\n",
      "Epoch 18/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.2003 - binary_accuracy: 0.7289\n",
      "Epoch 19/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2003 - binary_accuracy: 0.7289\n",
      "Epoch 20/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2003 - binary_accuracy: 0.7344\n",
      "Epoch 21/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2000 - binary_accuracy: 0.7273\n",
      "Epoch 22/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2000 - binary_accuracy: 0.7285\n",
      "Epoch 23/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2001 - binary_accuracy: 0.7356\n",
      "Epoch 24/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1997 - binary_accuracy: 0.7318\n",
      "Epoch 25/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1999 - binary_accuracy: 0.7319\n",
      "Epoch 26/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.2000 - binary_accuracy: 0.7342\n",
      "Epoch 27/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1999 - binary_accuracy: 0.7357\n",
      "Epoch 28/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1996 - binary_accuracy: 0.7267\n",
      "Epoch 29/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1996 - binary_accuracy: 0.7260\n",
      "Epoch 30/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1994 - binary_accuracy: 0.7322\n",
      "Epoch 31/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1993 - binary_accuracy: 0.7298\n",
      "Epoch 32/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1998 - binary_accuracy: 0.7365\n",
      "Epoch 33/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1994 - binary_accuracy: 0.7258\n",
      "Epoch 34/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1993 - binary_accuracy: 0.7316\n",
      "Epoch 35/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1992 - binary_accuracy: 0.7331\n",
      "Epoch 36/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1990 - binary_accuracy: 0.7371\n",
      "Epoch 37/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1988 - binary_accuracy: 0.7366\n",
      "Epoch 38/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1987 - binary_accuracy: 0.7347\n",
      "Epoch 39/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1987 - binary_accuracy: 0.7310\n",
      "Epoch 40/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1985 - binary_accuracy: 0.7358\n",
      "Epoch 41/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1984 - binary_accuracy: 0.7375\n",
      "Epoch 42/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1982 - binary_accuracy: 0.7279\n",
      "Epoch 43/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1978 - binary_accuracy: 0.7286\n",
      "Epoch 44/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1981 - binary_accuracy: 0.7288\n",
      "Epoch 45/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1979 - binary_accuracy: 0.7345\n",
      "Epoch 46/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1976 - binary_accuracy: 0.7248\n",
      "Epoch 47/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1972 - binary_accuracy: 0.7321\n",
      "Epoch 48/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1969 - binary_accuracy: 0.7285\n",
      "Epoch 49/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1970 - binary_accuracy: 0.7311\n",
      "Epoch 50/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1967 - binary_accuracy: 0.7268\n",
      "Epoch 51/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1966 - binary_accuracy: 0.7260\n",
      "Epoch 52/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1966 - binary_accuracy: 0.7292\n",
      "Epoch 53/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1964 - binary_accuracy: 0.7280\n",
      "Epoch 54/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1965 - binary_accuracy: 0.7248\n",
      "Epoch 55/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1958 - binary_accuracy: 0.7289\n",
      "Epoch 56/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1955 - binary_accuracy: 0.7250\n",
      "Epoch 57/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1956 - binary_accuracy: 0.7233\n",
      "Epoch 58/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1950 - binary_accuracy: 0.7207\n",
      "Epoch 59/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1954 - binary_accuracy: 0.7267\n",
      "Epoch 60/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1957 - binary_accuracy: 0.7269\n",
      "Epoch 61/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1943 - binary_accuracy: 0.7247\n",
      "Epoch 62/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1947 - binary_accuracy: 0.7256\n",
      "Epoch 63/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1946 - binary_accuracy: 0.7221\n",
      "Epoch 64/200\n",
      "62393/62393 [==============================] - 67s 1ms/step - loss: 0.1938 - binary_accuracy: 0.7212\n",
      "Epoch 65/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1939 - binary_accuracy: 0.7192\n",
      "Epoch 66/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1930 - binary_accuracy: 0.7178\n",
      "Epoch 67/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1933 - binary_accuracy: 0.7159\n",
      "Epoch 68/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7174\n",
      "Epoch 69/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1933 - binary_accuracy: 0.7203\n",
      "Epoch 70/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1927 - binary_accuracy: 0.7163\n",
      "Epoch 71/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1925 - binary_accuracy: 0.7194\n",
      "Epoch 72/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1921 - binary_accuracy: 0.7154\n",
      "Epoch 73/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1919 - binary_accuracy: 0.7206\n",
      "Epoch 74/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1918 - binary_accuracy: 0.7167\n",
      "Epoch 75/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1913 - binary_accuracy: 0.7207\n",
      "Epoch 76/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1914 - binary_accuracy: 0.7162\n",
      "Epoch 77/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1911 - binary_accuracy: 0.7112\n",
      "Epoch 78/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1907 - binary_accuracy: 0.7201\n",
      "Epoch 79/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1899 - binary_accuracy: 0.7141\n",
      "Epoch 80/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1902 - binary_accuracy: 0.7193\n",
      "Epoch 81/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1900 - binary_accuracy: 0.7142\n",
      "Epoch 82/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1891 - binary_accuracy: 0.7209\n",
      "Epoch 83/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1894 - binary_accuracy: 0.7186\n",
      "Epoch 84/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1891 - binary_accuracy: 0.7220\n",
      "Epoch 85/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1883 - binary_accuracy: 0.7158\n",
      "Epoch 86/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1883 - binary_accuracy: 0.7163\n",
      "Epoch 87/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1886 - binary_accuracy: 0.7194\n",
      "Epoch 88/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1879 - binary_accuracy: 0.7186\n",
      "Epoch 89/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1880 - binary_accuracy: 0.7168\n",
      "Epoch 90/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1874 - binary_accuracy: 0.7173\n",
      "Epoch 91/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1867 - binary_accuracy: 0.7208\n",
      "Epoch 92/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1869 - binary_accuracy: 0.7148\n",
      "Epoch 93/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1866 - binary_accuracy: 0.7199\n",
      "Epoch 94/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1855 - binary_accuracy: 0.7187\n",
      "Epoch 95/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1867 - binary_accuracy: 0.7198\n",
      "Epoch 96/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1857 - binary_accuracy: 0.7162\n",
      "Epoch 97/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1856 - binary_accuracy: 0.7140\n",
      "Epoch 98/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1853 - binary_accuracy: 0.7172\n",
      "Epoch 99/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1846 - binary_accuracy: 0.7210\n",
      "Epoch 100/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1852 - binary_accuracy: 0.7170\n",
      "Epoch 101/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1854 - binary_accuracy: 0.7170\n",
      "Epoch 102/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1903 - binary_accuracy: 0.7146\n",
      "Epoch 103/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1908 - binary_accuracy: 0.7171\n",
      "Epoch 104/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1858 - binary_accuracy: 0.7195\n",
      "Epoch 105/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1849 - binary_accuracy: 0.7162\n",
      "Epoch 106/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1850 - binary_accuracy: 0.7172\n",
      "Epoch 107/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1850 - binary_accuracy: 0.7150\n",
      "Epoch 108/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1843 - binary_accuracy: 0.7168\n",
      "Epoch 109/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1843 - binary_accuracy: 0.7171\n",
      "Epoch 110/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1836 - binary_accuracy: 0.7152\n",
      "Epoch 111/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1833 - binary_accuracy: 0.7163\n",
      "Epoch 112/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1830 - binary_accuracy: 0.7130\n",
      "Epoch 113/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1830 - binary_accuracy: 0.7158\n",
      "Epoch 114/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1835 - binary_accuracy: 0.7139\n",
      "Epoch 115/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1815 - binary_accuracy: 0.7148\n",
      "Epoch 116/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1809 - binary_accuracy: 0.7200\n",
      "Epoch 117/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1823 - binary_accuracy: 0.7138\n",
      "Epoch 118/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1805 - binary_accuracy: 0.7195\n",
      "Epoch 119/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1811 - binary_accuracy: 0.7146\n",
      "Epoch 120/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1811 - binary_accuracy: 0.7183\n",
      "Epoch 121/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1809 - binary_accuracy: 0.7131\n",
      "Epoch 122/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1818 - binary_accuracy: 0.7159\n",
      "Epoch 123/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1806 - binary_accuracy: 0.7096\n",
      "Epoch 124/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1788 - binary_accuracy: 0.7224\n",
      "Epoch 125/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1809 - binary_accuracy: 0.7131\n",
      "Epoch 126/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1805 - binary_accuracy: 0.7133\n",
      "Epoch 127/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1803 - binary_accuracy: 0.7170\n",
      "Epoch 128/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1812 - binary_accuracy: 0.7168\n",
      "Epoch 129/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1804 - binary_accuracy: 0.7188\n",
      "Epoch 130/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1780 - binary_accuracy: 0.7163\n",
      "Epoch 131/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1782 - binary_accuracy: 0.7176\n",
      "Epoch 132/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1780 - binary_accuracy: 0.7167\n",
      "Epoch 133/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1779 - binary_accuracy: 0.7184\n",
      "Epoch 134/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1799 - binary_accuracy: 0.7133\n",
      "Epoch 135/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1806 - binary_accuracy: 0.7183\n",
      "Epoch 136/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1787 - binary_accuracy: 0.7162\n",
      "Epoch 137/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1776 - binary_accuracy: 0.7168\n",
      "Epoch 138/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1778 - binary_accuracy: 0.7131\n",
      "Epoch 139/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1780 - binary_accuracy: 0.7167\n",
      "Epoch 140/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1767 - binary_accuracy: 0.7225\n",
      "Epoch 141/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1759 - binary_accuracy: 0.7183\n",
      "Epoch 142/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1785 - binary_accuracy: 0.7159\n",
      "Epoch 143/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1772 - binary_accuracy: 0.7143\n",
      "Epoch 144/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1751 - binary_accuracy: 0.7218\n",
      "Epoch 145/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1762 - binary_accuracy: 0.7175\n",
      "Epoch 146/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1754 - binary_accuracy: 0.7190\n",
      "Epoch 147/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1758 - binary_accuracy: 0.7154\n",
      "Epoch 148/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1757 - binary_accuracy: 0.7188\n",
      "Epoch 149/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1751 - binary_accuracy: 0.7192\n",
      "Epoch 150/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1751 - binary_accuracy: 0.7188\n",
      "Epoch 151/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1755 - binary_accuracy: 0.7170\n",
      "Epoch 152/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1754 - binary_accuracy: 0.7207\n",
      "Epoch 153/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1749 - binary_accuracy: 0.7206\n",
      "Epoch 154/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1740 - binary_accuracy: 0.7232\n",
      "Epoch 155/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1742 - binary_accuracy: 0.7168\n",
      "Epoch 156/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1729 - binary_accuracy: 0.7229\n",
      "Epoch 157/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1740 - binary_accuracy: 0.7204\n",
      "Epoch 158/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1733 - binary_accuracy: 0.7169\n",
      "Epoch 159/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1731 - binary_accuracy: 0.7226\n",
      "Epoch 160/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1730 - binary_accuracy: 0.7207\n",
      "Epoch 161/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1731 - binary_accuracy: 0.7218\n",
      "Epoch 162/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1722 - binary_accuracy: 0.7195\n",
      "Epoch 163/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1720 - binary_accuracy: 0.7182\n",
      "Epoch 164/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1723 - binary_accuracy: 0.7205\n",
      "Epoch 165/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1718 - binary_accuracy: 0.7170\n",
      "Epoch 166/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1737 - binary_accuracy: 0.7157\n",
      "Epoch 167/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1743 - binary_accuracy: 0.7204\n",
      "Epoch 168/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1734 - binary_accuracy: 0.7214\n",
      "Epoch 169/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1715 - binary_accuracy: 0.7192\n",
      "Epoch 170/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1707 - binary_accuracy: 0.7193\n",
      "Epoch 171/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1719 - binary_accuracy: 0.7210\n",
      "Epoch 172/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1710 - binary_accuracy: 0.7228\n",
      "Epoch 173/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1708 - binary_accuracy: 0.7261\n",
      "Epoch 174/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1703 - binary_accuracy: 0.7239\n",
      "Epoch 175/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1700 - binary_accuracy: 0.7246\n",
      "Epoch 176/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1710 - binary_accuracy: 0.7198\n",
      "Epoch 177/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1696 - binary_accuracy: 0.7223\n",
      "Epoch 178/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1708 - binary_accuracy: 0.7228\n",
      "Epoch 179/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1705 - binary_accuracy: 0.7230\n",
      "Epoch 180/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1694 - binary_accuracy: 0.7256\n",
      "Epoch 181/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1693 - binary_accuracy: 0.7242\n",
      "Epoch 182/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1680 - binary_accuracy: 0.7235\n",
      "Epoch 183/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1682 - binary_accuracy: 0.7218\n",
      "Epoch 184/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1677 - binary_accuracy: 0.7270\n",
      "Epoch 185/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1679 - binary_accuracy: 0.7221\n",
      "Epoch 186/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1682 - binary_accuracy: 0.7249\n",
      "Epoch 187/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1679 - binary_accuracy: 0.7235\n",
      "Epoch 188/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1681 - binary_accuracy: 0.7244\n",
      "Epoch 189/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1676 - binary_accuracy: 0.7267\n",
      "Epoch 190/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1681 - binary_accuracy: 0.7224\n",
      "Epoch 191/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1677 - binary_accuracy: 0.7231\n",
      "Epoch 192/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1671 - binary_accuracy: 0.7272\n",
      "Epoch 193/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1667 - binary_accuracy: 0.7240\n",
      "Epoch 194/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1657 - binary_accuracy: 0.7275\n",
      "Epoch 195/200\n",
      "62393/62393 [==============================] - 66s 1ms/step - loss: 0.1655 - binary_accuracy: 0.7288\n",
      "Epoch 196/200\n",
      "62393/62393 [==============================] - 65s 1ms/step - loss: 0.1665 - binary_accuracy: 0.7300\n",
      "Epoch 197/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1663 - binary_accuracy: 0.7276\n",
      "Epoch 198/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1661 - binary_accuracy: 0.7280\n",
      "Epoch 199/200\n",
      "62393/62393 [==============================] - 64s 1ms/step - loss: 0.1652 - binary_accuracy: 0.7283\n",
      "Epoch 200/200\n",
      "62393/62393 [==============================] - 63s 1ms/step - loss: 0.1649 - binary_accuracy: 0.7284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb58a3dda90>"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=300, nb_epoch=200,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "RaII9C6rmHDz",
    "outputId": "ecbd1c47-83d2-47a5-8478-99c6df84390b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.3897835332345773\n",
      "Train Accuracy is  0.7581138909813601\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "V2Kx_GX6YlVg",
    "outputId": "9ad0fe6e-ac2c-4463-e4b5-5f4b7787306a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>39144</td>\n",
       "      <td>12770</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>2322</td>\n",
       "      <td>8157</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>41466</td>\n",
       "      <td>20927</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        39144  12770  51914\n",
       "1.0         2322   8157  10479\n",
       "All        41466  20927  62393"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "55UJyCOeZhtO",
    "outputId": "1b179518-c179-406c-d17d-48213064bec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.75      0.84     51914\n",
      "         1.0       0.39      0.78      0.52     10479\n",
      "\n",
      "    accuracy                           0.76     62393\n",
      "   macro avg       0.67      0.77      0.68     62393\n",
      "weighted avg       0.85      0.76      0.78     62393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "ZrLaDO3MaTl1",
    "outputId": "ccc93f3f-8588-4242-a054-949bebe56dd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.1870342771982116\n",
      "Test Accuracy is  0.5997333333333333\n"
     ]
    }
   ],
   "source": [
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "ugmE_j7Pby4g",
    "outputId": "17757eed-deea-4a1a-c16d-5acab01d56bc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1998</td>\n",
       "      <td>1091</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>410</td>\n",
       "      <td>251</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2408</td>\n",
       "      <td>1342</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        1998  1091  3089\n",
       "1.0         410   251   661\n",
       "All        2408  1342  3750"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gQoUGrArb3n6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8fRf9VhcyS5"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "G5wR385mc706",
    "outputId": "022da747-f5d8-4452-911f-eda9aa4f69f2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "62393/62393 [==============================] - 40s 649us/step - loss: 0.1530 - binary_accuracy: 0.1722\n",
      "Epoch 2/200\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1521 - binary_accuracy: 0.1681\n",
      "Epoch 3/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1511 - binary_accuracy: 0.1742\n",
      "Epoch 4/200\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1504 - binary_accuracy: 0.1979\n",
      "Epoch 5/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1500 - binary_accuracy: 0.2140\n",
      "Epoch 6/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1498 - binary_accuracy: 0.2023\n",
      "Epoch 7/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1497 - binary_accuracy: 0.2176\n",
      "Epoch 8/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1492 - binary_accuracy: 0.2397\n",
      "Epoch 9/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1490 - binary_accuracy: 0.2344\n",
      "Epoch 10/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1489 - binary_accuracy: 0.2325\n",
      "Epoch 11/200\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1484 - binary_accuracy: 0.2348\n",
      "Epoch 12/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1483 - binary_accuracy: 0.2458\n",
      "Epoch 13/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1482 - binary_accuracy: 0.2491\n",
      "Epoch 14/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1480 - binary_accuracy: 0.2477\n",
      "Epoch 15/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1478 - binary_accuracy: 0.2484\n",
      "Epoch 16/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1479 - binary_accuracy: 0.2503\n",
      "Epoch 17/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1478 - binary_accuracy: 0.2551\n",
      "Epoch 18/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1477 - binary_accuracy: 0.2549\n",
      "Epoch 19/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1478 - binary_accuracy: 0.2552\n",
      "Epoch 20/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1474 - binary_accuracy: 0.2592\n",
      "Epoch 21/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1474 - binary_accuracy: 0.2585\n",
      "Epoch 22/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1472 - binary_accuracy: 0.2535\n",
      "Epoch 23/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1471 - binary_accuracy: 0.2675\n",
      "Epoch 24/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1472 - binary_accuracy: 0.2643\n",
      "Epoch 25/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1472 - binary_accuracy: 0.2624\n",
      "Epoch 26/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1469 - binary_accuracy: 0.2731\n",
      "Epoch 27/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1469 - binary_accuracy: 0.2678\n",
      "Epoch 28/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1468 - binary_accuracy: 0.2750\n",
      "Epoch 29/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1466 - binary_accuracy: 0.2769\n",
      "Epoch 30/200\n",
      "62393/62393 [==============================] - 38s 609us/step - loss: 0.1465 - binary_accuracy: 0.2753\n",
      "Epoch 31/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1465 - binary_accuracy: 0.2813\n",
      "Epoch 32/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1461 - binary_accuracy: 0.2831\n",
      "Epoch 33/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1461 - binary_accuracy: 0.2843\n",
      "Epoch 34/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1459 - binary_accuracy: 0.2850\n",
      "Epoch 35/200\n",
      "62393/62393 [==============================] - 38s 609us/step - loss: 0.1459 - binary_accuracy: 0.2936\n",
      "Epoch 36/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1457 - binary_accuracy: 0.2901\n",
      "Epoch 37/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1453 - binary_accuracy: 0.3005\n",
      "Epoch 38/200\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1454 - binary_accuracy: 0.3029\n",
      "Epoch 39/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1449 - binary_accuracy: 0.3038\n",
      "Epoch 40/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1448 - binary_accuracy: 0.3078\n",
      "Epoch 41/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1446 - binary_accuracy: 0.3095\n",
      "Epoch 42/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1442 - binary_accuracy: 0.3177\n",
      "Epoch 43/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1439 - binary_accuracy: 0.3161\n",
      "Epoch 44/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1437 - binary_accuracy: 0.3185\n",
      "Epoch 45/200\n",
      "62393/62393 [==============================] - 38s 606us/step - loss: 0.1439 - binary_accuracy: 0.3176\n",
      "Epoch 46/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1430 - binary_accuracy: 0.3308\n",
      "Epoch 47/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1428 - binary_accuracy: 0.3312\n",
      "Epoch 48/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1426 - binary_accuracy: 0.3334\n",
      "Epoch 49/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1424 - binary_accuracy: 0.3317\n",
      "Epoch 50/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1420 - binary_accuracy: 0.3389\n",
      "Epoch 51/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1413 - binary_accuracy: 0.3432\n",
      "Epoch 52/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1409 - binary_accuracy: 0.3459\n",
      "Epoch 53/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1405 - binary_accuracy: 0.3539\n",
      "Epoch 54/200\n",
      "62393/62393 [==============================] - 38s 608us/step - loss: 0.1398 - binary_accuracy: 0.3596\n",
      "Epoch 55/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1398 - binary_accuracy: 0.3632\n",
      "Epoch 56/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1392 - binary_accuracy: 0.3664\n",
      "Epoch 57/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1387 - binary_accuracy: 0.3681\n",
      "Epoch 58/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1382 - binary_accuracy: 0.3793\n",
      "Epoch 59/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1380 - binary_accuracy: 0.3738\n",
      "Epoch 60/200\n",
      "62393/62393 [==============================] - 38s 609us/step - loss: 0.1370 - binary_accuracy: 0.3822\n",
      "Epoch 61/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1367 - binary_accuracy: 0.3885\n",
      "Epoch 62/200\n",
      "62393/62393 [==============================] - 38s 608us/step - loss: 0.1363 - binary_accuracy: 0.3926\n",
      "Epoch 63/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1358 - binary_accuracy: 0.3963\n",
      "Epoch 64/200\n",
      "62393/62393 [==============================] - 38s 609us/step - loss: 0.1355 - binary_accuracy: 0.3979\n",
      "Epoch 65/200\n",
      "62393/62393 [==============================] - 38s 605us/step - loss: 0.1346 - binary_accuracy: 0.4016\n",
      "Epoch 66/200\n",
      "62393/62393 [==============================] - 38s 608us/step - loss: 0.1343 - binary_accuracy: 0.4053\n",
      "Epoch 67/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1336 - binary_accuracy: 0.4105\n",
      "Epoch 68/200\n",
      "62393/62393 [==============================] - 38s 610us/step - loss: 0.1333 - binary_accuracy: 0.4129\n",
      "Epoch 69/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1324 - binary_accuracy: 0.4233\n",
      "Epoch 70/200\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1326 - binary_accuracy: 0.4210\n",
      "Epoch 71/200\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1320 - binary_accuracy: 0.4262\n",
      "Epoch 72/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1309 - binary_accuracy: 0.4339\n",
      "Epoch 73/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1310 - binary_accuracy: 0.4292\n",
      "Epoch 74/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1309 - binary_accuracy: 0.4383\n",
      "Epoch 75/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1303 - binary_accuracy: 0.4350\n",
      "Epoch 76/200\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1296 - binary_accuracy: 0.4443\n",
      "Epoch 77/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1295 - binary_accuracy: 0.4417\n",
      "Epoch 78/200\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1291 - binary_accuracy: 0.4488\n",
      "Epoch 79/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1285 - binary_accuracy: 0.4520\n",
      "Epoch 80/200\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1275 - binary_accuracy: 0.4592\n",
      "Epoch 81/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1273 - binary_accuracy: 0.4558\n",
      "Epoch 82/200\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1283 - binary_accuracy: 0.4569\n",
      "Epoch 83/200\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1279 - binary_accuracy: 0.4550\n",
      "Epoch 84/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1257 - binary_accuracy: 0.4681\n",
      "Epoch 85/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1249 - binary_accuracy: 0.4727\n",
      "Epoch 86/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1243 - binary_accuracy: 0.4772\n",
      "Epoch 87/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1257 - binary_accuracy: 0.4749\n",
      "Epoch 88/200\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1249 - binary_accuracy: 0.4747\n",
      "Epoch 89/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1237 - binary_accuracy: 0.4806\n",
      "Epoch 90/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1235 - binary_accuracy: 0.4815\n",
      "Epoch 91/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1226 - binary_accuracy: 0.4898\n",
      "Epoch 92/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1229 - binary_accuracy: 0.4864\n",
      "Epoch 93/200\n",
      "62393/62393 [==============================] - 38s 609us/step - loss: 0.1218 - binary_accuracy: 0.4962\n",
      "Epoch 94/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1224 - binary_accuracy: 0.4926\n",
      "Epoch 95/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1219 - binary_accuracy: 0.4975\n",
      "Epoch 96/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1206 - binary_accuracy: 0.5036\n",
      "Epoch 97/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1203 - binary_accuracy: 0.5061\n",
      "Epoch 98/200\n",
      "62393/62393 [==============================] - 38s 610us/step - loss: 0.1208 - binary_accuracy: 0.5038\n",
      "Epoch 99/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1190 - binary_accuracy: 0.5136\n",
      "Epoch 100/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1192 - binary_accuracy: 0.5151\n",
      "Epoch 101/200\n",
      "62393/62393 [==============================] - 38s 606us/step - loss: 0.1190 - binary_accuracy: 0.5160\n",
      "Epoch 102/200\n",
      "62393/62393 [==============================] - 38s 606us/step - loss: 0.1195 - binary_accuracy: 0.5176\n",
      "Epoch 103/200\n",
      "62393/62393 [==============================] - 38s 608us/step - loss: 0.1178 - binary_accuracy: 0.5227\n",
      "Epoch 104/200\n",
      "62393/62393 [==============================] - 40s 639us/step - loss: 0.1175 - binary_accuracy: 0.5247\n",
      "Epoch 105/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1178 - binary_accuracy: 0.5229\n",
      "Epoch 106/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1198 - binary_accuracy: 0.5153\n",
      "Epoch 107/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1164 - binary_accuracy: 0.5311\n",
      "Epoch 108/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1165 - binary_accuracy: 0.5352\n",
      "Epoch 109/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1162 - binary_accuracy: 0.5311\n",
      "Epoch 110/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1159 - binary_accuracy: 0.5370\n",
      "Epoch 111/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1158 - binary_accuracy: 0.5343\n",
      "Epoch 112/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1167 - binary_accuracy: 0.5333\n",
      "Epoch 113/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1144 - binary_accuracy: 0.5467\n",
      "Epoch 114/200\n",
      "62393/62393 [==============================] - 38s 610us/step - loss: 0.1144 - binary_accuracy: 0.5441\n",
      "Epoch 115/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1148 - binary_accuracy: 0.5459\n",
      "Epoch 116/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1140 - binary_accuracy: 0.5491\n",
      "Epoch 117/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1129 - binary_accuracy: 0.5552\n",
      "Epoch 118/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1115 - binary_accuracy: 0.5642\n",
      "Epoch 119/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1136 - binary_accuracy: 0.5540\n",
      "Epoch 120/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1132 - binary_accuracy: 0.5538\n",
      "Epoch 121/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1111 - binary_accuracy: 0.5678\n",
      "Epoch 122/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1120 - binary_accuracy: 0.5611\n",
      "Epoch 123/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1113 - binary_accuracy: 0.5658\n",
      "Epoch 124/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1116 - binary_accuracy: 0.5707\n",
      "Epoch 125/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1119 - binary_accuracy: 0.5637\n",
      "Epoch 126/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1099 - binary_accuracy: 0.5761\n",
      "Epoch 127/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1097 - binary_accuracy: 0.5768\n",
      "Epoch 128/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1108 - binary_accuracy: 0.5708\n",
      "Epoch 129/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1101 - binary_accuracy: 0.5740\n",
      "Epoch 130/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1097 - binary_accuracy: 0.5782\n",
      "Epoch 131/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1080 - binary_accuracy: 0.5870\n",
      "Epoch 132/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1090 - binary_accuracy: 0.5813\n",
      "Epoch 133/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1085 - binary_accuracy: 0.5846\n",
      "Epoch 134/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1090 - binary_accuracy: 0.5796\n",
      "Epoch 135/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.1088 - binary_accuracy: 0.5838\n",
      "Epoch 136/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1074 - binary_accuracy: 0.5884\n",
      "Epoch 137/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1075 - binary_accuracy: 0.5886\n",
      "Epoch 138/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.1076 - binary_accuracy: 0.5885\n",
      "Epoch 139/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1074 - binary_accuracy: 0.5917\n",
      "Epoch 140/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1076 - binary_accuracy: 0.5923\n",
      "Epoch 141/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1065 - binary_accuracy: 0.5936\n",
      "Epoch 142/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1056 - binary_accuracy: 0.5960\n",
      "Epoch 143/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.1072 - binary_accuracy: 0.5920\n",
      "Epoch 144/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1054 - binary_accuracy: 0.5996\n",
      "Epoch 145/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.1056 - binary_accuracy: 0.6029\n",
      "Epoch 146/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1051 - binary_accuracy: 0.6041\n",
      "Epoch 147/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1053 - binary_accuracy: 0.6003\n",
      "Epoch 148/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1042 - binary_accuracy: 0.6061\n",
      "Epoch 149/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1047 - binary_accuracy: 0.6056\n",
      "Epoch 150/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1034 - binary_accuracy: 0.6152\n",
      "Epoch 151/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1037 - binary_accuracy: 0.6116\n",
      "Epoch 152/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.1044 - binary_accuracy: 0.6081\n",
      "Epoch 153/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1038 - binary_accuracy: 0.6090\n",
      "Epoch 154/200\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.1027 - binary_accuracy: 0.6175\n",
      "Epoch 155/200\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1027 - binary_accuracy: 0.6162\n",
      "Epoch 156/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1035 - binary_accuracy: 0.6150\n",
      "Epoch 157/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1032 - binary_accuracy: 0.6142\n",
      "Epoch 158/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1034 - binary_accuracy: 0.6153\n",
      "Epoch 159/200\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1029 - binary_accuracy: 0.6165\n",
      "Epoch 160/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.1024 - binary_accuracy: 0.6193\n",
      "Epoch 161/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1016 - binary_accuracy: 0.6241\n",
      "Epoch 162/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1011 - binary_accuracy: 0.6237\n",
      "Epoch 163/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1013 - binary_accuracy: 0.6235\n",
      "Epoch 164/200\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1024 - binary_accuracy: 0.6200\n",
      "Epoch 165/200\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1001 - binary_accuracy: 0.6338\n",
      "Epoch 166/200\n",
      "62393/62393 [==============================] - 39s 633us/step - loss: 0.1011 - binary_accuracy: 0.6327\n",
      "Epoch 167/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1023 - binary_accuracy: 0.6230\n",
      "Epoch 168/200\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1020 - binary_accuracy: 0.6259\n",
      "Epoch 169/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1000 - binary_accuracy: 0.6321\n",
      "Epoch 170/200\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1007 - binary_accuracy: 0.6307\n",
      "Epoch 171/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0994 - binary_accuracy: 0.6391\n",
      "Epoch 172/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0988 - binary_accuracy: 0.6419\n",
      "Epoch 173/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.1002 - binary_accuracy: 0.6344\n",
      "Epoch 174/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0975 - binary_accuracy: 0.6454\n",
      "Epoch 175/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0988 - binary_accuracy: 0.6417\n",
      "Epoch 176/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0992 - binary_accuracy: 0.6396\n",
      "Epoch 177/200\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0978 - binary_accuracy: 0.6450\n",
      "Epoch 178/200\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0990 - binary_accuracy: 0.6434\n",
      "Epoch 179/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0976 - binary_accuracy: 0.6486\n",
      "Epoch 180/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0969 - binary_accuracy: 0.6503\n",
      "Epoch 181/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0972 - binary_accuracy: 0.6500\n",
      "Epoch 182/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0981 - binary_accuracy: 0.6476\n",
      "Epoch 183/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0962 - binary_accuracy: 0.6520\n",
      "Epoch 184/200\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0976 - binary_accuracy: 0.6494\n",
      "Epoch 185/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0971 - binary_accuracy: 0.6512\n",
      "Epoch 186/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.0964 - binary_accuracy: 0.6531\n",
      "Epoch 187/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0959 - binary_accuracy: 0.6585\n",
      "Epoch 188/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0967 - binary_accuracy: 0.6534\n",
      "Epoch 189/200\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0966 - binary_accuracy: 0.6515\n",
      "Epoch 190/200\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0961 - binary_accuracy: 0.6554\n",
      "Epoch 191/200\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0960 - binary_accuracy: 0.6544\n",
      "Epoch 192/200\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0962 - binary_accuracy: 0.6569\n",
      "Epoch 193/200\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0948 - binary_accuracy: 0.6600\n",
      "Epoch 194/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0955 - binary_accuracy: 0.6624\n",
      "Epoch 195/200\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0951 - binary_accuracy: 0.6603\n",
      "Epoch 196/200\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0943 - binary_accuracy: 0.6632\n",
      "Epoch 197/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0945 - binary_accuracy: 0.6656\n",
      "Epoch 198/200\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0945 - binary_accuracy: 0.6637\n",
      "Epoch 199/200\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.0936 - binary_accuracy: 0.6675\n",
      "Epoch 200/200\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0943 - binary_accuracy: 0.6656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fb57b1246d8>"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, nb_epoch=200,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "Oe7D8xCgiNHL",
    "outputId": "cdcbd50e-36ce-4b20-fed4-1014b1aed969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.3349296230383433\n",
      "Train Accuracy is  0.6685205071081692\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>31360</td>\n",
       "      <td>20554</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>128</td>\n",
       "      <td>10351</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>31488</td>\n",
       "      <td>30905</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        31360  20554  51914\n",
       "1.0          128  10351  10479\n",
       "All        31488  30905  62393"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)\n",
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "AqulXdti_qd2",
    "outputId": "3282a4f9-5313-4adf-dfbf-b366f9d135c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.60      0.75     51914\n",
      "         1.0       0.33      0.99      0.50     10479\n",
      "\n",
      "    accuracy                           0.67     62393\n",
      "   macro avg       0.67      0.80      0.63     62393\n",
      "weighted avg       0.88      0.67      0.71     62393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1UUDESw7Bzou"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d-0MOEBBAxkw"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "_bhAmDv3BL1E",
    "outputId": "fe59c085-22f3-496c-a3a3-b3733c7cf6df"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "62393/62393 [==============================] - 46s 729us/step - loss: 0.1525 - binary_accuracy: 0.1709\n",
      "Epoch 2/300\n",
      "62393/62393 [==============================] - 42s 668us/step - loss: 0.1513 - binary_accuracy: 0.1738\n",
      "Epoch 3/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.1503 - binary_accuracy: 0.1929\n",
      "Epoch 4/300\n",
      "62393/62393 [==============================] - 45s 717us/step - loss: 0.1503 - binary_accuracy: 0.2011\n",
      "Epoch 5/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1500 - binary_accuracy: 0.2078\n",
      "Epoch 6/300\n",
      "62393/62393 [==============================] - 44s 712us/step - loss: 0.1496 - binary_accuracy: 0.2189\n",
      "Epoch 7/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.1495 - binary_accuracy: 0.2146\n",
      "Epoch 8/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1493 - binary_accuracy: 0.2289\n",
      "Epoch 9/300\n",
      "62393/62393 [==============================] - 42s 673us/step - loss: 0.1489 - binary_accuracy: 0.2283\n",
      "Epoch 10/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1489 - binary_accuracy: 0.2274\n",
      "Epoch 11/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1484 - binary_accuracy: 0.2394\n",
      "Epoch 12/300\n",
      "62393/62393 [==============================] - 43s 688us/step - loss: 0.1483 - binary_accuracy: 0.2294\n",
      "Epoch 13/300\n",
      "62393/62393 [==============================] - 43s 687us/step - loss: 0.1483 - binary_accuracy: 0.2430\n",
      "Epoch 14/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1481 - binary_accuracy: 0.2466\n",
      "Epoch 15/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.1481 - binary_accuracy: 0.2404\n",
      "Epoch 16/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1480 - binary_accuracy: 0.2487\n",
      "Epoch 17/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1481 - binary_accuracy: 0.2507\n",
      "Epoch 18/300\n",
      "62393/62393 [==============================] - 43s 683us/step - loss: 0.1478 - binary_accuracy: 0.2439\n",
      "Epoch 19/300\n",
      "62393/62393 [==============================] - 44s 703us/step - loss: 0.1476 - binary_accuracy: 0.2550\n",
      "Epoch 20/300\n",
      "62393/62393 [==============================] - 42s 671us/step - loss: 0.1477 - binary_accuracy: 0.2533\n",
      "Epoch 21/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1477 - binary_accuracy: 0.2493\n",
      "Epoch 22/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1475 - binary_accuracy: 0.2573\n",
      "Epoch 23/300\n",
      "62393/62393 [==============================] - 43s 687us/step - loss: 0.1472 - binary_accuracy: 0.2624\n",
      "Epoch 24/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1473 - binary_accuracy: 0.2612\n",
      "Epoch 25/300\n",
      "62393/62393 [==============================] - 44s 701us/step - loss: 0.1473 - binary_accuracy: 0.2581\n",
      "Epoch 26/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1471 - binary_accuracy: 0.2638\n",
      "Epoch 27/300\n",
      "62393/62393 [==============================] - 42s 669us/step - loss: 0.1472 - binary_accuracy: 0.2714\n",
      "Epoch 28/300\n",
      "62393/62393 [==============================] - 42s 674us/step - loss: 0.1471 - binary_accuracy: 0.2687\n",
      "Epoch 29/300\n",
      "62393/62393 [==============================] - 41s 661us/step - loss: 0.1469 - binary_accuracy: 0.2712\n",
      "Epoch 30/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1468 - binary_accuracy: 0.2734\n",
      "Epoch 31/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1467 - binary_accuracy: 0.2756\n",
      "Epoch 32/300\n",
      "62393/62393 [==============================] - 41s 660us/step - loss: 0.1466 - binary_accuracy: 0.2778\n",
      "Epoch 33/300\n",
      "62393/62393 [==============================] - 41s 657us/step - loss: 0.1463 - binary_accuracy: 0.2807\n",
      "Epoch 34/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.1462 - binary_accuracy: 0.2845\n",
      "Epoch 35/300\n",
      "62393/62393 [==============================] - 42s 677us/step - loss: 0.1459 - binary_accuracy: 0.2890\n",
      "Epoch 36/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1458 - binary_accuracy: 0.2899\n",
      "Epoch 37/300\n",
      "62393/62393 [==============================] - 43s 681us/step - loss: 0.1456 - binary_accuracy: 0.2961\n",
      "Epoch 38/300\n",
      "62393/62393 [==============================] - 41s 665us/step - loss: 0.1454 - binary_accuracy: 0.2956\n",
      "Epoch 39/300\n",
      "62393/62393 [==============================] - 42s 671us/step - loss: 0.1454 - binary_accuracy: 0.3022\n",
      "Epoch 40/300\n",
      "62393/62393 [==============================] - 42s 668us/step - loss: 0.1451 - binary_accuracy: 0.3020\n",
      "Epoch 41/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.1447 - binary_accuracy: 0.3030\n",
      "Epoch 42/300\n",
      "62393/62393 [==============================] - 43s 683us/step - loss: 0.1445 - binary_accuracy: 0.3081\n",
      "Epoch 43/300\n",
      "62393/62393 [==============================] - 41s 664us/step - loss: 0.1442 - binary_accuracy: 0.3124\n",
      "Epoch 44/300\n",
      "62393/62393 [==============================] - 42s 668us/step - loss: 0.1439 - binary_accuracy: 0.3187\n",
      "Epoch 45/300\n",
      "62393/62393 [==============================] - 41s 661us/step - loss: 0.1438 - binary_accuracy: 0.3176\n",
      "Epoch 46/300\n",
      "62393/62393 [==============================] - 42s 674us/step - loss: 0.1436 - binary_accuracy: 0.3190\n",
      "Epoch 47/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1432 - binary_accuracy: 0.3216\n",
      "Epoch 48/300\n",
      "62393/62393 [==============================] - 42s 673us/step - loss: 0.1426 - binary_accuracy: 0.3322\n",
      "Epoch 49/300\n",
      "62393/62393 [==============================] - 42s 681us/step - loss: 0.1424 - binary_accuracy: 0.3360\n",
      "Epoch 50/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.1419 - binary_accuracy: 0.3406\n",
      "Epoch 51/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.1419 - binary_accuracy: 0.3383\n",
      "Epoch 52/300\n",
      "62393/62393 [==============================] - 45s 716us/step - loss: 0.1418 - binary_accuracy: 0.3345\n",
      "Epoch 53/300\n",
      "62393/62393 [==============================] - 44s 697us/step - loss: 0.1416 - binary_accuracy: 0.3350\n",
      "Epoch 54/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.1406 - binary_accuracy: 0.3509\n",
      "Epoch 55/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1405 - binary_accuracy: 0.3477\n",
      "Epoch 56/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1400 - binary_accuracy: 0.3575\n",
      "Epoch 57/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1400 - binary_accuracy: 0.3544\n",
      "Epoch 58/300\n",
      "62393/62393 [==============================] - 42s 670us/step - loss: 0.1391 - binary_accuracy: 0.3668\n",
      "Epoch 59/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1385 - binary_accuracy: 0.3659\n",
      "Epoch 60/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.1383 - binary_accuracy: 0.3702\n",
      "Epoch 61/300\n",
      "62393/62393 [==============================] - 43s 687us/step - loss: 0.1382 - binary_accuracy: 0.3714\n",
      "Epoch 62/300\n",
      "62393/62393 [==============================] - 43s 690us/step - loss: 0.1372 - binary_accuracy: 0.3772\n",
      "Epoch 63/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.1368 - binary_accuracy: 0.3818\n",
      "Epoch 64/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1368 - binary_accuracy: 0.3830\n",
      "Epoch 65/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1360 - binary_accuracy: 0.3863\n",
      "Epoch 66/300\n",
      "62393/62393 [==============================] - 41s 663us/step - loss: 0.1357 - binary_accuracy: 0.3883\n",
      "Epoch 67/300\n",
      "62393/62393 [==============================] - 42s 680us/step - loss: 0.1354 - binary_accuracy: 0.3959\n",
      "Epoch 68/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1347 - binary_accuracy: 0.4055\n",
      "Epoch 69/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.1342 - binary_accuracy: 0.4024\n",
      "Epoch 70/300\n",
      "62393/62393 [==============================] - 43s 688us/step - loss: 0.1337 - binary_accuracy: 0.4076\n",
      "Epoch 71/300\n",
      "62393/62393 [==============================] - 42s 679us/step - loss: 0.1333 - binary_accuracy: 0.4102\n",
      "Epoch 72/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.1333 - binary_accuracy: 0.4085\n",
      "Epoch 73/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.1327 - binary_accuracy: 0.4159\n",
      "Epoch 74/300\n",
      "62393/62393 [==============================] - 42s 678us/step - loss: 0.1318 - binary_accuracy: 0.4226\n",
      "Epoch 75/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1310 - binary_accuracy: 0.4244\n",
      "Epoch 76/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.1309 - binary_accuracy: 0.4300\n",
      "Epoch 77/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1306 - binary_accuracy: 0.4296\n",
      "Epoch 78/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.1305 - binary_accuracy: 0.4307\n",
      "Epoch 79/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.1305 - binary_accuracy: 0.4349\n",
      "Epoch 80/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.1301 - binary_accuracy: 0.4350\n",
      "Epoch 81/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.1295 - binary_accuracy: 0.4355\n",
      "Epoch 82/300\n",
      "62393/62393 [==============================] - 42s 680us/step - loss: 0.1286 - binary_accuracy: 0.4499\n",
      "Epoch 83/300\n",
      "62393/62393 [==============================] - 44s 703us/step - loss: 0.1279 - binary_accuracy: 0.4497\n",
      "Epoch 84/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1285 - binary_accuracy: 0.4435\n",
      "Epoch 85/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.1275 - binary_accuracy: 0.4552\n",
      "Epoch 86/300\n",
      "62393/62393 [==============================] - 42s 669us/step - loss: 0.1268 - binary_accuracy: 0.4567\n",
      "Epoch 87/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1267 - binary_accuracy: 0.4573\n",
      "Epoch 88/300\n",
      "62393/62393 [==============================] - 43s 688us/step - loss: 0.1267 - binary_accuracy: 0.4604\n",
      "Epoch 89/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.1248 - binary_accuracy: 0.4646\n",
      "Epoch 90/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.1259 - binary_accuracy: 0.4647\n",
      "Epoch 91/300\n",
      "62393/62393 [==============================] - 42s 678us/step - loss: 0.1246 - binary_accuracy: 0.4731\n",
      "Epoch 92/300\n",
      "62393/62393 [==============================] - 43s 690us/step - loss: 0.1243 - binary_accuracy: 0.4755\n",
      "Epoch 93/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1241 - binary_accuracy: 0.4773\n",
      "Epoch 94/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1236 - binary_accuracy: 0.4830\n",
      "Epoch 95/300\n",
      "62393/62393 [==============================] - 42s 670us/step - loss: 0.1229 - binary_accuracy: 0.4878\n",
      "Epoch 96/300\n",
      "62393/62393 [==============================] - 43s 690us/step - loss: 0.1227 - binary_accuracy: 0.4905\n",
      "Epoch 97/300\n",
      "62393/62393 [==============================] - 42s 677us/step - loss: 0.1227 - binary_accuracy: 0.4888\n",
      "Epoch 98/300\n",
      "62393/62393 [==============================] - 42s 672us/step - loss: 0.1222 - binary_accuracy: 0.4884\n",
      "Epoch 99/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1217 - binary_accuracy: 0.4931\n",
      "Epoch 100/300\n",
      "62393/62393 [==============================] - 42s 679us/step - loss: 0.1209 - binary_accuracy: 0.5029\n",
      "Epoch 101/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1216 - binary_accuracy: 0.4952\n",
      "Epoch 102/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1209 - binary_accuracy: 0.5020\n",
      "Epoch 103/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.1205 - binary_accuracy: 0.5035\n",
      "Epoch 104/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.1196 - binary_accuracy: 0.5075\n",
      "Epoch 105/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1197 - binary_accuracy: 0.5072\n",
      "Epoch 106/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1189 - binary_accuracy: 0.5119\n",
      "Epoch 107/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.1190 - binary_accuracy: 0.5124\n",
      "Epoch 108/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1184 - binary_accuracy: 0.5186\n",
      "Epoch 109/300\n",
      "62393/62393 [==============================] - 41s 664us/step - loss: 0.1172 - binary_accuracy: 0.5230\n",
      "Epoch 110/300\n",
      "62393/62393 [==============================] - 42s 678us/step - loss: 0.1185 - binary_accuracy: 0.5210\n",
      "Epoch 111/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.1168 - binary_accuracy: 0.5258\n",
      "Epoch 112/300\n",
      "62393/62393 [==============================] - 43s 683us/step - loss: 0.1169 - binary_accuracy: 0.5260\n",
      "Epoch 113/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1158 - binary_accuracy: 0.5350\n",
      "Epoch 114/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.1165 - binary_accuracy: 0.5300\n",
      "Epoch 115/300\n",
      "62393/62393 [==============================] - 42s 675us/step - loss: 0.1169 - binary_accuracy: 0.5317\n",
      "Epoch 116/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1160 - binary_accuracy: 0.5341\n",
      "Epoch 117/300\n",
      "62393/62393 [==============================] - 42s 673us/step - loss: 0.1150 - binary_accuracy: 0.5405\n",
      "Epoch 118/300\n",
      "62393/62393 [==============================] - 42s 671us/step - loss: 0.1147 - binary_accuracy: 0.5416\n",
      "Epoch 119/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1149 - binary_accuracy: 0.5387\n",
      "Epoch 120/300\n",
      "62393/62393 [==============================] - 41s 660us/step - loss: 0.1144 - binary_accuracy: 0.5424\n",
      "Epoch 121/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.1138 - binary_accuracy: 0.5487\n",
      "Epoch 122/300\n",
      "62393/62393 [==============================] - 42s 680us/step - loss: 0.1136 - binary_accuracy: 0.5469\n",
      "Epoch 123/300\n",
      "62393/62393 [==============================] - 42s 677us/step - loss: 0.1141 - binary_accuracy: 0.5486\n",
      "Epoch 124/300\n",
      "62393/62393 [==============================] - 42s 667us/step - loss: 0.1129 - binary_accuracy: 0.5547\n",
      "Epoch 125/300\n",
      "62393/62393 [==============================] - 42s 670us/step - loss: 0.1124 - binary_accuracy: 0.5545\n",
      "Epoch 126/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1129 - binary_accuracy: 0.5519\n",
      "Epoch 127/300\n",
      "62393/62393 [==============================] - 46s 737us/step - loss: 0.1116 - binary_accuracy: 0.5599\n",
      "Epoch 128/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.1116 - binary_accuracy: 0.5611\n",
      "Epoch 129/300\n",
      "62393/62393 [==============================] - 43s 681us/step - loss: 0.1120 - binary_accuracy: 0.5602\n",
      "Epoch 130/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1111 - binary_accuracy: 0.5657\n",
      "Epoch 131/300\n",
      "62393/62393 [==============================] - 42s 676us/step - loss: 0.1102 - binary_accuracy: 0.5706\n",
      "Epoch 132/300\n",
      "62393/62393 [==============================] - 42s 674us/step - loss: 0.1103 - binary_accuracy: 0.5697\n",
      "Epoch 133/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.1099 - binary_accuracy: 0.5730\n",
      "Epoch 134/300\n",
      "62393/62393 [==============================] - 43s 690us/step - loss: 0.1106 - binary_accuracy: 0.5687\n",
      "Epoch 135/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1087 - binary_accuracy: 0.5770\n",
      "Epoch 136/300\n",
      "62393/62393 [==============================] - 45s 718us/step - loss: 0.1093 - binary_accuracy: 0.5767\n",
      "Epoch 137/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.1091 - binary_accuracy: 0.5755\n",
      "Epoch 138/300\n",
      "62393/62393 [==============================] - 45s 716us/step - loss: 0.1088 - binary_accuracy: 0.5805\n",
      "Epoch 139/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.1089 - binary_accuracy: 0.5793\n",
      "Epoch 140/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.1084 - binary_accuracy: 0.5801\n",
      "Epoch 141/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.1078 - binary_accuracy: 0.5827\n",
      "Epoch 142/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.1076 - binary_accuracy: 0.5872\n",
      "Epoch 143/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.1082 - binary_accuracy: 0.5804\n",
      "Epoch 144/300\n",
      "62393/62393 [==============================] - 42s 679us/step - loss: 0.1080 - binary_accuracy: 0.5871\n",
      "Epoch 145/300\n",
      "62393/62393 [==============================] - 42s 681us/step - loss: 0.1074 - binary_accuracy: 0.5872\n",
      "Epoch 146/300\n",
      "62393/62393 [==============================] - 42s 678us/step - loss: 0.1079 - binary_accuracy: 0.5871\n",
      "Epoch 147/300\n",
      "62393/62393 [==============================] - 43s 681us/step - loss: 0.1067 - binary_accuracy: 0.5961\n",
      "Epoch 148/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.1063 - binary_accuracy: 0.5934\n",
      "Epoch 149/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.1052 - binary_accuracy: 0.5997\n",
      "Epoch 150/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1054 - binary_accuracy: 0.5966\n",
      "Epoch 151/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.1059 - binary_accuracy: 0.5998\n",
      "Epoch 152/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.1043 - binary_accuracy: 0.6029\n",
      "Epoch 153/300\n",
      "62393/62393 [==============================] - 44s 710us/step - loss: 0.1044 - binary_accuracy: 0.6042\n",
      "Epoch 154/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.1050 - binary_accuracy: 0.6022\n",
      "Epoch 155/300\n",
      "62393/62393 [==============================] - 44s 713us/step - loss: 0.1051 - binary_accuracy: 0.6057\n",
      "Epoch 156/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.1041 - binary_accuracy: 0.6058\n",
      "Epoch 157/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.1033 - binary_accuracy: 0.6126\n",
      "Epoch 158/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.1033 - binary_accuracy: 0.6107\n",
      "Epoch 159/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.1035 - binary_accuracy: 0.6107\n",
      "Epoch 160/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.1036 - binary_accuracy: 0.6106\n",
      "Epoch 161/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1036 - binary_accuracy: 0.6134\n",
      "Epoch 162/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.1022 - binary_accuracy: 0.6184\n",
      "Epoch 163/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.1031 - binary_accuracy: 0.6143\n",
      "Epoch 164/300\n",
      "62393/62393 [==============================] - 43s 682us/step - loss: 0.1018 - binary_accuracy: 0.6194\n",
      "Epoch 165/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.1012 - binary_accuracy: 0.6240\n",
      "Epoch 166/300\n",
      "62393/62393 [==============================] - 44s 706us/step - loss: 0.1017 - binary_accuracy: 0.6214\n",
      "Epoch 167/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.1029 - binary_accuracy: 0.6146\n",
      "Epoch 168/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.1026 - binary_accuracy: 0.6176\n",
      "Epoch 169/300\n",
      "62393/62393 [==============================] - 44s 712us/step - loss: 0.1009 - binary_accuracy: 0.6285\n",
      "Epoch 170/300\n",
      "62393/62393 [==============================] - 44s 703us/step - loss: 0.1001 - binary_accuracy: 0.6327\n",
      "Epoch 171/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.1008 - binary_accuracy: 0.6267\n",
      "Epoch 172/300\n",
      "62393/62393 [==============================] - 45s 714us/step - loss: 0.1001 - binary_accuracy: 0.6342\n",
      "Epoch 173/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1001 - binary_accuracy: 0.6319\n",
      "Epoch 174/300\n",
      "62393/62393 [==============================] - 45s 728us/step - loss: 0.0985 - binary_accuracy: 0.6393\n",
      "Epoch 175/300\n",
      "62393/62393 [==============================] - 45s 714us/step - loss: 0.1000 - binary_accuracy: 0.6324\n",
      "Epoch 176/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0998 - binary_accuracy: 0.6366\n",
      "Epoch 177/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.1013 - binary_accuracy: 0.6310\n",
      "Epoch 178/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0986 - binary_accuracy: 0.6404\n",
      "Epoch 179/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0986 - binary_accuracy: 0.6403\n",
      "Epoch 180/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.0997 - binary_accuracy: 0.6356\n",
      "Epoch 181/300\n",
      "62393/62393 [==============================] - 43s 687us/step - loss: 0.0986 - binary_accuracy: 0.6381\n",
      "Epoch 182/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.0981 - binary_accuracy: 0.6438\n",
      "Epoch 183/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.0995 - binary_accuracy: 0.6369\n",
      "Epoch 184/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0978 - binary_accuracy: 0.6448\n",
      "Epoch 185/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0968 - binary_accuracy: 0.6496\n",
      "Epoch 186/300\n",
      "62393/62393 [==============================] - 44s 707us/step - loss: 0.0973 - binary_accuracy: 0.6474\n",
      "Epoch 187/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0971 - binary_accuracy: 0.6490\n",
      "Epoch 188/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.0978 - binary_accuracy: 0.6441\n",
      "Epoch 189/300\n",
      "62393/62393 [==============================] - 43s 685us/step - loss: 0.0973 - binary_accuracy: 0.6459\n",
      "Epoch 190/300\n",
      "62393/62393 [==============================] - 42s 679us/step - loss: 0.0957 - binary_accuracy: 0.6542\n",
      "Epoch 191/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0968 - binary_accuracy: 0.6500\n",
      "Epoch 192/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0958 - binary_accuracy: 0.6549\n",
      "Epoch 193/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0973 - binary_accuracy: 0.6493\n",
      "Epoch 194/300\n",
      "62393/62393 [==============================] - 43s 691us/step - loss: 0.0976 - binary_accuracy: 0.6467\n",
      "Epoch 195/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0962 - binary_accuracy: 0.6543\n",
      "Epoch 196/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0960 - binary_accuracy: 0.6546\n",
      "Epoch 197/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0960 - binary_accuracy: 0.6566\n",
      "Epoch 198/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0954 - binary_accuracy: 0.6597\n",
      "Epoch 199/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.0950 - binary_accuracy: 0.6601\n",
      "Epoch 200/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0947 - binary_accuracy: 0.6614\n",
      "Epoch 201/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.0946 - binary_accuracy: 0.6633\n",
      "Epoch 202/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0949 - binary_accuracy: 0.6621\n",
      "Epoch 203/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.0932 - binary_accuracy: 0.6684\n",
      "Epoch 204/300\n",
      "62393/62393 [==============================] - 44s 710us/step - loss: 0.0941 - binary_accuracy: 0.6655\n",
      "Epoch 205/300\n",
      "62393/62393 [==============================] - 45s 715us/step - loss: 0.0958 - binary_accuracy: 0.6564\n",
      "Epoch 206/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.0943 - binary_accuracy: 0.6672\n",
      "Epoch 207/300\n",
      "62393/62393 [==============================] - 44s 707us/step - loss: 0.0950 - binary_accuracy: 0.6600\n",
      "Epoch 208/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0933 - binary_accuracy: 0.6684\n",
      "Epoch 209/300\n",
      "62393/62393 [==============================] - 44s 712us/step - loss: 0.0932 - binary_accuracy: 0.6704\n",
      "Epoch 210/300\n",
      "62393/62393 [==============================] - 43s 683us/step - loss: 0.0931 - binary_accuracy: 0.6698\n",
      "Epoch 211/300\n",
      "62393/62393 [==============================] - 45s 720us/step - loss: 0.0934 - binary_accuracy: 0.6695\n",
      "Epoch 212/300\n",
      "62393/62393 [==============================] - 44s 710us/step - loss: 0.0923 - binary_accuracy: 0.6717\n",
      "Epoch 213/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0931 - binary_accuracy: 0.6691\n",
      "Epoch 214/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0935 - binary_accuracy: 0.6675\n",
      "Epoch 215/300\n",
      "62393/62393 [==============================] - 44s 697us/step - loss: 0.0937 - binary_accuracy: 0.6665\n",
      "Epoch 216/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0917 - binary_accuracy: 0.6749\n",
      "Epoch 217/300\n",
      "62393/62393 [==============================] - 45s 715us/step - loss: 0.0928 - binary_accuracy: 0.6740\n",
      "Epoch 218/300\n",
      "62393/62393 [==============================] - 45s 724us/step - loss: 0.0932 - binary_accuracy: 0.6710\n",
      "Epoch 219/300\n",
      "62393/62393 [==============================] - 46s 742us/step - loss: 0.0922 - binary_accuracy: 0.6774\n",
      "Epoch 220/300\n",
      "62393/62393 [==============================] - 45s 726us/step - loss: 0.0916 - binary_accuracy: 0.6752\n",
      "Epoch 221/300\n",
      "62393/62393 [==============================] - 45s 719us/step - loss: 0.0923 - binary_accuracy: 0.6743\n",
      "Epoch 222/300\n",
      "62393/62393 [==============================] - 45s 727us/step - loss: 0.0914 - binary_accuracy: 0.6795\n",
      "Epoch 223/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0912 - binary_accuracy: 0.6817\n",
      "Epoch 224/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0913 - binary_accuracy: 0.6809\n",
      "Epoch 225/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.0907 - binary_accuracy: 0.6820\n",
      "Epoch 226/300\n",
      "62393/62393 [==============================] - 43s 686us/step - loss: 0.0909 - binary_accuracy: 0.6853\n",
      "Epoch 227/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.0911 - binary_accuracy: 0.6805\n",
      "Epoch 228/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0906 - binary_accuracy: 0.6804\n",
      "Epoch 229/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0900 - binary_accuracy: 0.6847\n",
      "Epoch 230/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.0899 - binary_accuracy: 0.6873\n",
      "Epoch 231/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.0894 - binary_accuracy: 0.6854\n",
      "Epoch 232/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0899 - binary_accuracy: 0.6847\n",
      "Epoch 233/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.0904 - binary_accuracy: 0.6868\n",
      "Epoch 234/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.0900 - binary_accuracy: 0.6866\n",
      "Epoch 235/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0892 - binary_accuracy: 0.6872\n",
      "Epoch 236/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.0892 - binary_accuracy: 0.6891\n",
      "Epoch 237/300\n",
      "62393/62393 [==============================] - 44s 701us/step - loss: 0.0912 - binary_accuracy: 0.6833\n",
      "Epoch 238/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.0886 - binary_accuracy: 0.6924\n",
      "Epoch 239/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.0882 - binary_accuracy: 0.6975\n",
      "Epoch 240/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0890 - binary_accuracy: 0.6928\n",
      "Epoch 241/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.0877 - binary_accuracy: 0.6962\n",
      "Epoch 242/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.0888 - binary_accuracy: 0.6935\n",
      "Epoch 243/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.0881 - binary_accuracy: 0.6968\n",
      "Epoch 244/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0881 - binary_accuracy: 0.6972\n",
      "Epoch 245/300\n",
      "62393/62393 [==============================] - 43s 692us/step - loss: 0.0868 - binary_accuracy: 0.7021\n",
      "Epoch 246/300\n",
      "62393/62393 [==============================] - 43s 689us/step - loss: 0.0881 - binary_accuracy: 0.6979\n",
      "Epoch 247/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0878 - binary_accuracy: 0.6975\n",
      "Epoch 248/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0888 - binary_accuracy: 0.6935\n",
      "Epoch 249/300\n",
      "62393/62393 [==============================] - 44s 699us/step - loss: 0.0883 - binary_accuracy: 0.6933\n",
      "Epoch 250/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0867 - binary_accuracy: 0.7037\n",
      "Epoch 251/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0859 - binary_accuracy: 0.7072\n",
      "Epoch 252/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0868 - binary_accuracy: 0.7051\n",
      "Epoch 253/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0853 - binary_accuracy: 0.7081\n",
      "Epoch 254/300\n",
      "62393/62393 [==============================] - 44s 701us/step - loss: 0.0861 - binary_accuracy: 0.7044\n",
      "Epoch 255/300\n",
      "62393/62393 [==============================] - 43s 684us/step - loss: 0.0867 - binary_accuracy: 0.7061\n",
      "Epoch 256/300\n",
      "62393/62393 [==============================] - 42s 680us/step - loss: 0.0875 - binary_accuracy: 0.7012\n",
      "Epoch 257/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.0875 - binary_accuracy: 0.7020\n",
      "Epoch 258/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0865 - binary_accuracy: 0.7019\n",
      "Epoch 259/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0850 - binary_accuracy: 0.7107\n",
      "Epoch 260/300\n",
      "62393/62393 [==============================] - 43s 693us/step - loss: 0.0869 - binary_accuracy: 0.7060\n",
      "Epoch 261/300\n",
      "62393/62393 [==============================] - 47s 747us/step - loss: 0.0868 - binary_accuracy: 0.7052\n",
      "Epoch 262/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0854 - binary_accuracy: 0.7093\n",
      "Epoch 263/300\n",
      "62393/62393 [==============================] - 43s 687us/step - loss: 0.0870 - binary_accuracy: 0.7046\n",
      "Epoch 264/300\n",
      "62393/62393 [==============================] - 44s 698us/step - loss: 0.0848 - binary_accuracy: 0.7125\n",
      "Epoch 265/300\n",
      "62393/62393 [==============================] - 45s 722us/step - loss: 0.0855 - binary_accuracy: 0.7110\n",
      "Epoch 266/300\n",
      "62393/62393 [==============================] - 45s 714us/step - loss: 0.0846 - binary_accuracy: 0.7151\n",
      "Epoch 267/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.0856 - binary_accuracy: 0.7090\n",
      "Epoch 268/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0854 - binary_accuracy: 0.7096\n",
      "Epoch 269/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.0846 - binary_accuracy: 0.7147\n",
      "Epoch 271/300\n",
      "62393/62393 [==============================] - 43s 694us/step - loss: 0.0853 - binary_accuracy: 0.7124\n",
      "Epoch 272/300\n",
      "62393/62393 [==============================] - 43s 697us/step - loss: 0.0854 - binary_accuracy: 0.7130\n",
      "Epoch 273/300\n",
      "62393/62393 [==============================] - 44s 712us/step - loss: 0.0838 - binary_accuracy: 0.7204\n",
      "Epoch 274/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.0849 - binary_accuracy: 0.7181\n",
      "Epoch 275/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.0845 - binary_accuracy: 0.7166\n",
      "Epoch 276/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0851 - binary_accuracy: 0.7140\n",
      "Epoch 277/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0847 - binary_accuracy: 0.7171\n",
      "Epoch 278/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0853 - binary_accuracy: 0.7127\n",
      "Epoch 279/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0846 - binary_accuracy: 0.7183\n",
      "Epoch 280/300\n",
      "62393/62393 [==============================] - 44s 703us/step - loss: 0.0840 - binary_accuracy: 0.7181\n",
      "Epoch 281/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.0830 - binary_accuracy: 0.7234\n",
      "Epoch 282/300\n",
      "62393/62393 [==============================] - 44s 702us/step - loss: 0.0823 - binary_accuracy: 0.7240\n",
      "Epoch 283/300\n",
      "62393/62393 [==============================] - 44s 706us/step - loss: 0.0846 - binary_accuracy: 0.7176\n",
      "Epoch 284/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0852 - binary_accuracy: 0.7153\n",
      "Epoch 285/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0829 - binary_accuracy: 0.7226\n",
      "Epoch 286/300\n",
      "62393/62393 [==============================] - 43s 695us/step - loss: 0.0825 - binary_accuracy: 0.7250\n",
      "Epoch 287/300\n",
      "62393/62393 [==============================] - 44s 706us/step - loss: 0.0833 - binary_accuracy: 0.7206\n",
      "Epoch 288/300\n",
      "62393/62393 [==============================] - 44s 709us/step - loss: 0.0831 - binary_accuracy: 0.7256\n",
      "Epoch 289/300\n",
      "62393/62393 [==============================] - 44s 707us/step - loss: 0.0824 - binary_accuracy: 0.7238\n",
      "Epoch 290/300\n",
      "62393/62393 [==============================] - 44s 706us/step - loss: 0.0819 - binary_accuracy: 0.7288\n",
      "Epoch 291/300\n",
      "62393/62393 [==============================] - 43s 696us/step - loss: 0.0824 - binary_accuracy: 0.7257\n",
      "Epoch 292/300\n",
      "62393/62393 [==============================] - 44s 700us/step - loss: 0.0813 - binary_accuracy: 0.7291\n",
      "Epoch 293/300\n",
      "62393/62393 [==============================] - 44s 705us/step - loss: 0.0830 - binary_accuracy: 0.7220\n",
      "Epoch 294/300\n",
      "62393/62393 [==============================] - 44s 708us/step - loss: 0.0814 - binary_accuracy: 0.7293\n",
      "Epoch 295/300\n",
      "62393/62393 [==============================] - 44s 711us/step - loss: 0.0803 - binary_accuracy: 0.7327\n",
      "Epoch 296/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.0834 - binary_accuracy: 0.7234\n",
      "Epoch 297/300\n",
      "62393/62393 [==============================] - 44s 704us/step - loss: 0.0813 - binary_accuracy: 0.7297\n",
      "Epoch 298/300\n",
      "62393/62393 [==============================] - 44s 707us/step - loss: 0.0815 - binary_accuracy: 0.7309\n",
      "Epoch 299/300\n",
      "62393/62393 [==============================] - 46s 735us/step - loss: 0.0828 - binary_accuracy: 0.7276\n",
      "Epoch 300/300\n",
      "62393/62393 [==============================] - 46s 731us/step - loss: 0.0804 - binary_accuracy: 0.7314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f30019b2a90>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, nb_epoch=300,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "KgQhPfFnBRV7",
    "outputId": "e085ba5d-e79d-45e6-edcc-6a19d15015ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.39436885865457294\n",
      "Train Accuracy is  0.742455083102271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.69      0.82     51914\n",
      "         1.0       0.39      1.00      0.56     10479\n",
      "\n",
      "    accuracy                           0.74     62393\n",
      "   macro avg       0.70      0.84      0.69     62393\n",
      "weighted avg       0.90      0.74      0.77     62393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "v-kJTh9M7VAH",
    "outputId": "2f53582a-cf97-4c9e-b2f8-c6947ab7dcb7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>35889</td>\n",
       "      <td>16025</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>44</td>\n",
       "      <td>10435</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>35933</td>\n",
       "      <td>26460</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        35889  16025  51914\n",
       "1.0           44  10435  10479\n",
       "All        35933  26460  62393"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hvjRq0vM7tlA",
    "outputId": "60620f32-c034-4a82-f424-1546399dc84d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.18471337579617833\n",
      "Test Accuracy is  0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 172
    },
    "colab_type": "code",
    "id": "UmcBqNFi8Cub",
    "outputId": "fe67b308-ad1b-446f-ea9f-6e1432c32b75"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1681</td>\n",
       "      <td>1408</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>342</td>\n",
       "      <td>319</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2023</td>\n",
       "      <td>1727</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        1681  1408  3089\n",
       "1.0         342   319   661\n",
       "All        2023  1727  3750"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npj_5jL28Fn-"
   },
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(units=50,return_sequences=True,input_shape=(X_train.shape[1],45)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(units=50,return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(LSTM(units=50))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "class_weight={0:0.10,\n",
    "               1:0.90}\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam',\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aQdLxUQW9bIS",
    "outputId": "2e02a201-061d-4f31-f849-6d21fd0cb95e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "62393/62393 [==============================] - 42s 671us/step - loss: 0.1529 - binary_accuracy: 0.1685\n",
      "Epoch 2/500\n",
      "62393/62393 [==============================] - 40s 641us/step - loss: 0.1519 - binary_accuracy: 0.1681\n",
      "Epoch 3/500\n",
      "62393/62393 [==============================] - 40s 634us/step - loss: 0.1507 - binary_accuracy: 0.1818\n",
      "Epoch 4/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1505 - binary_accuracy: 0.1913\n",
      "Epoch 5/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1499 - binary_accuracy: 0.2066\n",
      "Epoch 6/500\n",
      "62393/62393 [==============================] - 40s 634us/step - loss: 0.1494 - binary_accuracy: 0.2147\n",
      "Epoch 7/500\n",
      "62393/62393 [==============================] - 40s 639us/step - loss: 0.1493 - binary_accuracy: 0.2259\n",
      "Epoch 8/500\n",
      "62393/62393 [==============================] - 40s 637us/step - loss: 0.1492 - binary_accuracy: 0.2223\n",
      "Epoch 9/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1487 - binary_accuracy: 0.2303\n",
      "Epoch 10/500\n",
      "62393/62393 [==============================] - 40s 634us/step - loss: 0.1485 - binary_accuracy: 0.2383\n",
      "Epoch 11/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1486 - binary_accuracy: 0.2297\n",
      "Epoch 12/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1483 - binary_accuracy: 0.2456\n",
      "Epoch 13/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1481 - binary_accuracy: 0.2424\n",
      "Epoch 14/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1482 - binary_accuracy: 0.2390\n",
      "Epoch 15/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1480 - binary_accuracy: 0.2433\n",
      "Epoch 16/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1478 - binary_accuracy: 0.2461\n",
      "Epoch 17/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1477 - binary_accuracy: 0.2573\n",
      "Epoch 18/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1476 - binary_accuracy: 0.2492\n",
      "Epoch 19/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1477 - binary_accuracy: 0.2490\n",
      "Epoch 20/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1474 - binary_accuracy: 0.2580\n",
      "Epoch 21/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1477 - binary_accuracy: 0.2490\n",
      "Epoch 22/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1473 - binary_accuracy: 0.2603\n",
      "Epoch 23/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1471 - binary_accuracy: 0.2718\n",
      "Epoch 24/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1470 - binary_accuracy: 0.2650\n",
      "Epoch 25/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1470 - binary_accuracy: 0.2686\n",
      "Epoch 26/500\n",
      "62393/62393 [==============================] - 40s 638us/step - loss: 0.1469 - binary_accuracy: 0.2687\n",
      "Epoch 27/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1470 - binary_accuracy: 0.2683\n",
      "Epoch 28/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1465 - binary_accuracy: 0.2831\n",
      "Epoch 29/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1463 - binary_accuracy: 0.2861\n",
      "Epoch 30/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1462 - binary_accuracy: 0.2931\n",
      "Epoch 31/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1462 - binary_accuracy: 0.2877\n",
      "Epoch 32/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1460 - binary_accuracy: 0.2896\n",
      "Epoch 33/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1459 - binary_accuracy: 0.2977\n",
      "Epoch 34/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1457 - binary_accuracy: 0.2937\n",
      "Epoch 35/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1455 - binary_accuracy: 0.3016\n",
      "Epoch 36/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1454 - binary_accuracy: 0.3035\n",
      "Epoch 37/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1451 - binary_accuracy: 0.3052\n",
      "Epoch 38/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1449 - binary_accuracy: 0.3076\n",
      "Epoch 39/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1447 - binary_accuracy: 0.3102\n",
      "Epoch 40/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1447 - binary_accuracy: 0.3210\n",
      "Epoch 41/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1442 - binary_accuracy: 0.3261\n",
      "Epoch 42/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1441 - binary_accuracy: 0.3226\n",
      "Epoch 43/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1438 - binary_accuracy: 0.3310\n",
      "Epoch 44/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1433 - binary_accuracy: 0.3385\n",
      "Epoch 45/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1432 - binary_accuracy: 0.3441\n",
      "Epoch 46/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1429 - binary_accuracy: 0.3407\n",
      "Epoch 47/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1425 - binary_accuracy: 0.3468\n",
      "Epoch 48/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1420 - binary_accuracy: 0.3496\n",
      "Epoch 49/500\n",
      "62393/62393 [==============================] - 40s 636us/step - loss: 0.1416 - binary_accuracy: 0.3571\n",
      "Epoch 50/500\n",
      "62393/62393 [==============================] - 40s 637us/step - loss: 0.1414 - binary_accuracy: 0.3594\n",
      "Epoch 51/500\n",
      "62393/62393 [==============================] - 40s 642us/step - loss: 0.1409 - binary_accuracy: 0.3580\n",
      "Epoch 52/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1409 - binary_accuracy: 0.3643\n",
      "Epoch 53/500\n",
      "62393/62393 [==============================] - 40s 638us/step - loss: 0.1403 - binary_accuracy: 0.3674\n",
      "Epoch 54/500\n",
      "62393/62393 [==============================] - 40s 636us/step - loss: 0.1398 - binary_accuracy: 0.3680\n",
      "Epoch 55/500\n",
      "62393/62393 [==============================] - 40s 643us/step - loss: 0.1395 - binary_accuracy: 0.3750\n",
      "Epoch 56/500\n",
      "62393/62393 [==============================] - 40s 634us/step - loss: 0.1391 - binary_accuracy: 0.3793\n",
      "Epoch 57/500\n",
      "62393/62393 [==============================] - 40s 639us/step - loss: 0.1385 - binary_accuracy: 0.3837\n",
      "Epoch 58/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1380 - binary_accuracy: 0.3873\n",
      "Epoch 59/500\n",
      "62393/62393 [==============================] - 39s 633us/step - loss: 0.1380 - binary_accuracy: 0.3847\n",
      "Epoch 60/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1367 - binary_accuracy: 0.3968\n",
      "Epoch 61/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1366 - binary_accuracy: 0.3960\n",
      "Epoch 62/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1363 - binary_accuracy: 0.3969\n",
      "Epoch 63/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1356 - binary_accuracy: 0.4030\n",
      "Epoch 64/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1348 - binary_accuracy: 0.4094\n",
      "Epoch 65/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1346 - binary_accuracy: 0.4084\n",
      "Epoch 66/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1340 - binary_accuracy: 0.4132\n",
      "Epoch 67/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1339 - binary_accuracy: 0.4167\n",
      "Epoch 68/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1329 - binary_accuracy: 0.4168\n",
      "Epoch 69/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1336 - binary_accuracy: 0.4155\n",
      "Epoch 70/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1332 - binary_accuracy: 0.4161\n",
      "Epoch 71/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1322 - binary_accuracy: 0.4252\n",
      "Epoch 72/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1323 - binary_accuracy: 0.4244\n",
      "Epoch 73/500\n",
      "62393/62393 [==============================] - 40s 636us/step - loss: 0.1307 - binary_accuracy: 0.4340\n",
      "Epoch 74/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1307 - binary_accuracy: 0.4339\n",
      "Epoch 75/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1303 - binary_accuracy: 0.4413\n",
      "Epoch 76/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1300 - binary_accuracy: 0.4389\n",
      "Epoch 77/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1295 - binary_accuracy: 0.4456\n",
      "Epoch 78/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1289 - binary_accuracy: 0.4469\n",
      "Epoch 79/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1290 - binary_accuracy: 0.4449\n",
      "Epoch 80/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1282 - binary_accuracy: 0.4538\n",
      "Epoch 81/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1273 - binary_accuracy: 0.4569\n",
      "Epoch 82/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1282 - binary_accuracy: 0.4545\n",
      "Epoch 83/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1273 - binary_accuracy: 0.4579\n",
      "Epoch 84/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1270 - binary_accuracy: 0.4607\n",
      "Epoch 85/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1259 - binary_accuracy: 0.4687\n",
      "Epoch 86/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1248 - binary_accuracy: 0.4749\n",
      "Epoch 87/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1256 - binary_accuracy: 0.4713\n",
      "Epoch 88/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1258 - binary_accuracy: 0.4718\n",
      "Epoch 89/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1244 - binary_accuracy: 0.4775\n",
      "Epoch 90/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1240 - binary_accuracy: 0.4789\n",
      "Epoch 91/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1230 - binary_accuracy: 0.4857\n",
      "Epoch 92/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1231 - binary_accuracy: 0.4858\n",
      "Epoch 93/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1231 - binary_accuracy: 0.4855\n",
      "Epoch 94/500\n",
      "62393/62393 [==============================] - 40s 637us/step - loss: 0.1226 - binary_accuracy: 0.4898\n",
      "Epoch 95/500\n",
      "62393/62393 [==============================] - 40s 648us/step - loss: 0.1227 - binary_accuracy: 0.4874\n",
      "Epoch 96/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1215 - binary_accuracy: 0.4989\n",
      "Epoch 97/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1216 - binary_accuracy: 0.4949\n",
      "Epoch 98/500\n",
      "62393/62393 [==============================] - 40s 635us/step - loss: 0.1214 - binary_accuracy: 0.4975\n",
      "Epoch 99/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1214 - binary_accuracy: 0.4995\n",
      "Epoch 100/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1202 - binary_accuracy: 0.5018\n",
      "Epoch 101/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1212 - binary_accuracy: 0.4985\n",
      "Epoch 102/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1198 - binary_accuracy: 0.5072\n",
      "Epoch 103/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1181 - binary_accuracy: 0.5162\n",
      "Epoch 104/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1187 - binary_accuracy: 0.5165\n",
      "Epoch 105/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1187 - binary_accuracy: 0.5142\n",
      "Epoch 106/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1190 - binary_accuracy: 0.5122\n",
      "Epoch 107/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1177 - binary_accuracy: 0.5209\n",
      "Epoch 108/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1188 - binary_accuracy: 0.5121\n",
      "Epoch 109/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1172 - binary_accuracy: 0.5242\n",
      "Epoch 110/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.1169 - binary_accuracy: 0.5226\n",
      "Epoch 111/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1170 - binary_accuracy: 0.5217\n",
      "Epoch 112/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1150 - binary_accuracy: 0.5359\n",
      "Epoch 113/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1150 - binary_accuracy: 0.5316\n",
      "Epoch 114/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.1164 - binary_accuracy: 0.5281\n",
      "Epoch 115/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1154 - binary_accuracy: 0.5335\n",
      "Epoch 116/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1148 - binary_accuracy: 0.5343\n",
      "Epoch 117/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1157 - binary_accuracy: 0.5324\n",
      "Epoch 118/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1135 - binary_accuracy: 0.5443\n",
      "Epoch 119/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1148 - binary_accuracy: 0.5382\n",
      "Epoch 120/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1138 - binary_accuracy: 0.5430\n",
      "Epoch 121/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1130 - binary_accuracy: 0.5502\n",
      "Epoch 122/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1125 - binary_accuracy: 0.5470\n",
      "Epoch 123/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1130 - binary_accuracy: 0.5466\n",
      "Epoch 124/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1126 - binary_accuracy: 0.5503\n",
      "Epoch 125/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1119 - binary_accuracy: 0.5537\n",
      "Epoch 126/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1117 - binary_accuracy: 0.5558\n",
      "Epoch 127/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1114 - binary_accuracy: 0.5587\n",
      "Epoch 128/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1117 - binary_accuracy: 0.5562\n",
      "Epoch 129/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1112 - binary_accuracy: 0.5590\n",
      "Epoch 130/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1109 - binary_accuracy: 0.5626\n",
      "Epoch 131/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1120 - binary_accuracy: 0.5557\n",
      "Epoch 132/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1099 - binary_accuracy: 0.5687\n",
      "Epoch 133/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1106 - binary_accuracy: 0.5634\n",
      "Epoch 134/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1097 - binary_accuracy: 0.5743\n",
      "Epoch 135/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1092 - binary_accuracy: 0.5710\n",
      "Epoch 136/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1110 - binary_accuracy: 0.5621\n",
      "Epoch 137/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1096 - binary_accuracy: 0.5713\n",
      "Epoch 138/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1083 - binary_accuracy: 0.5790\n",
      "Epoch 139/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1093 - binary_accuracy: 0.5741\n",
      "Epoch 140/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1084 - binary_accuracy: 0.5779\n",
      "Epoch 141/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1083 - binary_accuracy: 0.5779\n",
      "Epoch 142/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1078 - binary_accuracy: 0.5814\n",
      "Epoch 143/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1086 - binary_accuracy: 0.5800\n",
      "Epoch 144/500\n",
      "62393/62393 [==============================] - 40s 638us/step - loss: 0.1059 - binary_accuracy: 0.5870\n",
      "Epoch 145/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.1074 - binary_accuracy: 0.5840\n",
      "Epoch 146/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1061 - binary_accuracy: 0.5912\n",
      "Epoch 147/500\n",
      "62393/62393 [==============================] - 39s 633us/step - loss: 0.1063 - binary_accuracy: 0.5905\n",
      "Epoch 148/500\n",
      "62393/62393 [==============================] - 39s 632us/step - loss: 0.1068 - binary_accuracy: 0.5869\n",
      "Epoch 149/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1066 - binary_accuracy: 0.5862\n",
      "Epoch 150/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.1053 - binary_accuracy: 0.5917\n",
      "Epoch 151/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1044 - binary_accuracy: 0.5969\n",
      "Epoch 152/500\n",
      "62393/62393 [==============================] - 40s 634us/step - loss: 0.1058 - binary_accuracy: 0.5944\n",
      "Epoch 153/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1055 - binary_accuracy: 0.5944\n",
      "Epoch 154/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1049 - binary_accuracy: 0.5990\n",
      "Epoch 155/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1059 - binary_accuracy: 0.5939\n",
      "Epoch 156/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1045 - binary_accuracy: 0.5986\n",
      "Epoch 157/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1045 - binary_accuracy: 0.6000\n",
      "Epoch 158/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.1050 - binary_accuracy: 0.5998\n",
      "Epoch 159/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1041 - binary_accuracy: 0.6019\n",
      "Epoch 160/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1034 - binary_accuracy: 0.6083\n",
      "Epoch 161/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1028 - binary_accuracy: 0.6126\n",
      "Epoch 162/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1030 - binary_accuracy: 0.6092\n",
      "Epoch 163/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1033 - binary_accuracy: 0.6089\n",
      "Epoch 164/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.1027 - binary_accuracy: 0.6133\n",
      "Epoch 165/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1023 - binary_accuracy: 0.6115\n",
      "Epoch 166/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.1017 - binary_accuracy: 0.6183\n",
      "Epoch 167/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.1015 - binary_accuracy: 0.6180\n",
      "Epoch 168/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.1010 - binary_accuracy: 0.6220\n",
      "Epoch 169/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1001 - binary_accuracy: 0.6250\n",
      "Epoch 170/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.1016 - binary_accuracy: 0.6173\n",
      "Epoch 171/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.1013 - binary_accuracy: 0.6219\n",
      "Epoch 172/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.1014 - binary_accuracy: 0.6208\n",
      "Epoch 173/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1002 - binary_accuracy: 0.6247\n",
      "Epoch 174/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0998 - binary_accuracy: 0.6287\n",
      "Epoch 175/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.1000 - binary_accuracy: 0.6256\n",
      "Epoch 176/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0991 - binary_accuracy: 0.6284\n",
      "Epoch 177/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0996 - binary_accuracy: 0.6299\n",
      "Epoch 178/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.1009 - binary_accuracy: 0.6257\n",
      "Epoch 179/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0996 - binary_accuracy: 0.6278\n",
      "Epoch 180/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0988 - binary_accuracy: 0.6330\n",
      "Epoch 181/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0993 - binary_accuracy: 0.6329\n",
      "Epoch 182/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0987 - binary_accuracy: 0.6371\n",
      "Epoch 183/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0981 - binary_accuracy: 0.6393\n",
      "Epoch 184/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0986 - binary_accuracy: 0.6365\n",
      "Epoch 185/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0973 - binary_accuracy: 0.6408\n",
      "Epoch 186/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0984 - binary_accuracy: 0.6389\n",
      "Epoch 187/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0971 - binary_accuracy: 0.6422\n",
      "Epoch 188/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0973 - binary_accuracy: 0.6432\n",
      "Epoch 189/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0969 - binary_accuracy: 0.6462\n",
      "Epoch 190/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0984 - binary_accuracy: 0.6363\n",
      "Epoch 191/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0969 - binary_accuracy: 0.6468\n",
      "Epoch 192/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0972 - binary_accuracy: 0.6447\n",
      "Epoch 193/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0968 - binary_accuracy: 0.6458\n",
      "Epoch 194/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0979 - binary_accuracy: 0.6437\n",
      "Epoch 195/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0967 - binary_accuracy: 0.6468\n",
      "Epoch 196/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0965 - binary_accuracy: 0.6491\n",
      "Epoch 197/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0952 - binary_accuracy: 0.6528\n",
      "Epoch 198/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0961 - binary_accuracy: 0.6502\n",
      "Epoch 199/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0951 - binary_accuracy: 0.6530\n",
      "Epoch 200/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0955 - binary_accuracy: 0.6518\n",
      "Epoch 201/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0944 - binary_accuracy: 0.6594\n",
      "Epoch 202/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0952 - binary_accuracy: 0.6545\n",
      "Epoch 203/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0940 - binary_accuracy: 0.6598\n",
      "Epoch 204/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0937 - binary_accuracy: 0.6626\n",
      "Epoch 205/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0948 - binary_accuracy: 0.6579\n",
      "Epoch 206/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0952 - binary_accuracy: 0.6556\n",
      "Epoch 207/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0927 - binary_accuracy: 0.6663\n",
      "Epoch 208/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0934 - binary_accuracy: 0.6650\n",
      "Epoch 209/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0955 - binary_accuracy: 0.6557\n",
      "Epoch 210/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0947 - binary_accuracy: 0.6610\n",
      "Epoch 211/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0933 - binary_accuracy: 0.6641\n",
      "Epoch 212/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0931 - binary_accuracy: 0.6671\n",
      "Epoch 213/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0935 - binary_accuracy: 0.6629\n",
      "Epoch 214/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0929 - binary_accuracy: 0.6693\n",
      "Epoch 215/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0929 - binary_accuracy: 0.6678\n",
      "Epoch 216/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0923 - binary_accuracy: 0.6711\n",
      "Epoch 217/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0920 - binary_accuracy: 0.6696\n",
      "Epoch 218/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0909 - binary_accuracy: 0.6745\n",
      "Epoch 219/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0923 - binary_accuracy: 0.6702\n",
      "Epoch 220/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0921 - binary_accuracy: 0.6703\n",
      "Epoch 221/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0912 - binary_accuracy: 0.6784\n",
      "Epoch 222/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0913 - binary_accuracy: 0.6740\n",
      "Epoch 223/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0920 - binary_accuracy: 0.6747\n",
      "Epoch 224/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0908 - binary_accuracy: 0.6797\n",
      "Epoch 225/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0917 - binary_accuracy: 0.6756\n",
      "Epoch 226/500\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.0903 - binary_accuracy: 0.6786\n",
      "Epoch 227/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0910 - binary_accuracy: 0.6771\n",
      "Epoch 228/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0918 - binary_accuracy: 0.6731\n",
      "Epoch 229/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0906 - binary_accuracy: 0.6817\n",
      "Epoch 230/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0893 - binary_accuracy: 0.6845\n",
      "Epoch 231/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0908 - binary_accuracy: 0.6782\n",
      "Epoch 232/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0910 - binary_accuracy: 0.6802\n",
      "Epoch 233/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0893 - binary_accuracy: 0.6849\n",
      "Epoch 234/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0913 - binary_accuracy: 0.6755\n",
      "Epoch 235/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0894 - binary_accuracy: 0.6876\n",
      "Epoch 236/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0883 - binary_accuracy: 0.6879\n",
      "Epoch 237/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0897 - binary_accuracy: 0.6845\n",
      "Epoch 238/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0888 - binary_accuracy: 0.6879\n",
      "Epoch 239/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0902 - binary_accuracy: 0.6814\n",
      "Epoch 240/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0886 - binary_accuracy: 0.6882\n",
      "Epoch 241/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0891 - binary_accuracy: 0.6881\n",
      "Epoch 242/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0898 - binary_accuracy: 0.6831\n",
      "Epoch 243/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0894 - binary_accuracy: 0.6859\n",
      "Epoch 244/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0900 - binary_accuracy: 0.6826\n",
      "Epoch 245/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0876 - binary_accuracy: 0.6912\n",
      "Epoch 246/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0885 - binary_accuracy: 0.6905\n",
      "Epoch 247/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0870 - binary_accuracy: 0.6959\n",
      "Epoch 248/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0892 - binary_accuracy: 0.6892\n",
      "Epoch 249/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0877 - binary_accuracy: 0.6950\n",
      "Epoch 250/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0871 - binary_accuracy: 0.6985\n",
      "Epoch 251/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0878 - binary_accuracy: 0.6947\n",
      "Epoch 252/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0890 - binary_accuracy: 0.6906\n",
      "Epoch 253/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0874 - binary_accuracy: 0.6973\n",
      "Epoch 254/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0886 - binary_accuracy: 0.6914\n",
      "Epoch 255/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0863 - binary_accuracy: 0.6979\n",
      "Epoch 256/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0869 - binary_accuracy: 0.6972\n",
      "Epoch 257/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0869 - binary_accuracy: 0.6988\n",
      "Epoch 258/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0869 - binary_accuracy: 0.6979\n",
      "Epoch 259/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0879 - binary_accuracy: 0.6960\n",
      "Epoch 260/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0864 - binary_accuracy: 0.6999\n",
      "Epoch 261/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0862 - binary_accuracy: 0.7035\n",
      "Epoch 262/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0868 - binary_accuracy: 0.6999\n",
      "Epoch 263/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0836 - binary_accuracy: 0.7099\n",
      "Epoch 264/500\n",
      "62393/62393 [==============================] - 38s 611us/step - loss: 0.0886 - binary_accuracy: 0.6907\n",
      "Epoch 265/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0854 - binary_accuracy: 0.7017\n",
      "Epoch 266/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0847 - binary_accuracy: 0.7044\n",
      "Epoch 267/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0866 - binary_accuracy: 0.6991\n",
      "Epoch 268/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0868 - binary_accuracy: 0.6991\n",
      "Epoch 269/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0841 - binary_accuracy: 0.7103\n",
      "Epoch 270/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0848 - binary_accuracy: 0.7075\n",
      "Epoch 271/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0853 - binary_accuracy: 0.7064\n",
      "Epoch 272/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0864 - binary_accuracy: 0.7024\n",
      "Epoch 273/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0841 - binary_accuracy: 0.7115\n",
      "Epoch 274/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0858 - binary_accuracy: 0.7043\n",
      "Epoch 275/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0848 - binary_accuracy: 0.7080\n",
      "Epoch 276/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0849 - binary_accuracy: 0.7082\n",
      "Epoch 277/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0846 - binary_accuracy: 0.7092\n",
      "Epoch 278/500\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.0840 - binary_accuracy: 0.7122\n",
      "Epoch 279/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0833 - binary_accuracy: 0.7153\n",
      "Epoch 280/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0840 - binary_accuracy: 0.7132\n",
      "Epoch 281/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0852 - binary_accuracy: 0.7107\n",
      "Epoch 282/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0838 - binary_accuracy: 0.7158\n",
      "Epoch 283/500\n",
      "62393/62393 [==============================] - 38s 612us/step - loss: 0.0835 - binary_accuracy: 0.7150\n",
      "Epoch 284/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0831 - binary_accuracy: 0.7174\n",
      "Epoch 285/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0840 - binary_accuracy: 0.7125\n",
      "Epoch 286/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0841 - binary_accuracy: 0.7147\n",
      "Epoch 287/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0839 - binary_accuracy: 0.7126\n",
      "Epoch 288/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0840 - binary_accuracy: 0.7125\n",
      "Epoch 289/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0819 - binary_accuracy: 0.7199\n",
      "Epoch 290/500\n",
      "62393/62393 [==============================] - 38s 610us/step - loss: 0.0847 - binary_accuracy: 0.7100\n",
      "Epoch 291/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0827 - binary_accuracy: 0.7197\n",
      "Epoch 292/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0814 - binary_accuracy: 0.7253\n",
      "Epoch 293/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0829 - binary_accuracy: 0.7184\n",
      "Epoch 294/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0819 - binary_accuracy: 0.7234\n",
      "Epoch 295/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0840 - binary_accuracy: 0.7141\n",
      "Epoch 296/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0816 - binary_accuracy: 0.7254\n",
      "Epoch 297/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0836 - binary_accuracy: 0.7146\n",
      "Epoch 298/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0820 - binary_accuracy: 0.7217\n",
      "Epoch 299/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0823 - binary_accuracy: 0.7206\n",
      "Epoch 300/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0814 - binary_accuracy: 0.7230\n",
      "Epoch 301/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0811 - binary_accuracy: 0.7262\n",
      "Epoch 302/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0816 - binary_accuracy: 0.7250\n",
      "Epoch 303/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0813 - binary_accuracy: 0.7267\n",
      "Epoch 304/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0816 - binary_accuracy: 0.7240\n",
      "Epoch 305/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0816 - binary_accuracy: 0.7255\n",
      "Epoch 306/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0801 - binary_accuracy: 0.7302\n",
      "Epoch 307/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0806 - binary_accuracy: 0.7318\n",
      "Epoch 308/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0803 - binary_accuracy: 0.7292\n",
      "Epoch 309/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0811 - binary_accuracy: 0.7298\n",
      "Epoch 310/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0802 - binary_accuracy: 0.7296\n",
      "Epoch 311/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0807 - binary_accuracy: 0.7273\n",
      "Epoch 312/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0824 - binary_accuracy: 0.7282\n",
      "Epoch 313/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0799 - binary_accuracy: 0.7316\n",
      "Epoch 314/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0798 - binary_accuracy: 0.7341\n",
      "Epoch 315/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0795 - binary_accuracy: 0.7350\n",
      "Epoch 316/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0805 - binary_accuracy: 0.7320\n",
      "Epoch 317/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0813 - binary_accuracy: 0.7289\n",
      "Epoch 318/500\n",
      "62393/62393 [==============================] - 38s 614us/step - loss: 0.0807 - binary_accuracy: 0.7285\n",
      "Epoch 319/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0802 - binary_accuracy: 0.7317\n",
      "Epoch 320/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0792 - binary_accuracy: 0.7361\n",
      "Epoch 321/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0790 - binary_accuracy: 0.7360\n",
      "Epoch 322/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0795 - binary_accuracy: 0.7377\n",
      "Epoch 323/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0793 - binary_accuracy: 0.7342\n",
      "Epoch 324/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0796 - binary_accuracy: 0.7344\n",
      "Epoch 325/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0786 - binary_accuracy: 0.7393\n",
      "Epoch 326/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0788 - binary_accuracy: 0.7413\n",
      "Epoch 327/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0789 - binary_accuracy: 0.7408\n",
      "Epoch 328/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0793 - binary_accuracy: 0.7382\n",
      "Epoch 329/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0789 - binary_accuracy: 0.7389\n",
      "Epoch 330/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0790 - binary_accuracy: 0.7378\n",
      "Epoch 331/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0788 - binary_accuracy: 0.7401\n",
      "Epoch 332/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0797 - binary_accuracy: 0.7368\n",
      "Epoch 333/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0777 - binary_accuracy: 0.7449\n",
      "Epoch 334/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0797 - binary_accuracy: 0.7342\n",
      "Epoch 335/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0785 - binary_accuracy: 0.7384\n",
      "Epoch 336/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0791 - binary_accuracy: 0.7400\n",
      "Epoch 337/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0782 - binary_accuracy: 0.7395\n",
      "Epoch 338/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0778 - binary_accuracy: 0.7442\n",
      "Epoch 339/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0788 - binary_accuracy: 0.7365\n",
      "Epoch 340/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0769 - binary_accuracy: 0.7460\n",
      "Epoch 341/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0771 - binary_accuracy: 0.7449\n",
      "Epoch 342/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0793 - binary_accuracy: 0.7386\n",
      "Epoch 343/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0766 - binary_accuracy: 0.7451\n",
      "Epoch 344/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0768 - binary_accuracy: 0.7461\n",
      "Epoch 345/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0771 - binary_accuracy: 0.7444\n",
      "Epoch 346/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0767 - binary_accuracy: 0.7503\n",
      "Epoch 347/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0767 - binary_accuracy: 0.7489\n",
      "Epoch 348/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0776 - binary_accuracy: 0.7452\n",
      "Epoch 349/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0764 - binary_accuracy: 0.7499\n",
      "Epoch 350/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0776 - binary_accuracy: 0.7457\n",
      "Epoch 351/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0792 - binary_accuracy: 0.7415\n",
      "Epoch 352/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0757 - binary_accuracy: 0.7501\n",
      "Epoch 353/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.0765 - binary_accuracy: 0.7513\n",
      "Epoch 354/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0774 - binary_accuracy: 0.7444\n",
      "Epoch 355/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0775 - binary_accuracy: 0.7460\n",
      "Epoch 356/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0771 - binary_accuracy: 0.7475\n",
      "Epoch 357/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0767 - binary_accuracy: 0.7499\n",
      "Epoch 358/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0762 - binary_accuracy: 0.7525\n",
      "Epoch 359/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0779 - binary_accuracy: 0.7475\n",
      "Epoch 360/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0782 - binary_accuracy: 0.7451\n",
      "Epoch 361/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.0771 - binary_accuracy: 0.7467\n",
      "Epoch 362/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0758 - binary_accuracy: 0.7527\n",
      "Epoch 363/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0741 - binary_accuracy: 0.7588\n",
      "Epoch 364/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0757 - binary_accuracy: 0.7517\n",
      "Epoch 365/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0769 - binary_accuracy: 0.7498\n",
      "Epoch 366/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0764 - binary_accuracy: 0.7513\n",
      "Epoch 367/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0742 - binary_accuracy: 0.7621\n",
      "Epoch 368/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0766 - binary_accuracy: 0.7523\n",
      "Epoch 369/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0767 - binary_accuracy: 0.7509\n",
      "Epoch 370/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0756 - binary_accuracy: 0.7548\n",
      "Epoch 371/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0768 - binary_accuracy: 0.7520\n",
      "Epoch 372/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0760 - binary_accuracy: 0.7553\n",
      "Epoch 373/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0745 - binary_accuracy: 0.7597\n",
      "Epoch 374/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.0742 - binary_accuracy: 0.7601\n",
      "Epoch 375/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0731 - binary_accuracy: 0.7635\n",
      "Epoch 376/500\n",
      "62393/62393 [==============================] - 39s 630us/step - loss: 0.0764 - binary_accuracy: 0.7534\n",
      "Epoch 377/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0757 - binary_accuracy: 0.7574\n",
      "Epoch 378/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0735 - binary_accuracy: 0.7601\n",
      "Epoch 379/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0744 - binary_accuracy: 0.7593\n",
      "Epoch 380/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0757 - binary_accuracy: 0.7555\n",
      "Epoch 381/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0733 - binary_accuracy: 0.7635\n",
      "Epoch 382/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0743 - binary_accuracy: 0.7605\n",
      "Epoch 383/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0747 - binary_accuracy: 0.7576\n",
      "Epoch 384/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0741 - binary_accuracy: 0.7624\n",
      "Epoch 385/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0748 - binary_accuracy: 0.7598\n",
      "Epoch 386/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0733 - binary_accuracy: 0.7660\n",
      "Epoch 387/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0735 - binary_accuracy: 0.7624\n",
      "Epoch 388/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0736 - binary_accuracy: 0.7643\n",
      "Epoch 389/500\n",
      "62393/62393 [==============================] - 39s 618us/step - loss: 0.0745 - binary_accuracy: 0.7602\n",
      "Epoch 390/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0742 - binary_accuracy: 0.7618\n",
      "Epoch 391/500\n",
      "62393/62393 [==============================] - 38s 617us/step - loss: 0.0739 - binary_accuracy: 0.7623\n",
      "Epoch 392/500\n",
      "62393/62393 [==============================] - 39s 617us/step - loss: 0.0746 - binary_accuracy: 0.7624\n",
      "Epoch 393/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0746 - binary_accuracy: 0.7646\n",
      "Epoch 394/500\n",
      "62393/62393 [==============================] - 38s 615us/step - loss: 0.0745 - binary_accuracy: 0.7626\n",
      "Epoch 395/500\n",
      "62393/62393 [==============================] - 38s 616us/step - loss: 0.0737 - binary_accuracy: 0.7646\n",
      "Epoch 396/500\n",
      "62393/62393 [==============================] - 38s 613us/step - loss: 0.0745 - binary_accuracy: 0.7613\n",
      "Epoch 397/500\n",
      "62393/62393 [==============================] - 45s 719us/step - loss: 0.0739 - binary_accuracy: 0.7645\n",
      "Epoch 398/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0719 - binary_accuracy: 0.7700\n",
      "Epoch 399/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0723 - binary_accuracy: 0.7695\n",
      "Epoch 400/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0743 - binary_accuracy: 0.7633\n",
      "Epoch 401/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0726 - binary_accuracy: 0.7668\n",
      "Epoch 402/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0742 - binary_accuracy: 0.7629\n",
      "Epoch 403/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0721 - binary_accuracy: 0.7688\n",
      "Epoch 404/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0742 - binary_accuracy: 0.7616\n",
      "Epoch 405/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0789 - binary_accuracy: 0.7480\n",
      "Epoch 406/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0731 - binary_accuracy: 0.7660\n",
      "Epoch 407/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0715 - binary_accuracy: 0.7723\n",
      "Epoch 408/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0720 - binary_accuracy: 0.7707\n",
      "Epoch 409/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.0726 - binary_accuracy: 0.7708\n",
      "Epoch 410/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0731 - binary_accuracy: 0.7680\n",
      "Epoch 411/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0721 - binary_accuracy: 0.7699\n",
      "Epoch 412/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0719 - binary_accuracy: 0.7728\n",
      "Epoch 413/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0724 - binary_accuracy: 0.7712\n",
      "Epoch 414/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0702 - binary_accuracy: 0.7776\n",
      "Epoch 415/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0719 - binary_accuracy: 0.7735\n",
      "Epoch 416/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0713 - binary_accuracy: 0.7728\n",
      "Epoch 417/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0726 - binary_accuracy: 0.7694\n",
      "Epoch 418/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0721 - binary_accuracy: 0.7715\n",
      "Epoch 419/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0712 - binary_accuracy: 0.7770\n",
      "Epoch 420/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0717 - binary_accuracy: 0.7735\n",
      "Epoch 421/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0721 - binary_accuracy: 0.7738\n",
      "Epoch 422/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0720 - binary_accuracy: 0.7720\n",
      "Epoch 423/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0719 - binary_accuracy: 0.7731\n",
      "Epoch 424/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0719 - binary_accuracy: 0.7730\n",
      "Epoch 425/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.0716 - binary_accuracy: 0.7732\n",
      "Epoch 426/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0703 - binary_accuracy: 0.7786\n",
      "Epoch 427/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0722 - binary_accuracy: 0.7733\n",
      "Epoch 428/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0701 - binary_accuracy: 0.7753\n",
      "Epoch 429/500\n",
      "62393/62393 [==============================] - 39s 623us/step - loss: 0.0701 - binary_accuracy: 0.7795\n",
      "Epoch 430/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0709 - binary_accuracy: 0.7752\n",
      "Epoch 431/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.0721 - binary_accuracy: 0.7717\n",
      "Epoch 432/500\n",
      "62393/62393 [==============================] - 39s 619us/step - loss: 0.0714 - binary_accuracy: 0.7758\n",
      "Epoch 433/500\n",
      "62393/62393 [==============================] - 40s 636us/step - loss: 0.0717 - binary_accuracy: 0.7721\n",
      "Epoch 434/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0719 - binary_accuracy: 0.7712\n",
      "Epoch 435/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0705 - binary_accuracy: 0.7777\n",
      "Epoch 436/500\n",
      "62393/62393 [==============================] - 39s 625us/step - loss: 0.0701 - binary_accuracy: 0.7794\n",
      "Epoch 437/500\n",
      "62393/62393 [==============================] - 39s 622us/step - loss: 0.0722 - binary_accuracy: 0.7722\n",
      "Epoch 438/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0715 - binary_accuracy: 0.7740\n",
      "Epoch 439/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0694 - binary_accuracy: 0.7827\n",
      "Epoch 440/500\n",
      "62393/62393 [==============================] - 39s 626us/step - loss: 0.0704 - binary_accuracy: 0.7789\n",
      "Epoch 441/500\n",
      "62393/62393 [==============================] - 39s 633us/step - loss: 0.0683 - binary_accuracy: 0.7853\n",
      "Epoch 442/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.0704 - binary_accuracy: 0.7789\n",
      "Epoch 443/500\n",
      "62393/62393 [==============================] - 39s 621us/step - loss: 0.0690 - binary_accuracy: 0.7820\n",
      "Epoch 444/500\n",
      "62393/62393 [==============================] - 39s 620us/step - loss: 0.0705 - binary_accuracy: 0.7789\n",
      "Epoch 445/500\n",
      "62393/62393 [==============================] - 39s 628us/step - loss: 0.0703 - binary_accuracy: 0.7796\n",
      "Epoch 446/500\n",
      "62393/62393 [==============================] - 39s 631us/step - loss: 0.0718 - binary_accuracy: 0.7737\n",
      "Epoch 447/500\n",
      "62393/62393 [==============================] - 39s 627us/step - loss: 0.0681 - binary_accuracy: 0.7861\n",
      "Epoch 448/500\n",
      "62393/62393 [==============================] - 39s 624us/step - loss: 0.0699 - binary_accuracy: 0.7814\n",
      "Epoch 449/500\n",
      "62393/62393 [==============================] - 39s 629us/step - loss: 0.0730 - binary_accuracy: 0.7701\n",
      "Epoch 450/500\n",
      "36500/62393 [================>.............] - ETA: 15s - loss: 0.0684 - binary_accuracy: 0.7853Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=500, nb_epoch=500,class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "TxdxrzuD9gK8",
    "outputId": "14723d2c-969b-4f86-ee37-6616c3fe6b49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision is  0.4927084808155175\n",
      "Train Accuracy is  0.8270959883320245\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>41165</td>\n",
       "      <td>10749</td>\n",
       "      <td>51914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>39</td>\n",
       "      <td>10440</td>\n",
       "      <td>10479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>41204</td>\n",
       "      <td>21189</td>\n",
       "      <td>62393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0      1    All\n",
       "True                          \n",
       "0.0        41165  10749  51914\n",
       "1.0           39  10440  10479\n",
       "All        41204  21189  62393"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,accuracy_score\n",
    "y_predicted=model.predict_classes(X_train)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_train, y_predicted)\n",
    "accuracy=accuracy_score(y_train,y_predicted)\n",
    "print(\"Train Precision is \",precision)\n",
    "print(\"Train Accuracy is \",accuracy)\n",
    "\n",
    "pd.crosstab(y_train, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "colab_type": "code",
    "id": "nUgO7sic989s",
    "outputId": "daf628dd-c872-498e-b97b-9ddb35dee89a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision is  0.19191226867717615\n",
      "Test Accuracy is  0.584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>1910</td>\n",
       "      <td>1179</td>\n",
       "      <td>3089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>381</td>\n",
       "      <td>280</td>\n",
       "      <td>661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>2291</td>\n",
       "      <td>1459</td>\n",
       "      <td>3750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     0     1   All\n",
       "True                       \n",
       "0.0        1910  1179  3089\n",
       "1.0         381   280   661\n",
       "All        2291  1459  3750"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predicted=model.predict_classes(X_test)\n",
    "y_predicted=y_predicted.reshape(1,-1)[0]\n",
    "precision = precision_score(y_test, y_predicted)\n",
    "accuracy=accuracy_score(y_test,y_predicted)\n",
    "print(\"Test Precision is \",precision)\n",
    "print(\"Test Accuracy is \",accuracy)\n",
    "\n",
    "pd.crosstab(y_test, y_predicted, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tRNOxbg9js0N"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market-2 .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
